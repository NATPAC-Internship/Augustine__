{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exporter Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State</th>\n",
       "      <th>pin</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>Taluk</th>\n",
       "      <th>District</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5P HORTIPLEX</td>\n",
       "      <td>19, 2nd St, Balamurugan Nagar, Anna Nagar Exte...</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>600042</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Chennai City Corporation</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>12.978761</td>\n",
       "      <td>80.197810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.A.NUTS</td>\n",
       "      <td>WJMW+7F7, Chandanathope, Mamoodu, Kerala 14, I...</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>686012</td>\n",
       "      <td>1346288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kottayam</td>\n",
       "      <td>Kottayam</td>\n",
       "      <td>9.548567</td>\n",
       "      <td>76.522308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.K. AHAMED MODERAN RICE MILL</td>\n",
       "      <td>P.O, 40/2, Mannarpalayam Main Rd, Allikuttai, ...</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>636017</td>\n",
       "      <td>214500</td>\n",
       "      <td>48600</td>\n",
       "      <td>0</td>\n",
       "      <td>24000</td>\n",
       "      <td>24000</td>\n",
       "      <td>144685</td>\n",
       "      <td>194590</td>\n",
       "      <td>452294</td>\n",
       "      <td>1653150</td>\n",
       "      <td>Allikuttai</td>\n",
       "      <td>Salem</td>\n",
       "      <td>11.671925</td>\n",
       "      <td>78.192939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.K.R. TEXTILES</td>\n",
       "      <td>48W5+XQ9, Velampalayam, A.Thirumuruganpoondi, ...</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>641652</td>\n",
       "      <td>441797</td>\n",
       "      <td>361413</td>\n",
       "      <td>679656</td>\n",
       "      <td>568203</td>\n",
       "      <td>197687</td>\n",
       "      <td>14754</td>\n",
       "      <td>0</td>\n",
       "      <td>2841</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiruppur</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>11.139879</td>\n",
       "      <td>77.314291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.M.FISHERIES</td>\n",
       "      <td>98WW+WWQ, Valanjavazhy, Ambalapuzha, Kerala 68...</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>688005</td>\n",
       "      <td>1374800</td>\n",
       "      <td>1961480</td>\n",
       "      <td>2034720</td>\n",
       "      <td>3308895</td>\n",
       "      <td>2385049</td>\n",
       "      <td>1697278</td>\n",
       "      <td>2512818</td>\n",
       "      <td>3724210</td>\n",
       "      <td>3315054</td>\n",
       "      <td>Ambalappuzha</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>9.407684</td>\n",
       "      <td>76.351707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>WAYANAD ORGANIC RESEARCH P LTD</td>\n",
       "      <td>Wayanad, Kerala, India</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>686012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>401</td>\n",
       "      <td>Kottayam</td>\n",
       "      <td>Kottayam</td>\n",
       "      <td>9.548567</td>\n",
       "      <td>76.522308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>WAYANAD SPICE VILLAGE</td>\n",
       "      <td>Surabhikavala, Pulpally, Kerala 673579, India</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>673579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34707</td>\n",
       "      <td>Sulthanbathery</td>\n",
       "      <td>Wayanad</td>\n",
       "      <td>11.798784</td>\n",
       "      <td>76.174897</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>YUGA DEMETER EXIM</td>\n",
       "      <td>4 335 2.p.a.p Canal Feeder Road Munnar, Main R...</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>642112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28000</td>\n",
       "      <td>Udamalpet</td>\n",
       "      <td>Coimbatore</td>\n",
       "      <td>10.507437</td>\n",
       "      <td>77.203841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>ZAIN TEX</td>\n",
       "      <td>24, Sivanar Street, Sendarapatti, Gugai, Salem...</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>636006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5088</td>\n",
       "      <td>Salem</td>\n",
       "      <td>Salem</td>\n",
       "      <td>11.643417</td>\n",
       "      <td>78.152907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>ZULI EXPORTS</td>\n",
       "      <td>near GLPS Nottappuram, C Building, 12- 281, Pu...</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>676304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28500</td>\n",
       "      <td>Tirurangadi</td>\n",
       "      <td>Malappuram</td>\n",
       "      <td>11.056520</td>\n",
       "      <td>75.983266</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2645 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Exporter Name  \\\n",
       "0                       5P HORTIPLEX   \n",
       "1                           A.A.NUTS   \n",
       "2      A.K. AHAMED MODERAN RICE MILL   \n",
       "3                    A.K.R. TEXTILES   \n",
       "4                      A.M.FISHERIES   \n",
       "...                              ...   \n",
       "2640  WAYANAD ORGANIC RESEARCH P LTD   \n",
       "2641           WAYANAD SPICE VILLAGE   \n",
       "2642               YUGA DEMETER EXIM   \n",
       "2643                        ZAIN TEX   \n",
       "2644                    ZULI EXPORTS   \n",
       "\n",
       "                                                Address       State     pin  \\\n",
       "0     19, 2nd St, Balamurugan Nagar, Anna Nagar Exte...  Tamil Nadu  600042   \n",
       "1     WJMW+7F7, Chandanathope, Mamoodu, Kerala 14, I...      Kerala  686012   \n",
       "2     P.O, 40/2, Mannarpalayam Main Rd, Allikuttai, ...  Tamil Nadu  636017   \n",
       "3     48W5+XQ9, Velampalayam, A.Thirumuruganpoondi, ...  Tamil Nadu  641652   \n",
       "4     98WW+WWQ, Valanjavazhy, Ambalapuzha, Kerala 68...      Kerala  688005   \n",
       "...                                                 ...         ...     ...   \n",
       "2640                             Wayanad, Kerala, India      Kerala  686012   \n",
       "2641      Surabhikavala, Pulpally, Kerala 673579, India      Kerala  673579   \n",
       "2642  4 335 2.p.a.p Canal Feeder Road Munnar, Main R...  Tamil Nadu  642112   \n",
       "2643  24, Sivanar Street, Sendarapatti, Gugai, Salem...  Tamil Nadu  636006   \n",
       "2644  near GLPS Nottappuram, C Building, 12- 281, Pu...      Kerala  676304   \n",
       "\n",
       "         2015     2016     2017     2018     2019     2020     2021     2022  \\\n",
       "0       20000        0        0        0        0        0        0        0   \n",
       "1     1346288        0        0        0        0        0        0        0   \n",
       "2      214500    48600        0    24000    24000   144685   194590   452294   \n",
       "3      441797   361413   679656   568203   197687    14754        0     2841   \n",
       "4     1374800  1961480  2034720  3308895  2385049  1697278  2512818  3724210   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "2640        0        0        0        0        0        0        0        0   \n",
       "2641        0        0        0        0        0        0        0        0   \n",
       "2642        0        0        0        0        0        0        0        0   \n",
       "2643        0        0        0        0        0        0        0        0   \n",
       "2644        0        0        0        0        0        0        0        0   \n",
       "\n",
       "         2023                     Taluk    District   Latitude  Longitude  \\\n",
       "0           0  Chennai City Corporation     Chennai  12.978761  80.197810   \n",
       "1           0                  Kottayam    Kottayam   9.548567  76.522308   \n",
       "2     1653150                Allikuttai       Salem  11.671925  78.192939   \n",
       "3           0                  Tiruppur  Coimbatore  11.139879  77.314291   \n",
       "4     3315054              Ambalappuzha   Alappuzha   9.407684  76.351707   \n",
       "...       ...                       ...         ...        ...        ...   \n",
       "2640      401                  Kottayam    Kottayam   9.548567  76.522308   \n",
       "2641    34707            Sulthanbathery     Wayanad  11.798784  76.174897   \n",
       "2642    28000                 Udamalpet  Coimbatore  10.507437  77.203841   \n",
       "2643     5088                     Salem       Salem  11.643417  78.152907   \n",
       "2644    28500               Tirurangadi  Malappuram  11.056520  75.983266   \n",
       "\n",
       "      Cluster  \n",
       "0           2  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "...       ...  \n",
       "2640        0  \n",
       "2641        3  \n",
       "2642        1  \n",
       "2643        1  \n",
       "2644        3  \n",
       "\n",
       "[2645 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\filtered_clustered_clster2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Prepare the data for training\n",
    "X_train = df[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y_train = df[['2024', '2025', '2026', '2027', '2028']]\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for years 2024-2028 using the last row of the training data as an example\n",
    "#df_last_row = df.iloc[[1]]  # Assuming the last row contains the data for prediction\n",
    "predictions = rf_model.predict(df_last_row[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']])\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "df_predictions = pd.DataFrame(predictions, columns=['2024', '2025', '2026', '2027', '2028'])\n",
    "\n",
    "# Save the predictions to a new CSV file\n",
    "df_predictions.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Rand_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "X_train = df[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y_train = df[['2024', '2025', '2026', '2027', '2028']]\n",
    "\n",
    "# Initialize the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for all rows\n",
    "predictions = []\n",
    "for index, row in df.iterrows():\n",
    "    features = row[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']].values.reshape(1, -1)\n",
    "    pred = rf_model.predict(features)\n",
    "    predictions.append(pred[0])\n",
    "\n",
    "# Create a DataFrame for the predictions\n",
    "df_predictions = pd.DataFrame(predictions, columns=['2024', '2025', '2026', '2027', '2028'])\n",
    "\n",
    "# Combine the predictions with the original DataFrame\n",
    "df_combined = pd.concat([df, df_predictions], axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df_combined.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Rand_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Quantity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Quantity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m X_2024 \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]  \u001b[38;5;66;03m# Take the last row for prediction\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):  \u001b[38;5;66;03m# Create lagged features for 2024\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     X_2024[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantity_lag_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_2024\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuantity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshift(lag)\n\u001b[0;32m     42\u001b[0m predicted_quantity_2024 \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_2024)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted quantity for 2024:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_quantity_2024)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Quantity'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\filtered_clustered_clster2.csv')\n",
    "\n",
    "# Create a time series DataFrame with 'Year' as the index\n",
    "years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "time_series_df = pd.DataFrame({'Year': years})\n",
    "time_series_df.set_index('Year', inplace=True)\n",
    "\n",
    "# Populate the time series DataFrame with quantity values\n",
    "for year in years:\n",
    "    time_series_df.loc[year, 'Quantity'] = df[year].sum()\n",
    "\n",
    "# Create lagged features for time series forecasting\n",
    "for lag in range(1, 6):  # Using lag values from 1 to 5 (adjust as needed)\n",
    "    time_series_df[f'Quantity_lag_{lag}'] = time_series_df['Quantity'].shift(lag)\n",
    "\n",
    "# Drop rows with NaN values due to lagging\n",
    "time_series_df.dropna(inplace=True)\n",
    "\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = time_series_df.drop(['Quantity'], axis=1)  # Features\n",
    "y = time_series_df['Quantity']  # Target variable\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the entire time series data\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Make predictions for 2024\n",
    "# Create features for 2024 based on the last available data point\n",
    "X_2024 = X.iloc[[-1]]  # Take the last row for prediction\n",
    "for lag in range(1, 6):  # Create lagged features for 2024\n",
    "    X_2024[f'Quantity_lag_{lag}'] = X_2024['Quantity'].shift(lag)\n",
    "\n",
    "predicted_quantity_2024 = rf_model.predict(X_2024)\n",
    "print(\"Predicted quantity for 2024:\", predicted_quantity_2024)\n",
    "\n",
    "# Save the prediction to a new CSV file\n",
    "predicted_df = pd.DataFrame({'Year': [2024], 'Quantity': [predicted_quantity_2024]})\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Rand_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train Random Forest model using full data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is your DataFrame with columns 'd_2015' to 'd_2023'\n",
    "df['d_2024'] = float('NaN')\n",
    "# Separate features and target\n",
    "X = df[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y = df['d_2024']  # Assuming 'd_2024' is the column for 2024 data\n",
    "\n",
    "# Train Random Forest model using full data\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions for 2024\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate model (optional, since you're using full data for training)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save predictions to CSV\n",
    "predictions_df = pd.DataFrame({'Predicted_d_2024': y_pred})\n",
    "predictions_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Rand_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train Random Forest model using full data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024 and populate 'd_2024' column\u001b[39;00m\n\u001b[0;32m     19\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_2024\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is your DataFrame with columns 'd_2015' to 'd_2023'\n",
    "\n",
    "# Add placeholder column 'd_2024' with NaN values\n",
    "df['d_2024'] = float('NaN')\n",
    "\n",
    "# Separate features and target\n",
    "X = df[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y = df['d_2024']  # Placeholder column for 2024 data\n",
    "\n",
    "# Train Random Forest model using full data\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions for 2024 and populate 'd_2024' column\n",
    "df['d_2024'] = model.predict(X)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df.to_csv('predicted_2024_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '5P HORTIPLEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming df is your DataFrame with columns 'd_2015' to 'd_2023'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create a SimpleImputer to fill NaN values with the mean\u001b[39;00m\n\u001b[0;32m      9\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m df_filled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mdf\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[0;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m df_filled[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2016\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2018\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    877\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py:390\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    382\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter was deprecated in version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    388\u001b[0m     )\n\u001b[1;32m--> 390\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\impute\\_base.py:342\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    337\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    339\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    340\u001b[0m         )\n\u001b[0;32m    341\u001b[0m     )\n\u001b[1;32m--> 342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '5P HORTIPLEX'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming df is your DataFrame with columns 'd_2015' to 'd_2023'\n",
    "\n",
    "# Create a SimpleImputer to fill NaN values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_filled[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y = df_filled['d_2024']  # Placeholder column for 2024 data\n",
    "\n",
    "# Train Random Forest model using full data\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions for 2024 and populate 'd_2024' column\n",
    "df_filled['d_2024'] = model.predict(X)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df_filled.to_csv('predicted_2024_full_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Train Linear Regression model using full data\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024 and populate 'd_2024' column\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md_2024\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming df is your DataFrame with columns 'd_2015' to 'd_2023'\n",
    "\n",
    "# Create a placeholder column 'd_2024' with NaN values\n",
    "df['d_2024'] = float('NaN')\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df[['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']]\n",
    "y = df['d_2024']\n",
    "\n",
    "# Train Linear Regression model using full data\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions for 2024 and populate 'd_2024' column\n",
    "df['d_2024'] = model.predict(X)\n",
    "\n",
    "# Save predictions to CSV\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2645, 23805]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     23\u001b[0m prediction_2024 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([df[feature_cols]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2645, 23805]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming your dataset is already loaded into the 'df' DataFrame\n",
    "\n",
    "# Create a list of column names for the input features (years)\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "# Create a new DataFrame with only the relevant columns\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Create a list of years for the target variable\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, df[feature_cols].values.ravel())\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(np.array([df[feature_cols].values[-1]]))\n",
    "\n",
    "# Create a new column 'd_2024' in the original DataFrame\n",
    "df['d_2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in input data (X): 0\n",
      "Shape of input data (X): (2645, 9)\n",
      "Shape of target data (y): (23805,)\n",
      "Number of unique rows in input data (X): 2628\n",
      "Number of unique rows in target data (y): 2628\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2645, 23805]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     36\u001b[0m prediction_2024 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([df[feature_cols]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2645, 23805]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Create a list of column names for the input features (years)\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "# Check for missing values in the feature columns\n",
    "print(\"Missing values in input data (X):\", df[feature_cols].isnull().sum().sum())\n",
    "\n",
    "# Drop rows with missing values in the feature columns\n",
    "df = df.dropna(subset=feature_cols)\n",
    "\n",
    "# Create a new DataFrame with only the relevant columns\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Create a list of years for the target variable\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Check the dimensions of input data and target data\n",
    "print(\"Shape of input data (X):\", X.shape)\n",
    "print(\"Shape of target data (y):\", df[feature_cols].values.ravel().shape)\n",
    "\n",
    "# Check for duplicate rows in input data and target data\n",
    "print(\"Number of unique rows in input data (X):\", X.drop_duplicates().shape[0])\n",
    "print(\"Number of unique rows in target data (y):\", df[feature_cols].drop_duplicates().shape[0])\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, df[feature_cols].values.ravel())\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(np.array([df[feature_cols].values[-1]]))\n",
    "\n",
    "# Create a new column 'd_2024' in the original DataFrame\n",
    "df['d_2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Month_Day'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load your dataset and pivot it if needed\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Assuming you already have the 'pivot_df' DataFrame loaded\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Prepare the training data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMonth_Day\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;241m2015\u001b[39m,\u001b[38;5;241m2016\u001b[39m,\u001b[38;5;241m2017\u001b[39m,\u001b[38;5;241m2018\u001b[39m, \u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2020\u001b[39m, \u001b[38;5;241m2021\u001b[39m, \u001b[38;5;241m2022\u001b[39m,\u001b[38;5;241m2024\u001b[39m]]  \u001b[38;5;66;03m# Corrected column access\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# One-hot encode the Month_Day column\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6248\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6250\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Month_Day'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas import *\n",
    "\n",
    "# Load your dataset and pivot it if needed\n",
    "# Assuming you already have the 'pivot_df' DataFrame loaded\n",
    "\n",
    "# Prepare the training data\n",
    "X_train = df[['Month_Day']]\n",
    "y_train = df[[2015,2016,2017,2018, 2019, 2020, 2021, 2022,2024]]  # Corrected column access\n",
    "\n",
    "# One-hot encode the Month_Day column\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "# Train a regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Generate all dates for the year 2023\n",
    "dates_2023 = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "dates_2023_formatted = dates_2023.strftime('%m-%d')\n",
    "\n",
    "# Prepare data for predicting 2023\n",
    "X_test = pd.DataFrame({'Month_Day': dates_2023_formatted})\n",
    "X_test_encoded = ct.transform(X_test)\n",
    "\n",
    "# Predict for 2023\n",
    "predictions_2023 = model.predict(X_test_encoded)\n",
    "\n",
    "# Save predictions to final.csv\n",
    "predictions_df = pd.DataFrame(predictions_2023, columns=[str(year) for year in range(2023, 2028)])\n",
    "predictions_df.insert(0, 'Month_Day', dates_2023_formatted)\n",
    "predictions_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2645, 23805]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     31\u001b[0m prediction_2024 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(ct\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([X_train\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1124\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2645, 23805]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Create a list of column names for the input features (years)\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "# Create a new DataFrame with only the relevant columns\n",
    "X_train = df[feature_cols]\n",
    "\n",
    "# Create a list of years for the target variable\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# One-hot encode the input features\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [i for i in range(len(feature_cols))])], remainder='passthrough')\n",
    "X_train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "# Reshape the target variable to a 1D array\n",
    "y_train = df[feature_cols].values.ravel()\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(ct.transform(np.array([X_train.values[-1]])))\n",
    "\n",
    "# Create a new DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'d_2024': prediction_2024})\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'d_2024'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_2024'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2015\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2016\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2017\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2018\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m X_train \u001b[38;5;241m=\u001b[39m df[feature_cols]\n\u001b[1;32m---> 12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md_2024\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Target variable for 2024\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# One-hot encode the input features\u001b[39;00m\n\u001b[0;32m     15\u001b[0m ct \u001b[38;5;241m=\u001b[39m ColumnTransformer(transformers\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(), [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(feature_cols))])], remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_2024'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training and prediction\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['d_2024']  # Target variable for 2024\n",
    "\n",
    "# One-hot encode the input features\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [i for i in range(len(feature_cols))])], remainder='passthrough')\n",
    "X_train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(ct.transform(np.array([X_train.values[-1]])))\n",
    "\n",
    "# Create a DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'d_2024': prediction_2024})\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'd_2024' not found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training and prediction\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "\n",
    "# Target variable for 2024 (column to be predicted)\n",
    "y_train = df['d_2024'] if 'd_2024' in df.columns else None\n",
    "\n",
    "if y_train is not None:\n",
    "    # One-hot encode the input features\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [i for i in range(len(feature_cols))])], remainder='passthrough')\n",
    "    X_train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "\n",
    "    # Make predictions for 2024\n",
    "    prediction_2024 = model.predict(ct.transform(np.array([X_train.values[-1]])))\n",
    "\n",
    "    # Create a DataFrame with the predicted value for 2024\n",
    "    predicted_df = pd.DataFrame({'d_2024': prediction_2024})\n",
    "\n",
    "    # Save the predicted DataFrame to a new CSV file\n",
    "    predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n",
    "else:\n",
    "    print(\"Column 'd_2024' not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     30\u001b[0m prediction_2024 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(ct\u001b[38;5;241m.\u001b[39mtransform(np\u001b[38;5;241m.\u001b[39marray([X_train\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    585\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[1;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "\n",
    "# Create an empty column 'd_2024' in the DataFrame\n",
    "df['d_2024'] = np.nan\n",
    "\n",
    "# One-hot encode the input features\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [i for i in range(len(feature_cols))])], remainder='passthrough')\n",
    "X_train_encoded = ct.fit_transform(X_train)\n",
    "\n",
    "# Extract the target variable (empty 'd_2024' column)\n",
    "y_train = df['d_2024']\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(ct.transform(np.array([X_train.values[-1]])))\n",
    "\n",
    "# Update the 'd_2024' column with the predicted values\n",
    "df.loc[df.index[-1], 'd_2024'] = prediction_2024[0]\n",
    "\n",
    "# Save the DataFrame with predicted 'd_2024' to a new CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Create a DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'2024': prediction_2024})\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Linear_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "prediction_2025 = model.predict(X_train)\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Create a DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'2024': prediction_2024})\n",
    "\n",
    "prediction_2025[prediction_2025 < 0] = 0\n",
    "predicted_df = pd.DataFrame({'2024': prediction_2024,'2025': prediction_2025})\n",
    "\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Lin.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_24504\\691307158.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[str(year)] = prediction\n",
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_24504\\691307158.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[str(year)] = prediction\n",
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_24504\\691307158.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[str(year)] = prediction\n",
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_24504\\691307158.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[str(year)] = prediction\n",
      "C:\\Users\\augus\\AppData\\Local\\Temp\\ipykernel_24504\\691307158.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[str(year)] = prediction\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict values for 2024, 2025, and 2026\n",
    "predictions = {}\n",
    "for year in range(2024, 2029):\n",
    "    # Predict based on existing data\n",
    "    prediction = model.predict(X_train)\n",
    "    # Replace negative predictions with 0\n",
    "    prediction[prediction < 0] = 0\n",
    "    predictions[year] = prediction\n",
    "    # Update X_train to include the predicted values for the next year\n",
    "    X_train[str(year)] = prediction\n",
    "    # Fit the model with updated data for the next prediction\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Create a DataFrame with all predicted values\n",
    "predicted_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Add a 'Year' column to the DataFrame\n",
    "predicted_df['Year'] = predicted_df.index\n",
    "\n",
    "# Reorder columns to have 'Year' as the first column\n",
    "predicted_df = predicted_df[['Year', 2024, 2025, 2026,2027,2028]]  # Removed quotes around column names\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Code\\Lin.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_with_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2025 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "prediction_2025[prediction_2025 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2025'] = prediction_2025\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2026 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "prediction_2026[prediction_2026 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2026'] = prediction_2026\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2027 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "prediction_2027[prediction_2027 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2027'] = prediction_2027\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026','2027']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2028 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "prediction_2028[prediction_2028 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2028'] = prediction_2028\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')\n",
    "\n",
    "df = df.drop(columns=['pin','adress'])\n",
    "\n",
    "\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\Linear_chumma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2025\n",
    "prediction_2025 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2025[prediction_2025 < 0] = 0\n",
    "\n",
    "# Add the predicted '2025' column to the DataFrame\n",
    "df['2025'] = prediction_2025\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2026\n",
    "prediction_2026 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2026[prediction_2026 < 0] = 0\n",
    "\n",
    "# Add the predicted '2026' column to the DataFrame\n",
    "df['2026'] = prediction_2026\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2027\n",
    "prediction_2027 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2027[prediction_2027 < 0] = 0\n",
    "\n",
    "# Add the predicted '2027' column to the DataFrame\n",
    "df['2027'] = prediction_2027\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026','2027']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a Random Forest Regression model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2028\n",
    "prediction_2028 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2028[prediction_2028 < 0] = 0\n",
    "\n",
    "# Add the predicted '2028' column to the DataFrame\n",
    "df['2028'] = prediction_2028\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['2026prediction_2026'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\RandFr_chumma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.5-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\augus\\appdata\\roaming\\python\\python311\\site-packages (from catboost) (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\python311\\lib\\site-packages (from catboost) (1.26.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\python311\\lib\\site-packages (from catboost) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from catboost) (1.12.0)\n",
      "Collecting plotly (from catboost)\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: six in c:\\users\\augus\\appdata\\roaming\\python\\python311\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\augus\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\augus\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\python311\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.5-cp311-cp311-win_amd64.whl (101.1 MB)\n",
      "   ---------------------------------------- 0.0/101.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/101.1 MB 660.6 kB/s eta 0:02:34\n",
      "   ---------------------------------------- 0.1/101.1 MB 1.7 MB/s eta 0:01:00\n",
      "   ---------------------------------------- 0.4/101.1 MB 3.3 MB/s eta 0:00:31\n",
      "   ---------------------------------------- 0.6/101.1 MB 3.5 MB/s eta 0:00:29\n",
      "   ---------------------------------------- 0.8/101.1 MB 3.6 MB/s eta 0:00:28\n",
      "   ---------------------------------------- 1.0/101.1 MB 3.8 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 1.2/101.1 MB 3.8 MB/s eta 0:00:27\n",
      "    --------------------------------------- 1.4/101.1 MB 3.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 1.6/101.1 MB 4.0 MB/s eta 0:00:26\n",
      "    --------------------------------------- 1.8/101.1 MB 3.8 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.0/101.1 MB 3.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.2/101.1 MB 3.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.4/101.1 MB 4.0 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.6/101.1 MB 4.0 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.8/101.1 MB 4.0 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.0/101.1 MB 4.0 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.2/101.1 MB 4.0 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.4/101.1 MB 4.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.6/101.1 MB 4.1 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.8/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 3.9/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.1/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.3/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.5/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.7/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 4.9/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.1/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.3/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.5/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.7/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 5.9/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 6.1/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 6.3/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 6.5/101.1 MB 4.1 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 6.7/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 6.9/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 7.1/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 7.3/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 7.5/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 7.7/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 7.8/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.0/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.3/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.4/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.7/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 8.8/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.0/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.3/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.4/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.6/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 9.8/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 10.0/101.1 MB 4.1 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 10.2/101.1 MB 4.1 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 10.4/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 10.6/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 10.8/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 11.0/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 11.2/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 11.4/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 11.6/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 11.8/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 12.0/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 12.2/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 12.4/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 12.6/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 12.8/101.1 MB 4.2 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 13.0/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 13.2/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 13.4/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 13.5/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 13.8/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.0/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.2/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.3/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.5/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.7/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.9/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 15.1/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 15.3/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 15.5/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 15.7/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 15.9/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.1/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.3/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.5/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.7/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 16.9/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 17.1/101.1 MB 4.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 17.3/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 17.5/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 17.7/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 17.9/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 18.1/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 18.2/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 18.5/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 18.6/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 18.9/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 19.0/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 19.3/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 19.4/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 19.6/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 19.8/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 20.0/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 20.2/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 20.4/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 20.6/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 20.8/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 21.0/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 21.2/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 21.4/101.1 MB 4.2 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 21.6/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 21.8/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 22.0/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 22.1/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 22.3/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 22.5/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 22.7/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 22.9/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 23.1/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 23.3/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 23.5/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 23.7/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 23.9/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 24.1/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 24.3/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 24.5/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 24.7/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 24.9/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 25.1/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 25.3/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 25.5/101.1 MB 4.2 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 25.7/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 25.9/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.1/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.2/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.5/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.6/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 26.8/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.0/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.2/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.4/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 27.6/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 27.8/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.0/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.2/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.4/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.6/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 28.8/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.0/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.2/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.4/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.6/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.8/101.1 MB 4.2 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 30.0/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 30.2/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 30.4/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 30.6/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 30.8/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.0/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.2/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.4/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.6/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.8/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 31.9/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 32.1/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 32.3/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 32.5/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 32.7/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 32.9/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 33.1/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 33.3/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 33.5/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 33.7/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 33.9/101.1 MB 4.2 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 34.1/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 34.3/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 34.5/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 34.7/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 34.9/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 35.1/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 35.3/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 35.5/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 35.7/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 35.9/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 36.1/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 36.3/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 36.5/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 36.7/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 36.9/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 37.1/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 37.3/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 37.5/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 37.7/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 37.9/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 38.1/101.1 MB 4.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 38.3/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 38.5/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 38.6/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 38.9/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 39.0/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 39.2/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 39.4/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 39.6/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 39.8/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 40.0/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 40.3/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 40.4/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 40.6/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 40.8/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 41.0/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 41.2/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 41.4/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 41.7/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 41.9/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 42.1/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 42.3/101.1 MB 4.2 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 42.5/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 42.7/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 42.9/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 43.1/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 43.3/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 43.5/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 43.7/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 43.8/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.1/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.2/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.5/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.6/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 44.8/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 45.1/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 45.2/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 45.4/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 45.6/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 45.8/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 46.0/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 46.2/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 46.4/101.1 MB 4.2 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 46.6/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 46.8/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.0/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.2/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.4/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.6/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 47.8/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 48.0/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.2/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.5/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.7/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.9/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.1/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.3/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.5/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.7/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 49.9/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.1/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.3/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 50.4/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 50.7/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 50.8/101.1 MB 4.2 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 51.0/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 51.2/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 51.4/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 51.6/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 51.8/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 52.0/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 52.2/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 52.4/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 52.6/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 52.8/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 53.0/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 53.2/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 53.4/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 53.6/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 53.8/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.0/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.2/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.4/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.6/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.8/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 54.9/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 55.1/101.1 MB 4.2 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 55.4/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 55.5/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 55.7/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 55.9/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 56.1/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 56.3/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 56.5/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 56.7/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 56.9/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 57.1/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 57.3/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 57.5/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 57.7/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 57.9/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 58.1/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 58.3/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 58.5/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 58.7/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 58.9/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 59.1/101.1 MB 4.2 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 59.3/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 59.5/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 59.7/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 59.9/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 60.1/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 60.3/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 60.5/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 60.7/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 60.8/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 61.1/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 61.2/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 61.5/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 61.6/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 61.8/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 62.0/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 62.2/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 62.4/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 62.6/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 62.8/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 63.0/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 63.2/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 63.4/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 63.6/101.1 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 63.8/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 64.0/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 64.2/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 64.4/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 64.6/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 64.8/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 65.0/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 65.2/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 65.4/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 65.6/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 65.8/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.0/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.2/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.4/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.6/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.8/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 66.9/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 67.2/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 67.3/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 67.5/101.1 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 67.7/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 67.9/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 68.1/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 68.3/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 68.5/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 68.7/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 68.9/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 69.1/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 69.3/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 69.5/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 69.7/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 69.9/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 70.1/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 70.3/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 70.5/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 70.7/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 70.9/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 71.1/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 71.2/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 71.4/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 71.7/101.1 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 71.8/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.0/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.2/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.4/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.6/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 72.8/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 73.0/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 73.2/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 73.4/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 73.6/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 73.8/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.0/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.2/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.4/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.6/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.8/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 74.9/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 75.2/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 75.3/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 75.5/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 75.7/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 75.9/101.1 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 76.1/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.3/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.5/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.7/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 76.9/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.1/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.3/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.5/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.7/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 77.9/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 78.1/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 78.3/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.5/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.7/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 78.9/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.1/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.3/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.5/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.6/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 79.8/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 80.0/101.1 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 80.2/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.4/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.6/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 80.8/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.0/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.2/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.4/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.6/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 81.8/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.0/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.2/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.4/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.6/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.8/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 82.9/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 83.1/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 83.3/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.5/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.7/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 83.9/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.1/101.1 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 84.3/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.5/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.7/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 84.9/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 85.1/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 85.3/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 85.5/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 85.7/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 85.9/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.1/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.3/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.4/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.7/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 86.8/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.0/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.2/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.4/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.6/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 87.8/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 88.0/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 88.2/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 88.4/101.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 88.6/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 88.8/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.0/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.2/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.4/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.6/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 89.8/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.0/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.2/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.4/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.6/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 90.8/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 91.0/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.1/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.3/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.5/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.7/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 91.9/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.1/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.3/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.5/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.7/101.1 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.9/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.1/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.3/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 93.5/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.7/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 93.9/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.1/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.3/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.5/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.7/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 94.9/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.0/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.2/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.4/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.6/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.8/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 96.0/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.2/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.4/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.6/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 96.8/101.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.0/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.2/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.4/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.6/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.8/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.0/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.2/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.4/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.6/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.8/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.9/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.4/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.5/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.3/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.5/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.1/101.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.1/101.1 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.1/47.1 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "   ---------------------------------------- 0.0/16.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/16.4 MB 6.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/16.4 MB 6.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.7/16.4 MB 5.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.9/16.4 MB 5.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.1/16.4 MB 4.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.3/16.4 MB 4.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.5/16.4 MB 4.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/16.4 MB 4.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.9/16.4 MB 4.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.0/16.4 MB 4.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.3/16.4 MB 4.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 2.4/16.4 MB 4.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.6/16.4 MB 4.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.8/16.4 MB 4.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.0/16.4 MB 4.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.2/16.4 MB 4.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.4/16.4 MB 4.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.6/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.8/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 4.0/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.2/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.4/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.6/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.8/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.0/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 5.2/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.4/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.6/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.8/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.0/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 6.2/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.4/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 6.6/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.7/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 7.0/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.1/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 7.4/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.5/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 7.7/16.4 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 7.9/16.4 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.1/16.4 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.3/16.4 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.5/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/16.4 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.9/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.1/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.3/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.5/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.7/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.9/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.1/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.3/16.4 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.5/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.7/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.9/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 11.0/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.2/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.4/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.7/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.8/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 12.0/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 12.2/16.4 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.4/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.6/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.8/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 13.0/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.2/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.4/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.6/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.8/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.0/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.2/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.4/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.6/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.7/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.0/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.1/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.3/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.5/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.7/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.9/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.1/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.3/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.4/16.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.4/16.4 MB 4.1 MB/s eta 0:00:00\n",
      "Installing collected packages: plotly, graphviz, catboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\Python311\\\\Lib\\\\site-packages\\\\catboost\\\\_catboost.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 981589.8295164\ttotal: 156ms\tremaining: 2m 36s\n",
      "1:\tlearn: 924003.5497488\ttotal: 164ms\tremaining: 1m 21s\n",
      "2:\tlearn: 874690.1583949\ttotal: 175ms\tremaining: 58.2s\n",
      "3:\tlearn: 829169.1280099\ttotal: 183ms\tremaining: 45.6s\n",
      "4:\tlearn: 785413.4218465\ttotal: 193ms\tremaining: 38.3s\n",
      "5:\tlearn: 743834.0192658\ttotal: 205ms\tremaining: 33.9s\n",
      "6:\tlearn: 709997.5804777\ttotal: 214ms\tremaining: 30.3s\n",
      "7:\tlearn: 676549.9334979\ttotal: 225ms\tremaining: 27.9s\n",
      "8:\tlearn: 644343.1271465\ttotal: 237ms\tremaining: 26.1s\n",
      "9:\tlearn: 615446.0012666\ttotal: 257ms\tremaining: 25.4s\n",
      "10:\tlearn: 588443.9756229\ttotal: 263ms\tremaining: 23.6s\n",
      "11:\tlearn: 565147.7971661\ttotal: 273ms\tremaining: 22.4s\n",
      "12:\tlearn: 541511.8349276\ttotal: 285ms\tremaining: 21.6s\n",
      "13:\tlearn: 520653.5691491\ttotal: 298ms\tremaining: 21s\n",
      "14:\tlearn: 499966.8516221\ttotal: 307ms\tremaining: 20.1s\n",
      "15:\tlearn: 482506.7705240\ttotal: 315ms\tremaining: 19.4s\n",
      "16:\tlearn: 467017.8651163\ttotal: 320ms\tremaining: 18.5s\n",
      "17:\tlearn: 449244.1167487\ttotal: 350ms\tremaining: 19.1s\n",
      "18:\tlearn: 435091.3641636\ttotal: 364ms\tremaining: 18.8s\n",
      "19:\tlearn: 422592.9309724\ttotal: 389ms\tremaining: 19.1s\n",
      "20:\tlearn: 411187.2817975\ttotal: 405ms\tremaining: 18.9s\n",
      "21:\tlearn: 400683.6951112\ttotal: 422ms\tremaining: 18.8s\n",
      "22:\tlearn: 390525.8975513\ttotal: 434ms\tremaining: 18.4s\n",
      "23:\tlearn: 379970.8604981\ttotal: 446ms\tremaining: 18.2s\n",
      "24:\tlearn: 372036.6744367\ttotal: 456ms\tremaining: 17.8s\n",
      "25:\tlearn: 362313.7476056\ttotal: 463ms\tremaining: 17.3s\n",
      "26:\tlearn: 355631.7865192\ttotal: 473ms\tremaining: 17s\n",
      "27:\tlearn: 349322.7968620\ttotal: 479ms\tremaining: 16.6s\n",
      "28:\tlearn: 341830.5613508\ttotal: 485ms\tremaining: 16.2s\n",
      "29:\tlearn: 335967.0999214\ttotal: 492ms\tremaining: 15.9s\n",
      "30:\tlearn: 331040.1254082\ttotal: 496ms\tremaining: 15.5s\n",
      "31:\tlearn: 325954.9646490\ttotal: 499ms\tremaining: 15.1s\n",
      "32:\tlearn: 321885.8410833\ttotal: 508ms\tremaining: 14.9s\n",
      "33:\tlearn: 317619.3723560\ttotal: 511ms\tremaining: 14.5s\n",
      "34:\tlearn: 313593.7158952\ttotal: 516ms\tremaining: 14.2s\n",
      "35:\tlearn: 310227.8391442\ttotal: 523ms\tremaining: 14s\n",
      "36:\tlearn: 307118.9907916\ttotal: 528ms\tremaining: 13.7s\n",
      "37:\tlearn: 304151.1472967\ttotal: 537ms\tremaining: 13.6s\n",
      "38:\tlearn: 300960.5787011\ttotal: 541ms\tremaining: 13.3s\n",
      "39:\tlearn: 298642.1050276\ttotal: 545ms\tremaining: 13.1s\n",
      "40:\tlearn: 296412.3091293\ttotal: 552ms\tremaining: 12.9s\n",
      "41:\tlearn: 294263.0142714\ttotal: 558ms\tremaining: 12.7s\n",
      "42:\tlearn: 291895.1909644\ttotal: 564ms\tremaining: 12.5s\n",
      "43:\tlearn: 290273.7801638\ttotal: 568ms\tremaining: 12.3s\n",
      "44:\tlearn: 288721.0814760\ttotal: 571ms\tremaining: 12.1s\n",
      "45:\tlearn: 287529.0153798\ttotal: 577ms\tremaining: 12s\n",
      "46:\tlearn: 285982.9238777\ttotal: 584ms\tremaining: 11.8s\n",
      "47:\tlearn: 284722.1536068\ttotal: 589ms\tremaining: 11.7s\n",
      "48:\tlearn: 283736.6923574\ttotal: 602ms\tremaining: 11.7s\n",
      "49:\tlearn: 282546.1040264\ttotal: 628ms\tremaining: 11.9s\n",
      "50:\tlearn: 281425.8228344\ttotal: 640ms\tremaining: 11.9s\n",
      "51:\tlearn: 280535.1645220\ttotal: 646ms\tremaining: 11.8s\n",
      "52:\tlearn: 279673.6624914\ttotal: 652ms\tremaining: 11.7s\n",
      "53:\tlearn: 278929.4222353\ttotal: 661ms\tremaining: 11.6s\n",
      "54:\tlearn: 278245.9493832\ttotal: 666ms\tremaining: 11.4s\n",
      "55:\tlearn: 277636.3839816\ttotal: 671ms\tremaining: 11.3s\n",
      "56:\tlearn: 276998.0325800\ttotal: 687ms\tremaining: 11.4s\n",
      "57:\tlearn: 276624.6937533\ttotal: 696ms\tremaining: 11.3s\n",
      "58:\tlearn: 276153.7499772\ttotal: 704ms\tremaining: 11.2s\n",
      "59:\tlearn: 275670.0686086\ttotal: 716ms\tremaining: 11.2s\n",
      "60:\tlearn: 275352.9192381\ttotal: 725ms\tremaining: 11.2s\n",
      "61:\tlearn: 274954.8070441\ttotal: 736ms\tremaining: 11.1s\n",
      "62:\tlearn: 274682.6989953\ttotal: 746ms\tremaining: 11.1s\n",
      "63:\tlearn: 274419.6368848\ttotal: 751ms\tremaining: 11s\n",
      "64:\tlearn: 274245.4496185\ttotal: 765ms\tremaining: 11s\n",
      "65:\tlearn: 273985.3820337\ttotal: 784ms\tremaining: 11.1s\n",
      "66:\tlearn: 273748.2521915\ttotal: 811ms\tremaining: 11.3s\n",
      "67:\tlearn: 273525.9773610\ttotal: 837ms\tremaining: 11.5s\n",
      "68:\tlearn: 273244.5487644\ttotal: 851ms\tremaining: 11.5s\n",
      "69:\tlearn: 273059.2281413\ttotal: 871ms\tremaining: 11.6s\n",
      "70:\tlearn: 272731.7572499\ttotal: 880ms\tremaining: 11.5s\n",
      "71:\tlearn: 272536.5233931\ttotal: 892ms\tremaining: 11.5s\n",
      "72:\tlearn: 272304.0395584\ttotal: 905ms\tremaining: 11.5s\n",
      "73:\tlearn: 272174.5149178\ttotal: 909ms\tremaining: 11.4s\n",
      "74:\tlearn: 271962.6398581\ttotal: 915ms\tremaining: 11.3s\n",
      "75:\tlearn: 271798.7850933\ttotal: 930ms\tremaining: 11.3s\n",
      "76:\tlearn: 271632.3120744\ttotal: 939ms\tremaining: 11.3s\n",
      "77:\tlearn: 271503.7349113\ttotal: 947ms\tremaining: 11.2s\n",
      "78:\tlearn: 271252.0514751\ttotal: 956ms\tremaining: 11.1s\n",
      "79:\tlearn: 271082.4980478\ttotal: 962ms\tremaining: 11.1s\n",
      "80:\tlearn: 270880.7132844\ttotal: 968ms\tremaining: 11s\n",
      "81:\tlearn: 270734.0955350\ttotal: 972ms\tremaining: 10.9s\n",
      "82:\tlearn: 270613.1011643\ttotal: 977ms\tremaining: 10.8s\n",
      "83:\tlearn: 270475.4860306\ttotal: 983ms\tremaining: 10.7s\n",
      "84:\tlearn: 270351.1666130\ttotal: 991ms\tremaining: 10.7s\n",
      "85:\tlearn: 270242.8896479\ttotal: 997ms\tremaining: 10.6s\n",
      "86:\tlearn: 270078.2233573\ttotal: 1s\tremaining: 10.5s\n",
      "87:\tlearn: 269974.6203338\ttotal: 1.01s\tremaining: 10.4s\n",
      "88:\tlearn: 269816.8067235\ttotal: 1.01s\tremaining: 10.4s\n",
      "89:\tlearn: 269689.7037870\ttotal: 1.02s\tremaining: 10.3s\n",
      "90:\tlearn: 269591.4098721\ttotal: 1.03s\tremaining: 10.3s\n",
      "91:\tlearn: 269487.4439827\ttotal: 1.03s\tremaining: 10.2s\n",
      "92:\tlearn: 269403.8296123\ttotal: 1.05s\tremaining: 10.2s\n",
      "93:\tlearn: 269298.3488631\ttotal: 1.05s\tremaining: 10.1s\n",
      "94:\tlearn: 269245.9930385\ttotal: 1.06s\tremaining: 10.1s\n",
      "95:\tlearn: 269159.0792384\ttotal: 1.07s\tremaining: 10.1s\n",
      "96:\tlearn: 269084.8308354\ttotal: 1.07s\tremaining: 10s\n",
      "97:\tlearn: 269037.3917931\ttotal: 1.08s\tremaining: 9.93s\n",
      "98:\tlearn: 268957.8681351\ttotal: 1.08s\tremaining: 9.85s\n",
      "99:\tlearn: 268888.3541684\ttotal: 1.09s\tremaining: 9.78s\n",
      "100:\tlearn: 268839.5210654\ttotal: 1.1s\tremaining: 9.77s\n",
      "101:\tlearn: 268770.6204499\ttotal: 1.1s\tremaining: 9.71s\n",
      "102:\tlearn: 268704.2032358\ttotal: 1.11s\tremaining: 9.7s\n",
      "103:\tlearn: 268635.0703252\ttotal: 1.12s\tremaining: 9.62s\n",
      "104:\tlearn: 268562.4817663\ttotal: 1.12s\tremaining: 9.55s\n",
      "105:\tlearn: 268504.1056457\ttotal: 1.13s\tremaining: 9.52s\n",
      "106:\tlearn: 268462.3718499\ttotal: 1.13s\tremaining: 9.44s\n",
      "107:\tlearn: 268417.2091036\ttotal: 1.13s\tremaining: 9.37s\n",
      "108:\tlearn: 268334.8995246\ttotal: 1.14s\tremaining: 9.29s\n",
      "109:\tlearn: 268297.7769868\ttotal: 1.14s\tremaining: 9.24s\n",
      "110:\tlearn: 268268.8927800\ttotal: 1.15s\tremaining: 9.19s\n",
      "111:\tlearn: 268214.2477382\ttotal: 1.15s\tremaining: 9.12s\n",
      "112:\tlearn: 268150.4589003\ttotal: 1.15s\tremaining: 9.05s\n",
      "113:\tlearn: 268100.5108090\ttotal: 1.16s\tremaining: 9.02s\n",
      "114:\tlearn: 268062.6186652\ttotal: 1.16s\tremaining: 8.96s\n",
      "115:\tlearn: 268026.0012483\ttotal: 1.17s\tremaining: 8.9s\n",
      "116:\tlearn: 267950.0385988\ttotal: 1.17s\tremaining: 8.85s\n",
      "117:\tlearn: 267926.3421234\ttotal: 1.18s\tremaining: 8.79s\n",
      "118:\tlearn: 267895.0670663\ttotal: 1.18s\tremaining: 8.74s\n",
      "119:\tlearn: 267835.0483940\ttotal: 1.19s\tremaining: 8.69s\n",
      "120:\tlearn: 267814.0052120\ttotal: 1.19s\tremaining: 8.64s\n",
      "121:\tlearn: 267789.7403921\ttotal: 1.19s\tremaining: 8.6s\n",
      "122:\tlearn: 267740.6825866\ttotal: 1.2s\tremaining: 8.55s\n",
      "123:\tlearn: 267705.1175964\ttotal: 1.21s\tremaining: 8.52s\n",
      "124:\tlearn: 267687.9002942\ttotal: 1.21s\tremaining: 8.46s\n",
      "125:\tlearn: 267671.6169275\ttotal: 1.22s\tremaining: 8.47s\n",
      "126:\tlearn: 267627.8077580\ttotal: 1.23s\tremaining: 8.44s\n",
      "127:\tlearn: 267612.5745413\ttotal: 1.24s\tremaining: 8.41s\n",
      "128:\tlearn: 267578.4076134\ttotal: 1.24s\tremaining: 8.4s\n",
      "129:\tlearn: 267547.1690805\ttotal: 1.25s\tremaining: 8.37s\n",
      "130:\tlearn: 267525.5058744\ttotal: 1.25s\tremaining: 8.33s\n",
      "131:\tlearn: 267485.9328060\ttotal: 1.26s\tremaining: 8.28s\n",
      "132:\tlearn: 267471.3590501\ttotal: 1.26s\tremaining: 8.23s\n",
      "133:\tlearn: 267452.1294459\ttotal: 1.27s\tremaining: 8.19s\n",
      "134:\tlearn: 267413.7570218\ttotal: 1.27s\tremaining: 8.15s\n",
      "135:\tlearn: 267385.0892336\ttotal: 1.27s\tremaining: 8.1s\n",
      "136:\tlearn: 267373.5234805\ttotal: 1.28s\tremaining: 8.05s\n",
      "137:\tlearn: 267348.5549102\ttotal: 1.28s\tremaining: 8.03s\n",
      "138:\tlearn: 267337.3681358\ttotal: 1.29s\tremaining: 7.99s\n",
      "139:\tlearn: 267309.6907402\ttotal: 1.29s\tremaining: 7.94s\n",
      "140:\tlearn: 267299.3048102\ttotal: 1.3s\tremaining: 7.92s\n",
      "141:\tlearn: 267268.6009115\ttotal: 1.3s\tremaining: 7.89s\n",
      "142:\tlearn: 267254.9806290\ttotal: 1.31s\tremaining: 7.84s\n",
      "143:\tlearn: 267229.4173273\ttotal: 1.31s\tremaining: 7.8s\n",
      "144:\tlearn: 267215.4745192\ttotal: 1.32s\tremaining: 7.77s\n",
      "145:\tlearn: 267202.3377438\ttotal: 1.32s\tremaining: 7.73s\n",
      "146:\tlearn: 267180.3660185\ttotal: 1.32s\tremaining: 7.69s\n",
      "147:\tlearn: 267171.8172946\ttotal: 1.33s\tremaining: 7.66s\n",
      "148:\tlearn: 267146.2359672\ttotal: 1.34s\tremaining: 7.63s\n",
      "149:\tlearn: 267122.9919926\ttotal: 1.34s\tremaining: 7.6s\n",
      "150:\tlearn: 267104.5198539\ttotal: 1.35s\tremaining: 7.57s\n",
      "151:\tlearn: 267096.4059594\ttotal: 1.35s\tremaining: 7.54s\n",
      "152:\tlearn: 267081.5535327\ttotal: 1.35s\tremaining: 7.5s\n",
      "153:\tlearn: 267061.9629593\ttotal: 1.37s\tremaining: 7.51s\n",
      "154:\tlearn: 267051.8661750\ttotal: 1.38s\tremaining: 7.52s\n",
      "155:\tlearn: 267025.1691828\ttotal: 1.43s\tremaining: 7.74s\n",
      "156:\tlearn: 267015.7409611\ttotal: 1.44s\tremaining: 7.75s\n",
      "157:\tlearn: 267006.9024989\ttotal: 1.45s\tremaining: 7.75s\n",
      "158:\tlearn: 266998.6118530\ttotal: 1.46s\tremaining: 7.74s\n",
      "159:\tlearn: 266979.3606023\ttotal: 1.47s\tremaining: 7.71s\n",
      "160:\tlearn: 266971.5747013\ttotal: 1.47s\tremaining: 7.67s\n",
      "161:\tlearn: 266964.2633409\ttotal: 1.48s\tremaining: 7.64s\n",
      "162:\tlearn: 266957.3938086\ttotal: 1.49s\tremaining: 7.64s\n",
      "163:\tlearn: 266950.9359732\ttotal: 1.5s\tremaining: 7.63s\n",
      "164:\tlearn: 266945.7180487\ttotal: 1.5s\tremaining: 7.59s\n",
      "165:\tlearn: 266926.8813334\ttotal: 1.5s\tremaining: 7.56s\n",
      "166:\tlearn: 266910.0113070\ttotal: 1.51s\tremaining: 7.53s\n",
      "167:\tlearn: 266892.7802278\ttotal: 1.51s\tremaining: 7.5s\n",
      "168:\tlearn: 266886.7462616\ttotal: 1.52s\tremaining: 7.47s\n",
      "169:\tlearn: 266881.2111508\ttotal: 1.52s\tremaining: 7.44s\n",
      "170:\tlearn: 266876.4238718\ttotal: 1.53s\tremaining: 7.41s\n",
      "171:\tlearn: 266859.3542304\ttotal: 1.53s\tremaining: 7.37s\n",
      "172:\tlearn: 266837.2155374\ttotal: 1.53s\tremaining: 7.33s\n",
      "173:\tlearn: 266817.1649596\ttotal: 1.54s\tremaining: 7.31s\n",
      "174:\tlearn: 266804.1101708\ttotal: 1.54s\tremaining: 7.28s\n",
      "175:\tlearn: 266799.2783940\ttotal: 1.55s\tremaining: 7.25s\n",
      "176:\tlearn: 266795.2785124\ttotal: 1.55s\tremaining: 7.22s\n",
      "177:\tlearn: 266776.3630396\ttotal: 1.56s\tremaining: 7.21s\n",
      "178:\tlearn: 266759.3883059\ttotal: 1.57s\tremaining: 7.18s\n",
      "179:\tlearn: 266747.3378115\ttotal: 1.58s\tremaining: 7.22s\n",
      "180:\tlearn: 266733.0551013\ttotal: 1.6s\tremaining: 7.23s\n",
      "181:\tlearn: 266726.7307980\ttotal: 1.6s\tremaining: 7.21s\n",
      "182:\tlearn: 266714.5420676\ttotal: 1.61s\tremaining: 7.2s\n",
      "183:\tlearn: 266701.7418482\ttotal: 1.62s\tremaining: 7.21s\n",
      "184:\tlearn: 266686.1344476\ttotal: 1.63s\tremaining: 7.2s\n",
      "185:\tlearn: 266679.2594059\ttotal: 1.64s\tremaining: 7.18s\n",
      "186:\tlearn: 266669.0326247\ttotal: 1.65s\tremaining: 7.17s\n",
      "187:\tlearn: 266657.4915091\ttotal: 1.65s\tremaining: 7.13s\n",
      "188:\tlearn: 266637.8971102\ttotal: 1.66s\tremaining: 7.12s\n",
      "189:\tlearn: 266631.7517576\ttotal: 1.67s\tremaining: 7.11s\n",
      "190:\tlearn: 266627.4500496\ttotal: 1.67s\tremaining: 7.08s\n",
      "191:\tlearn: 266614.6777706\ttotal: 1.68s\tremaining: 7.07s\n",
      "192:\tlearn: 266610.9865547\ttotal: 1.68s\tremaining: 7.04s\n",
      "193:\tlearn: 266597.3185297\ttotal: 1.69s\tremaining: 7.01s\n",
      "194:\tlearn: 266586.1634262\ttotal: 1.69s\tremaining: 6.99s\n",
      "195:\tlearn: 266581.7332188\ttotal: 1.7s\tremaining: 6.95s\n",
      "196:\tlearn: 266570.2427865\ttotal: 1.7s\tremaining: 6.93s\n",
      "197:\tlearn: 266567.0592937\ttotal: 1.71s\tremaining: 6.91s\n",
      "198:\tlearn: 266557.4972071\ttotal: 1.71s\tremaining: 6.88s\n",
      "199:\tlearn: 266551.4131915\ttotal: 1.71s\tremaining: 6.86s\n",
      "200:\tlearn: 266545.9775850\ttotal: 1.72s\tremaining: 6.83s\n",
      "201:\tlearn: 266542.9888553\ttotal: 1.72s\tremaining: 6.81s\n",
      "202:\tlearn: 266534.7864136\ttotal: 1.73s\tremaining: 6.79s\n",
      "203:\tlearn: 266527.4740505\ttotal: 1.73s\tremaining: 6.76s\n",
      "204:\tlearn: 266519.1592865\ttotal: 1.74s\tremaining: 6.74s\n",
      "205:\tlearn: 266504.9049267\ttotal: 1.74s\tremaining: 6.72s\n",
      "206:\tlearn: 266502.5930288\ttotal: 1.75s\tremaining: 6.72s\n",
      "207:\tlearn: 266500.4107310\ttotal: 1.76s\tremaining: 6.71s\n",
      "208:\tlearn: 266492.9454264\ttotal: 1.77s\tremaining: 6.7s\n",
      "209:\tlearn: 266485.9565446\ttotal: 1.78s\tremaining: 6.68s\n",
      "210:\tlearn: 266478.2538666\ttotal: 1.78s\tremaining: 6.67s\n",
      "211:\tlearn: 266470.9603120\ttotal: 1.79s\tremaining: 6.65s\n",
      "212:\tlearn: 266464.8865763\ttotal: 1.79s\tremaining: 6.63s\n",
      "213:\tlearn: 266453.6815700\ttotal: 1.8s\tremaining: 6.62s\n",
      "214:\tlearn: 266451.6707685\ttotal: 1.81s\tremaining: 6.61s\n",
      "215:\tlearn: 266442.1864630\ttotal: 1.82s\tremaining: 6.59s\n",
      "216:\tlearn: 266439.1352657\ttotal: 1.82s\tremaining: 6.57s\n",
      "217:\tlearn: 266437.3145430\ttotal: 1.83s\tremaining: 6.55s\n",
      "218:\tlearn: 266431.2987810\ttotal: 1.83s\tremaining: 6.53s\n",
      "219:\tlearn: 266429.6314728\ttotal: 1.83s\tremaining: 6.51s\n",
      "220:\tlearn: 266421.9537266\ttotal: 1.84s\tremaining: 6.49s\n",
      "221:\tlearn: 266415.3119225\ttotal: 1.84s\tremaining: 6.47s\n",
      "222:\tlearn: 266413.7364756\ttotal: 1.85s\tremaining: 6.44s\n",
      "223:\tlearn: 266405.7155817\ttotal: 1.85s\tremaining: 6.42s\n",
      "224:\tlearn: 266403.1873293\ttotal: 1.86s\tremaining: 6.39s\n",
      "225:\tlearn: 266400.7818185\ttotal: 1.86s\tremaining: 6.38s\n",
      "226:\tlearn: 266393.6251146\ttotal: 1.86s\tremaining: 6.35s\n",
      "227:\tlearn: 266391.3964788\ttotal: 1.87s\tremaining: 6.33s\n",
      "228:\tlearn: 266385.4922221\ttotal: 1.88s\tremaining: 6.32s\n",
      "229:\tlearn: 266381.3743239\ttotal: 1.88s\tremaining: 6.3s\n",
      "230:\tlearn: 266379.9987874\ttotal: 1.89s\tremaining: 6.28s\n",
      "231:\tlearn: 266374.4335208\ttotal: 1.89s\tremaining: 6.27s\n",
      "232:\tlearn: 266371.6961433\ttotal: 1.9s\tremaining: 6.24s\n",
      "233:\tlearn: 266368.1519027\ttotal: 1.9s\tremaining: 6.22s\n",
      "234:\tlearn: 266366.9245106\ttotal: 1.91s\tremaining: 6.21s\n",
      "235:\tlearn: 266359.5052337\ttotal: 1.91s\tremaining: 6.19s\n",
      "236:\tlearn: 266353.6393337\ttotal: 1.92s\tremaining: 6.17s\n",
      "237:\tlearn: 266346.4164755\ttotal: 1.92s\tremaining: 6.15s\n",
      "238:\tlearn: 266342.0615641\ttotal: 1.93s\tremaining: 6.13s\n",
      "239:\tlearn: 266337.1207753\ttotal: 1.93s\tremaining: 6.11s\n",
      "240:\tlearn: 266332.6427458\ttotal: 1.94s\tremaining: 6.11s\n",
      "241:\tlearn: 266325.9267473\ttotal: 1.95s\tremaining: 6.09s\n",
      "242:\tlearn: 266319.2135592\ttotal: 1.96s\tremaining: 6.09s\n",
      "243:\tlearn: 266315.1489608\ttotal: 1.96s\tremaining: 6.08s\n",
      "244:\tlearn: 266313.3102215\ttotal: 1.97s\tremaining: 6.07s\n",
      "245:\tlearn: 266311.5695513\ttotal: 1.97s\tremaining: 6.05s\n",
      "246:\tlearn: 266306.9474198\ttotal: 1.98s\tremaining: 6.03s\n",
      "247:\tlearn: 266305.2973255\ttotal: 1.99s\tremaining: 6.03s\n",
      "248:\tlearn: 266304.0779194\ttotal: 1.99s\tremaining: 6.01s\n",
      "249:\tlearn: 266298.2927858\ttotal: 2s\tremaining: 5.99s\n",
      "250:\tlearn: 266296.7461550\ttotal: 2.01s\tremaining: 6s\n",
      "251:\tlearn: 266291.2163757\ttotal: 2.01s\tremaining: 5.98s\n",
      "252:\tlearn: 266285.9009169\ttotal: 2.02s\tremaining: 5.97s\n",
      "253:\tlearn: 266282.4290749\ttotal: 2.03s\tremaining: 5.97s\n",
      "254:\tlearn: 266281.6274680\ttotal: 2.04s\tremaining: 5.96s\n",
      "255:\tlearn: 266279.7646110\ttotal: 2.05s\tremaining: 5.97s\n",
      "256:\tlearn: 266276.6658522\ttotal: 2.06s\tremaining: 5.96s\n",
      "257:\tlearn: 266275.9440376\ttotal: 2.07s\tremaining: 5.95s\n",
      "258:\tlearn: 266272.5766377\ttotal: 2.07s\tremaining: 5.93s\n",
      "259:\tlearn: 266267.9439719\ttotal: 2.08s\tremaining: 5.92s\n",
      "260:\tlearn: 266262.7502422\ttotal: 2.08s\tremaining: 5.91s\n",
      "261:\tlearn: 266257.5857668\ttotal: 2.09s\tremaining: 5.88s\n",
      "262:\tlearn: 266256.8781049\ttotal: 2.09s\tremaining: 5.86s\n",
      "263:\tlearn: 266253.7614735\ttotal: 2.1s\tremaining: 5.85s\n",
      "264:\tlearn: 266250.6165926\ttotal: 2.1s\tremaining: 5.84s\n",
      "265:\tlearn: 266247.5822024\ttotal: 2.11s\tremaining: 5.82s\n",
      "266:\tlearn: 266244.2123816\ttotal: 2.11s\tremaining: 5.8s\n",
      "267:\tlearn: 266243.0663991\ttotal: 2.12s\tremaining: 5.79s\n",
      "268:\tlearn: 266239.5671633\ttotal: 2.12s\tremaining: 5.77s\n",
      "269:\tlearn: 266238.4844538\ttotal: 2.13s\tremaining: 5.75s\n",
      "270:\tlearn: 266235.7789226\ttotal: 2.13s\tremaining: 5.74s\n",
      "271:\tlearn: 266230.7535464\ttotal: 2.14s\tremaining: 5.73s\n",
      "272:\tlearn: 266230.1699953\ttotal: 2.14s\tremaining: 5.71s\n",
      "273:\tlearn: 266225.9394442\ttotal: 2.15s\tremaining: 5.69s\n",
      "274:\tlearn: 266223.4002436\ttotal: 2.16s\tremaining: 5.68s\n",
      "275:\tlearn: 266219.5272702\ttotal: 2.16s\tremaining: 5.67s\n",
      "276:\tlearn: 266218.4236766\ttotal: 2.17s\tremaining: 5.66s\n",
      "277:\tlearn: 266217.3871073\ttotal: 2.17s\tremaining: 5.64s\n",
      "278:\tlearn: 266214.0352434\ttotal: 2.18s\tremaining: 5.64s\n",
      "279:\tlearn: 266210.5725846\ttotal: 2.19s\tremaining: 5.64s\n",
      "280:\tlearn: 266209.5929090\ttotal: 2.2s\tremaining: 5.62s\n",
      "281:\tlearn: 266206.9183398\ttotal: 2.21s\tremaining: 5.63s\n",
      "282:\tlearn: 266204.9197029\ttotal: 2.21s\tremaining: 5.61s\n",
      "283:\tlearn: 266203.9307083\ttotal: 2.22s\tremaining: 5.59s\n",
      "284:\tlearn: 266201.8364227\ttotal: 2.23s\tremaining: 5.59s\n",
      "285:\tlearn: 266199.1928045\ttotal: 2.23s\tremaining: 5.57s\n",
      "286:\tlearn: 266196.5844379\ttotal: 2.23s\tremaining: 5.55s\n",
      "287:\tlearn: 266195.0248973\ttotal: 2.24s\tremaining: 5.54s\n",
      "288:\tlearn: 266192.9419306\ttotal: 2.25s\tremaining: 5.53s\n",
      "289:\tlearn: 266192.2228278\ttotal: 2.25s\tremaining: 5.51s\n",
      "290:\tlearn: 266189.5152671\ttotal: 2.26s\tremaining: 5.5s\n",
      "291:\tlearn: 266185.9060805\ttotal: 2.26s\tremaining: 5.49s\n",
      "292:\tlearn: 266183.1351082\ttotal: 2.27s\tremaining: 5.47s\n",
      "293:\tlearn: 266181.6891919\ttotal: 2.27s\tremaining: 5.45s\n",
      "294:\tlearn: 266179.2016339\ttotal: 2.27s\tremaining: 5.43s\n",
      "295:\tlearn: 266177.6431270\ttotal: 2.28s\tremaining: 5.42s\n",
      "296:\tlearn: 266175.2155901\ttotal: 2.28s\tremaining: 5.4s\n",
      "297:\tlearn: 266174.5487866\ttotal: 2.29s\tremaining: 5.38s\n",
      "298:\tlearn: 266172.4267518\ttotal: 2.29s\tremaining: 5.37s\n",
      "299:\tlearn: 266171.2222184\ttotal: 2.29s\tremaining: 5.35s\n",
      "300:\tlearn: 266168.8581362\ttotal: 2.3s\tremaining: 5.33s\n",
      "301:\tlearn: 266165.5166911\ttotal: 2.3s\tremaining: 5.32s\n",
      "302:\tlearn: 266165.0597500\ttotal: 2.3s\tremaining: 5.3s\n",
      "303:\tlearn: 266164.6296441\ttotal: 2.31s\tremaining: 5.29s\n",
      "304:\tlearn: 266162.3436780\ttotal: 2.31s\tremaining: 5.27s\n",
      "305:\tlearn: 266159.8843747\ttotal: 2.32s\tremaining: 5.26s\n",
      "306:\tlearn: 266159.4818234\ttotal: 2.32s\tremaining: 5.24s\n",
      "307:\tlearn: 266156.9756143\ttotal: 2.33s\tremaining: 5.22s\n",
      "308:\tlearn: 266153.9040987\ttotal: 2.33s\tremaining: 5.21s\n",
      "309:\tlearn: 266152.4306409\ttotal: 2.33s\tremaining: 5.19s\n",
      "310:\tlearn: 266150.4320632\ttotal: 2.34s\tremaining: 5.18s\n",
      "311:\tlearn: 266149.9224699\ttotal: 2.34s\tremaining: 5.17s\n",
      "312:\tlearn: 266148.3855984\ttotal: 2.35s\tremaining: 5.15s\n",
      "313:\tlearn: 266147.9183927\ttotal: 2.35s\tremaining: 5.14s\n",
      "314:\tlearn: 266147.5622807\ttotal: 2.36s\tremaining: 5.13s\n",
      "315:\tlearn: 266145.8426925\ttotal: 2.36s\tremaining: 5.11s\n",
      "316:\tlearn: 266143.9568638\ttotal: 2.36s\tremaining: 5.09s\n",
      "317:\tlearn: 266143.5329715\ttotal: 2.37s\tremaining: 5.08s\n",
      "318:\tlearn: 266143.2112080\ttotal: 2.37s\tremaining: 5.06s\n",
      "319:\tlearn: 266142.8273202\ttotal: 2.38s\tremaining: 5.05s\n",
      "320:\tlearn: 266141.2257562\ttotal: 2.38s\tremaining: 5.04s\n",
      "321:\tlearn: 266138.7535351\ttotal: 2.39s\tremaining: 5.02s\n",
      "322:\tlearn: 266136.7705414\ttotal: 2.4s\tremaining: 5.02s\n",
      "323:\tlearn: 266135.5600997\ttotal: 2.4s\tremaining: 5.01s\n",
      "324:\tlearn: 266135.1954927\ttotal: 2.4s\tremaining: 5s\n",
      "325:\tlearn: 266134.8514498\ttotal: 2.41s\tremaining: 4.99s\n",
      "326:\tlearn: 266132.4914831\ttotal: 2.41s\tremaining: 4.97s\n",
      "327:\tlearn: 266131.4554448\ttotal: 2.42s\tremaining: 4.95s\n",
      "328:\tlearn: 266130.9236180\ttotal: 2.42s\tremaining: 4.93s\n",
      "329:\tlearn: 266130.4219306\ttotal: 2.43s\tremaining: 4.93s\n",
      "330:\tlearn: 266129.8206823\ttotal: 2.43s\tremaining: 4.91s\n",
      "331:\tlearn: 266128.1342402\ttotal: 2.43s\tremaining: 4.89s\n",
      "332:\tlearn: 266126.5905985\ttotal: 2.43s\tremaining: 4.88s\n",
      "333:\tlearn: 266124.8733092\ttotal: 2.44s\tremaining: 4.87s\n",
      "334:\tlearn: 266123.4078652\ttotal: 2.44s\tremaining: 4.85s\n",
      "335:\tlearn: 266121.4890999\ttotal: 2.45s\tremaining: 4.84s\n",
      "336:\tlearn: 266119.4512942\ttotal: 2.45s\tremaining: 4.82s\n",
      "337:\tlearn: 266118.9084890\ttotal: 2.46s\tremaining: 4.82s\n",
      "338:\tlearn: 266117.1297603\ttotal: 2.47s\tremaining: 4.81s\n",
      "339:\tlearn: 266115.8705737\ttotal: 2.48s\tremaining: 4.81s\n",
      "340:\tlearn: 266114.5779228\ttotal: 2.49s\tremaining: 4.8s\n",
      "341:\tlearn: 266113.1474183\ttotal: 2.49s\tremaining: 4.8s\n",
      "342:\tlearn: 266112.8430284\ttotal: 2.5s\tremaining: 4.79s\n",
      "343:\tlearn: 266111.2643941\ttotal: 2.5s\tremaining: 4.77s\n",
      "344:\tlearn: 266109.7631995\ttotal: 2.51s\tremaining: 4.76s\n",
      "345:\tlearn: 266108.4470193\ttotal: 2.51s\tremaining: 4.74s\n",
      "346:\tlearn: 266107.9567551\ttotal: 2.51s\tremaining: 4.73s\n",
      "347:\tlearn: 266107.7249181\ttotal: 2.52s\tremaining: 4.72s\n",
      "348:\tlearn: 266107.5067449\ttotal: 2.52s\tremaining: 4.71s\n",
      "349:\tlearn: 266107.3013446\ttotal: 2.53s\tremaining: 4.7s\n",
      "350:\tlearn: 266107.0460887\ttotal: 2.54s\tremaining: 4.71s\n",
      "351:\tlearn: 266106.8598736\ttotal: 2.55s\tremaining: 4.7s\n",
      "352:\tlearn: 266105.4370830\ttotal: 2.56s\tremaining: 4.68s\n",
      "353:\tlearn: 266103.9818162\ttotal: 2.56s\tremaining: 4.67s\n",
      "354:\tlearn: 266102.8907968\ttotal: 2.57s\tremaining: 4.66s\n",
      "355:\tlearn: 266102.6541765\ttotal: 2.57s\tremaining: 4.65s\n",
      "356:\tlearn: 266102.4305257\ttotal: 2.58s\tremaining: 4.64s\n",
      "357:\tlearn: 266101.2720141\ttotal: 2.58s\tremaining: 4.63s\n",
      "358:\tlearn: 266100.1503282\ttotal: 2.63s\tremaining: 4.69s\n",
      "359:\tlearn: 266099.1222613\ttotal: 2.63s\tremaining: 4.68s\n",
      "360:\tlearn: 266098.9179730\ttotal: 2.65s\tremaining: 4.68s\n",
      "361:\tlearn: 266098.7250891\ttotal: 2.66s\tremaining: 4.69s\n",
      "362:\tlearn: 266098.5429356\ttotal: 2.67s\tremaining: 4.68s\n",
      "363:\tlearn: 266096.8998101\ttotal: 2.67s\tremaining: 4.67s\n",
      "364:\tlearn: 266095.9831209\ttotal: 2.67s\tremaining: 4.65s\n",
      "365:\tlearn: 266095.8151562\ttotal: 2.68s\tremaining: 4.64s\n",
      "366:\tlearn: 266095.6564822\ttotal: 2.7s\tremaining: 4.66s\n",
      "367:\tlearn: 266094.3850020\ttotal: 2.71s\tremaining: 4.65s\n",
      "368:\tlearn: 266093.3040651\ttotal: 2.71s\tremaining: 4.64s\n",
      "369:\tlearn: 266092.9805231\ttotal: 2.72s\tremaining: 4.63s\n",
      "370:\tlearn: 266092.6606786\ttotal: 2.72s\tremaining: 4.62s\n",
      "371:\tlearn: 266092.5132544\ttotal: 2.73s\tremaining: 4.61s\n",
      "372:\tlearn: 266092.3739101\ttotal: 2.74s\tremaining: 4.6s\n",
      "373:\tlearn: 266092.2421800\ttotal: 2.75s\tremaining: 4.6s\n",
      "374:\tlearn: 266091.9278322\ttotal: 2.75s\tremaining: 4.59s\n",
      "375:\tlearn: 266091.1779096\ttotal: 2.77s\tremaining: 4.59s\n",
      "376:\tlearn: 266090.9095751\ttotal: 2.77s\tremaining: 4.58s\n",
      "377:\tlearn: 266090.7893506\ttotal: 2.78s\tremaining: 4.57s\n",
      "378:\tlearn: 266089.5222339\ttotal: 2.78s\tremaining: 4.55s\n",
      "379:\tlearn: 266088.4307611\ttotal: 2.78s\tremaining: 4.54s\n",
      "380:\tlearn: 266087.2030552\ttotal: 2.79s\tremaining: 4.53s\n",
      "381:\tlearn: 266086.4537887\ttotal: 2.79s\tremaining: 4.52s\n",
      "382:\tlearn: 266085.4370167\ttotal: 2.8s\tremaining: 4.5s\n",
      "383:\tlearn: 266084.7478835\ttotal: 2.8s\tremaining: 4.49s\n",
      "384:\tlearn: 266083.6353729\ttotal: 2.81s\tremaining: 4.48s\n",
      "385:\tlearn: 266082.6162366\ttotal: 2.81s\tremaining: 4.47s\n",
      "386:\tlearn: 266081.8168236\ttotal: 2.81s\tremaining: 4.45s\n",
      "387:\tlearn: 266081.5659652\ttotal: 2.82s\tremaining: 4.44s\n",
      "388:\tlearn: 266081.3277385\ttotal: 2.82s\tremaining: 4.43s\n",
      "389:\tlearn: 266081.1014908\ttotal: 2.82s\tremaining: 4.42s\n",
      "390:\tlearn: 266080.9718592\ttotal: 2.83s\tremaining: 4.4s\n",
      "391:\tlearn: 266080.8506367\ttotal: 2.83s\tremaining: 4.39s\n",
      "392:\tlearn: 266080.7458847\ttotal: 2.83s\tremaining: 4.37s\n",
      "393:\tlearn: 266079.9339057\ttotal: 2.84s\tremaining: 4.36s\n",
      "394:\tlearn: 266079.6577892\ttotal: 2.84s\tremaining: 4.35s\n",
      "395:\tlearn: 266078.6406274\ttotal: 2.85s\tremaining: 4.34s\n",
      "396:\tlearn: 266078.5246923\ttotal: 2.85s\tremaining: 4.33s\n",
      "397:\tlearn: 266078.4442232\ttotal: 2.85s\tremaining: 4.32s\n",
      "398:\tlearn: 266077.6681510\ttotal: 2.86s\tremaining: 4.31s\n",
      "399:\tlearn: 266076.8452879\ttotal: 2.87s\tremaining: 4.31s\n",
      "400:\tlearn: 266076.6504165\ttotal: 2.88s\tremaining: 4.3s\n",
      "401:\tlearn: 266075.7668600\ttotal: 2.88s\tremaining: 4.29s\n",
      "402:\tlearn: 266075.6784255\ttotal: 2.88s\tremaining: 4.27s\n",
      "403:\tlearn: 266074.5906084\ttotal: 2.89s\tremaining: 4.26s\n",
      "404:\tlearn: 266073.4604148\ttotal: 2.89s\tremaining: 4.25s\n",
      "405:\tlearn: 266072.8019510\ttotal: 2.9s\tremaining: 4.24s\n",
      "406:\tlearn: 266072.1935225\ttotal: 2.9s\tremaining: 4.23s\n",
      "407:\tlearn: 266071.4123119\ttotal: 2.9s\tremaining: 4.21s\n",
      "408:\tlearn: 266070.6740771\ttotal: 2.91s\tremaining: 4.2s\n",
      "409:\tlearn: 266069.7603355\ttotal: 2.92s\tremaining: 4.2s\n",
      "410:\tlearn: 266068.9746212\ttotal: 2.92s\tremaining: 4.19s\n",
      "411:\tlearn: 266068.1726110\ttotal: 2.93s\tremaining: 4.18s\n",
      "412:\tlearn: 266067.5511148\ttotal: 2.93s\tremaining: 4.17s\n",
      "413:\tlearn: 266067.0031761\ttotal: 2.94s\tremaining: 4.16s\n",
      "414:\tlearn: 266066.0747220\ttotal: 2.94s\tremaining: 4.15s\n",
      "415:\tlearn: 266065.8873341\ttotal: 2.95s\tremaining: 4.14s\n",
      "416:\tlearn: 266065.2212200\ttotal: 2.95s\tremaining: 4.13s\n",
      "417:\tlearn: 266065.0137265\ttotal: 2.96s\tremaining: 4.12s\n",
      "418:\tlearn: 266064.1308453\ttotal: 2.96s\tremaining: 4.11s\n",
      "419:\tlearn: 266064.0011707\ttotal: 2.97s\tremaining: 4.1s\n",
      "420:\tlearn: 266063.2561210\ttotal: 2.97s\tremaining: 4.09s\n",
      "421:\tlearn: 266062.6553899\ttotal: 2.98s\tremaining: 4.08s\n",
      "422:\tlearn: 266062.1806908\ttotal: 2.99s\tremaining: 4.08s\n",
      "423:\tlearn: 266061.9865133\ttotal: 2.99s\tremaining: 4.06s\n",
      "424:\tlearn: 266061.1427022\ttotal: 3s\tremaining: 4.05s\n",
      "425:\tlearn: 266060.3676864\ttotal: 3s\tremaining: 4.05s\n",
      "426:\tlearn: 266059.6129380\ttotal: 3.01s\tremaining: 4.04s\n",
      "427:\tlearn: 266058.9070293\ttotal: 3.01s\tremaining: 4.02s\n",
      "428:\tlearn: 266058.2006764\ttotal: 3.01s\tremaining: 4.01s\n",
      "429:\tlearn: 266057.3266237\ttotal: 3.02s\tremaining: 4s\n",
      "430:\tlearn: 266056.6526965\ttotal: 3.02s\tremaining: 3.99s\n",
      "431:\tlearn: 266056.2045678\ttotal: 3.02s\tremaining: 3.98s\n",
      "432:\tlearn: 266055.5353816\ttotal: 3.03s\tremaining: 3.96s\n",
      "433:\tlearn: 266054.8260556\ttotal: 3.04s\tremaining: 3.96s\n",
      "434:\tlearn: 266054.4044062\ttotal: 3.04s\tremaining: 3.95s\n",
      "435:\tlearn: 266054.3364379\ttotal: 3.05s\tremaining: 3.95s\n",
      "436:\tlearn: 266053.6468365\ttotal: 3.06s\tremaining: 3.94s\n",
      "437:\tlearn: 266053.1592310\ttotal: 3.06s\tremaining: 3.93s\n",
      "438:\tlearn: 266053.0024202\ttotal: 3.07s\tremaining: 3.92s\n",
      "439:\tlearn: 266052.4148662\ttotal: 3.07s\tremaining: 3.91s\n",
      "440:\tlearn: 266052.2674578\ttotal: 3.07s\tremaining: 3.9s\n",
      "441:\tlearn: 266051.6217571\ttotal: 3.08s\tremaining: 3.88s\n",
      "442:\tlearn: 266051.4900691\ttotal: 3.08s\tremaining: 3.87s\n",
      "443:\tlearn: 266051.4233121\ttotal: 3.08s\tremaining: 3.86s\n",
      "444:\tlearn: 266051.2696953\ttotal: 3.09s\tremaining: 3.85s\n",
      "445:\tlearn: 266050.6748794\ttotal: 3.09s\tremaining: 3.84s\n",
      "446:\tlearn: 266050.3433861\ttotal: 3.09s\tremaining: 3.83s\n",
      "447:\tlearn: 266050.2115718\ttotal: 3.1s\tremaining: 3.82s\n",
      "448:\tlearn: 266050.0811294\ttotal: 3.1s\tremaining: 3.81s\n",
      "449:\tlearn: 266049.7382050\ttotal: 3.1s\tremaining: 3.79s\n",
      "450:\tlearn: 266049.2058351\ttotal: 3.11s\tremaining: 3.78s\n",
      "451:\tlearn: 266049.0756809\ttotal: 3.11s\tremaining: 3.77s\n",
      "452:\tlearn: 266048.6684295\ttotal: 3.12s\tremaining: 3.76s\n",
      "453:\tlearn: 266048.0730295\ttotal: 3.12s\tremaining: 3.75s\n",
      "454:\tlearn: 266047.9738854\ttotal: 3.13s\tremaining: 3.74s\n",
      "455:\tlearn: 266047.8885870\ttotal: 3.13s\tremaining: 3.73s\n",
      "456:\tlearn: 266047.2885892\ttotal: 3.13s\tremaining: 3.72s\n",
      "457:\tlearn: 266046.8010386\ttotal: 3.14s\tremaining: 3.71s\n",
      "458:\tlearn: 266046.3924072\ttotal: 3.14s\tremaining: 3.71s\n",
      "459:\tlearn: 266045.9694617\ttotal: 3.15s\tremaining: 3.7s\n",
      "460:\tlearn: 266045.2383775\ttotal: 3.15s\tremaining: 3.69s\n",
      "461:\tlearn: 266044.4996776\ttotal: 3.16s\tremaining: 3.68s\n",
      "462:\tlearn: 266044.1090199\ttotal: 3.17s\tremaining: 3.68s\n",
      "463:\tlearn: 266043.5309672\ttotal: 3.19s\tremaining: 3.68s\n",
      "464:\tlearn: 266042.8918651\ttotal: 3.19s\tremaining: 3.67s\n",
      "465:\tlearn: 266042.5746444\ttotal: 3.2s\tremaining: 3.66s\n",
      "466:\tlearn: 266041.9155508\ttotal: 3.2s\tremaining: 3.65s\n",
      "467:\tlearn: 266041.4843344\ttotal: 3.21s\tremaining: 3.64s\n",
      "468:\tlearn: 266041.0984873\ttotal: 3.21s\tremaining: 3.64s\n",
      "469:\tlearn: 266040.5408916\ttotal: 3.22s\tremaining: 3.63s\n",
      "470:\tlearn: 266040.0414525\ttotal: 3.22s\tremaining: 3.62s\n",
      "471:\tlearn: 266039.5514549\ttotal: 3.23s\tremaining: 3.61s\n",
      "472:\tlearn: 266039.2384312\ttotal: 3.23s\tremaining: 3.6s\n",
      "473:\tlearn: 266038.8289584\ttotal: 3.23s\tremaining: 3.59s\n",
      "474:\tlearn: 266038.5325971\ttotal: 3.24s\tremaining: 3.58s\n",
      "475:\tlearn: 266038.1897906\ttotal: 3.24s\tremaining: 3.56s\n",
      "476:\tlearn: 266037.7272819\ttotal: 3.24s\tremaining: 3.55s\n",
      "477:\tlearn: 266037.3627959\ttotal: 3.24s\tremaining: 3.54s\n",
      "478:\tlearn: 266036.8776248\ttotal: 3.25s\tremaining: 3.53s\n",
      "479:\tlearn: 266036.5642855\ttotal: 3.25s\tremaining: 3.52s\n",
      "480:\tlearn: 266036.2563757\ttotal: 3.25s\tremaining: 3.51s\n",
      "481:\tlearn: 266035.7782564\ttotal: 3.25s\tremaining: 3.5s\n",
      "482:\tlearn: 266035.3122211\ttotal: 3.26s\tremaining: 3.49s\n",
      "483:\tlearn: 266034.8631247\ttotal: 3.26s\tremaining: 3.48s\n",
      "484:\tlearn: 266034.5192228\ttotal: 3.27s\tremaining: 3.47s\n",
      "485:\tlearn: 266034.1676625\ttotal: 3.27s\tremaining: 3.46s\n",
      "486:\tlearn: 266033.8278277\ttotal: 3.27s\tremaining: 3.45s\n",
      "487:\tlearn: 266033.6449191\ttotal: 3.28s\tremaining: 3.44s\n",
      "488:\tlearn: 266033.5894258\ttotal: 3.28s\tremaining: 3.43s\n",
      "489:\tlearn: 266033.2176647\ttotal: 3.29s\tremaining: 3.42s\n",
      "490:\tlearn: 266032.7699185\ttotal: 3.29s\tremaining: 3.41s\n",
      "491:\tlearn: 266032.6829955\ttotal: 3.3s\tremaining: 3.4s\n",
      "492:\tlearn: 266032.5781199\ttotal: 3.3s\tremaining: 3.39s\n",
      "493:\tlearn: 266032.3863102\ttotal: 3.3s\tremaining: 3.38s\n",
      "494:\tlearn: 266032.0616544\ttotal: 3.3s\tremaining: 3.37s\n",
      "495:\tlearn: 266031.7197412\ttotal: 3.31s\tremaining: 3.36s\n",
      "496:\tlearn: 266031.3414324\ttotal: 3.31s\tremaining: 3.35s\n",
      "497:\tlearn: 266031.0605219\ttotal: 3.31s\tremaining: 3.34s\n",
      "498:\tlearn: 266030.7900035\ttotal: 3.32s\tremaining: 3.33s\n",
      "499:\tlearn: 266030.7425542\ttotal: 3.32s\tremaining: 3.32s\n",
      "500:\tlearn: 266030.6965180\ttotal: 3.32s\tremaining: 3.31s\n",
      "501:\tlearn: 266030.3950903\ttotal: 3.33s\tremaining: 3.3s\n",
      "502:\tlearn: 266030.1288791\ttotal: 3.33s\tremaining: 3.29s\n",
      "503:\tlearn: 266030.0345192\ttotal: 3.33s\tremaining: 3.28s\n",
      "504:\tlearn: 266029.7455826\ttotal: 3.34s\tremaining: 3.27s\n",
      "505:\tlearn: 266029.3947360\ttotal: 3.34s\tremaining: 3.26s\n",
      "506:\tlearn: 266029.0613677\ttotal: 3.35s\tremaining: 3.25s\n",
      "507:\tlearn: 266028.7599325\ttotal: 3.35s\tremaining: 3.24s\n",
      "508:\tlearn: 266028.4358512\ttotal: 3.35s\tremaining: 3.24s\n",
      "509:\tlearn: 266028.2209957\ttotal: 3.36s\tremaining: 3.23s\n",
      "510:\tlearn: 266027.9571377\ttotal: 3.36s\tremaining: 3.22s\n",
      "511:\tlearn: 266027.6007804\ttotal: 3.37s\tremaining: 3.21s\n",
      "512:\tlearn: 266027.2850230\ttotal: 3.37s\tremaining: 3.2s\n",
      "513:\tlearn: 266026.9948888\ttotal: 3.37s\tremaining: 3.19s\n",
      "514:\tlearn: 266026.7162603\ttotal: 3.38s\tremaining: 3.18s\n",
      "515:\tlearn: 266026.5118710\ttotal: 3.38s\tremaining: 3.17s\n",
      "516:\tlearn: 266026.4260473\ttotal: 3.38s\tremaining: 3.16s\n",
      "517:\tlearn: 266026.3378425\ttotal: 3.39s\tremaining: 3.15s\n",
      "518:\tlearn: 266025.9984261\ttotal: 3.39s\tremaining: 3.14s\n",
      "519:\tlearn: 266025.7236594\ttotal: 3.4s\tremaining: 3.13s\n",
      "520:\tlearn: 266025.5582053\ttotal: 3.4s\tremaining: 3.12s\n",
      "521:\tlearn: 266025.3790386\ttotal: 3.4s\tremaining: 3.12s\n",
      "522:\tlearn: 266025.1216596\ttotal: 3.41s\tremaining: 3.11s\n",
      "523:\tlearn: 266024.7262601\ttotal: 3.41s\tremaining: 3.1s\n",
      "524:\tlearn: 266024.6545957\ttotal: 3.42s\tremaining: 3.1s\n",
      "525:\tlearn: 266024.4478038\ttotal: 3.42s\tremaining: 3.09s\n",
      "526:\tlearn: 266024.2892835\ttotal: 3.43s\tremaining: 3.08s\n",
      "527:\tlearn: 266024.0602941\ttotal: 3.43s\tremaining: 3.07s\n",
      "528:\tlearn: 266023.6571144\ttotal: 3.44s\tremaining: 3.06s\n",
      "529:\tlearn: 266023.4016659\ttotal: 3.44s\tremaining: 3.05s\n",
      "530:\tlearn: 266023.1789345\ttotal: 3.44s\tremaining: 3.04s\n",
      "531:\tlearn: 266023.1364486\ttotal: 3.44s\tremaining: 3.03s\n",
      "532:\tlearn: 266022.8878730\ttotal: 3.44s\tremaining: 3.02s\n",
      "533:\tlearn: 266022.7582500\ttotal: 3.45s\tremaining: 3.01s\n",
      "534:\tlearn: 266022.5216673\ttotal: 3.54s\tremaining: 3.08s\n",
      "535:\tlearn: 266022.3838722\ttotal: 3.56s\tremaining: 3.09s\n",
      "536:\tlearn: 266022.1329867\ttotal: 3.6s\tremaining: 3.1s\n",
      "537:\tlearn: 266022.0698910\ttotal: 3.6s\tremaining: 3.1s\n",
      "538:\tlearn: 266021.9077952\ttotal: 3.61s\tremaining: 3.09s\n",
      "539:\tlearn: 266021.8424597\ttotal: 3.62s\tremaining: 3.08s\n",
      "540:\tlearn: 266021.7874185\ttotal: 3.62s\tremaining: 3.07s\n",
      "541:\tlearn: 266021.6148427\ttotal: 3.63s\tremaining: 3.07s\n",
      "542:\tlearn: 266021.3497706\ttotal: 3.63s\tremaining: 3.06s\n",
      "543:\tlearn: 266021.0878420\ttotal: 3.64s\tremaining: 3.05s\n",
      "544:\tlearn: 266020.7632942\ttotal: 3.65s\tremaining: 3.04s\n",
      "545:\tlearn: 266020.4997844\ttotal: 3.65s\tremaining: 3.03s\n",
      "546:\tlearn: 266020.2672514\ttotal: 3.65s\tremaining: 3.02s\n",
      "547:\tlearn: 266020.1160983\ttotal: 3.66s\tremaining: 3.02s\n",
      "548:\tlearn: 266019.7916013\ttotal: 3.67s\tremaining: 3.01s\n",
      "549:\tlearn: 266019.6355820\ttotal: 3.67s\tremaining: 3s\n",
      "550:\tlearn: 266019.3728926\ttotal: 3.68s\tremaining: 3s\n",
      "551:\tlearn: 266019.0971690\ttotal: 3.68s\tremaining: 2.99s\n",
      "552:\tlearn: 266018.9206779\ttotal: 3.69s\tremaining: 2.98s\n",
      "553:\tlearn: 266018.6273950\ttotal: 3.69s\tremaining: 2.97s\n",
      "554:\tlearn: 266018.3828152\ttotal: 3.7s\tremaining: 2.96s\n",
      "555:\tlearn: 266018.3272427\ttotal: 3.7s\tremaining: 2.96s\n",
      "556:\tlearn: 266018.0884727\ttotal: 3.71s\tremaining: 2.95s\n",
      "557:\tlearn: 266017.8680965\ttotal: 3.71s\tremaining: 2.94s\n",
      "558:\tlearn: 266017.6024323\ttotal: 3.72s\tremaining: 2.93s\n",
      "559:\tlearn: 266017.3985935\ttotal: 3.72s\tremaining: 2.92s\n",
      "560:\tlearn: 266017.3511876\ttotal: 3.73s\tremaining: 2.92s\n",
      "561:\tlearn: 266017.1166156\ttotal: 3.73s\tremaining: 2.91s\n",
      "562:\tlearn: 266016.8091999\ttotal: 3.73s\tremaining: 2.9s\n",
      "563:\tlearn: 266016.5653778\ttotal: 3.74s\tremaining: 2.89s\n",
      "564:\tlearn: 266016.3458139\ttotal: 3.74s\tremaining: 2.88s\n",
      "565:\tlearn: 266016.1112490\ttotal: 3.75s\tremaining: 2.87s\n",
      "566:\tlearn: 266015.8832476\ttotal: 3.75s\tremaining: 2.86s\n",
      "567:\tlearn: 266015.6686846\ttotal: 3.75s\tremaining: 2.85s\n",
      "568:\tlearn: 266015.6265332\ttotal: 3.76s\tremaining: 2.85s\n",
      "569:\tlearn: 266015.3596029\ttotal: 3.76s\tremaining: 2.84s\n",
      "570:\tlearn: 266015.1958225\ttotal: 3.76s\tremaining: 2.83s\n",
      "571:\tlearn: 266014.9991629\ttotal: 3.77s\tremaining: 2.82s\n",
      "572:\tlearn: 266014.7132904\ttotal: 3.77s\tremaining: 2.81s\n",
      "573:\tlearn: 266014.5166489\ttotal: 3.78s\tremaining: 2.8s\n",
      "574:\tlearn: 266014.2745079\ttotal: 3.78s\tremaining: 2.79s\n",
      "575:\tlearn: 266014.2336872\ttotal: 3.78s\tremaining: 2.79s\n",
      "576:\tlearn: 266014.0911944\ttotal: 3.79s\tremaining: 2.78s\n",
      "577:\tlearn: 266013.9054754\ttotal: 3.79s\tremaining: 2.77s\n",
      "578:\tlearn: 266013.7459837\ttotal: 3.79s\tremaining: 2.76s\n",
      "579:\tlearn: 266013.5935927\ttotal: 3.8s\tremaining: 2.75s\n",
      "580:\tlearn: 266013.4251418\ttotal: 3.81s\tremaining: 2.75s\n",
      "581:\tlearn: 266013.3425754\ttotal: 3.82s\tremaining: 2.74s\n",
      "582:\tlearn: 266013.2671220\ttotal: 3.82s\tremaining: 2.73s\n",
      "583:\tlearn: 266013.0208393\ttotal: 3.83s\tremaining: 2.73s\n",
      "584:\tlearn: 266012.8341825\ttotal: 3.83s\tremaining: 2.72s\n",
      "585:\tlearn: 266012.7964572\ttotal: 3.84s\tremaining: 2.71s\n",
      "586:\tlearn: 266012.6499931\ttotal: 3.85s\tremaining: 2.71s\n",
      "587:\tlearn: 266012.5031264\ttotal: 3.85s\tremaining: 2.7s\n",
      "588:\tlearn: 266012.2947643\ttotal: 3.86s\tremaining: 2.69s\n",
      "589:\tlearn: 266012.1348843\ttotal: 3.86s\tremaining: 2.69s\n",
      "590:\tlearn: 266012.0908440\ttotal: 3.87s\tremaining: 2.68s\n",
      "591:\tlearn: 266011.9609900\ttotal: 3.87s\tremaining: 2.67s\n",
      "592:\tlearn: 266011.7827857\ttotal: 3.88s\tremaining: 2.66s\n",
      "593:\tlearn: 266011.5729562\ttotal: 3.88s\tremaining: 2.66s\n",
      "594:\tlearn: 266011.3925259\ttotal: 3.89s\tremaining: 2.65s\n",
      "595:\tlearn: 266011.1620605\ttotal: 3.89s\tremaining: 2.64s\n",
      "596:\tlearn: 266010.8898622\ttotal: 3.9s\tremaining: 2.63s\n",
      "597:\tlearn: 266010.6910819\ttotal: 3.9s\tremaining: 2.62s\n",
      "598:\tlearn: 266010.5105227\ttotal: 3.9s\tremaining: 2.61s\n",
      "599:\tlearn: 266010.3421201\ttotal: 3.91s\tremaining: 2.6s\n",
      "600:\tlearn: 266010.2580685\ttotal: 3.91s\tremaining: 2.6s\n",
      "601:\tlearn: 266010.0821049\ttotal: 3.92s\tremaining: 2.59s\n",
      "602:\tlearn: 266009.9354088\ttotal: 3.92s\tremaining: 2.58s\n",
      "603:\tlearn: 266009.9101572\ttotal: 3.92s\tremaining: 2.57s\n",
      "604:\tlearn: 266009.8605203\ttotal: 3.93s\tremaining: 2.56s\n",
      "605:\tlearn: 266009.6143225\ttotal: 3.93s\tremaining: 2.56s\n",
      "606:\tlearn: 266009.3925007\ttotal: 3.93s\tremaining: 2.55s\n",
      "607:\tlearn: 266009.2619959\ttotal: 3.94s\tremaining: 2.54s\n",
      "608:\tlearn: 266009.0646858\ttotal: 3.94s\tremaining: 2.53s\n",
      "609:\tlearn: 266008.9548973\ttotal: 3.94s\tremaining: 2.52s\n",
      "610:\tlearn: 266008.8640629\ttotal: 3.95s\tremaining: 2.51s\n",
      "611:\tlearn: 266008.6647258\ttotal: 3.95s\tremaining: 2.5s\n",
      "612:\tlearn: 266008.6375227\ttotal: 3.95s\tremaining: 2.5s\n",
      "613:\tlearn: 266008.4931220\ttotal: 3.96s\tremaining: 2.49s\n",
      "614:\tlearn: 266008.3825202\ttotal: 3.96s\tremaining: 2.48s\n",
      "615:\tlearn: 266008.1839018\ttotal: 3.96s\tremaining: 2.47s\n",
      "616:\tlearn: 266008.0071770\ttotal: 3.97s\tremaining: 2.46s\n",
      "617:\tlearn: 266007.8321448\ttotal: 3.97s\tremaining: 2.45s\n",
      "618:\tlearn: 266007.7039018\ttotal: 3.98s\tremaining: 2.45s\n",
      "619:\tlearn: 266007.5443208\ttotal: 3.98s\tremaining: 2.44s\n",
      "620:\tlearn: 266007.3835934\ttotal: 3.98s\tremaining: 2.43s\n",
      "621:\tlearn: 266007.2242957\ttotal: 3.99s\tremaining: 2.42s\n",
      "622:\tlearn: 266007.1178521\ttotal: 3.99s\tremaining: 2.42s\n",
      "623:\tlearn: 266007.0452475\ttotal: 4s\tremaining: 2.41s\n",
      "624:\tlearn: 266007.0233124\ttotal: 4s\tremaining: 2.4s\n",
      "625:\tlearn: 266006.9521133\ttotal: 4.01s\tremaining: 2.39s\n",
      "626:\tlearn: 266006.8023698\ttotal: 4.01s\tremaining: 2.38s\n",
      "627:\tlearn: 266006.6563451\ttotal: 4.01s\tremaining: 2.38s\n",
      "628:\tlearn: 266006.4787278\ttotal: 4.02s\tremaining: 2.37s\n",
      "629:\tlearn: 266006.4034755\ttotal: 4.02s\tremaining: 2.36s\n",
      "630:\tlearn: 266006.2428858\ttotal: 4.03s\tremaining: 2.35s\n",
      "631:\tlearn: 266006.1131730\ttotal: 4.03s\tremaining: 2.35s\n",
      "632:\tlearn: 266006.0137776\ttotal: 4.03s\tremaining: 2.34s\n",
      "633:\tlearn: 266005.8675388\ttotal: 4.04s\tremaining: 2.33s\n",
      "634:\tlearn: 266005.7712364\ttotal: 4.04s\tremaining: 2.32s\n",
      "635:\tlearn: 266005.7000780\ttotal: 4.04s\tremaining: 2.31s\n",
      "636:\tlearn: 266005.5701587\ttotal: 4.05s\tremaining: 2.31s\n",
      "637:\tlearn: 266005.3941169\ttotal: 4.05s\tremaining: 2.3s\n",
      "638:\tlearn: 266005.2875873\ttotal: 4.05s\tremaining: 2.29s\n",
      "639:\tlearn: 266005.1179439\ttotal: 4.06s\tremaining: 2.28s\n",
      "640:\tlearn: 266004.9684456\ttotal: 4.06s\tremaining: 2.27s\n",
      "641:\tlearn: 266004.9484573\ttotal: 4.07s\tremaining: 2.27s\n",
      "642:\tlearn: 266004.8015048\ttotal: 4.07s\tremaining: 2.26s\n",
      "643:\tlearn: 266004.6552234\ttotal: 4.07s\tremaining: 2.25s\n",
      "644:\tlearn: 266004.5148918\ttotal: 4.08s\tremaining: 2.24s\n",
      "645:\tlearn: 266004.4075660\ttotal: 4.08s\tremaining: 2.23s\n",
      "646:\tlearn: 266004.3165913\ttotal: 4.08s\tremaining: 2.23s\n",
      "647:\tlearn: 266004.1960337\ttotal: 4.09s\tremaining: 2.22s\n",
      "648:\tlearn: 266004.0630373\ttotal: 4.09s\tremaining: 2.21s\n",
      "649:\tlearn: 266004.0090408\ttotal: 4.09s\tremaining: 2.2s\n",
      "650:\tlearn: 266003.8672423\ttotal: 4.1s\tremaining: 2.2s\n",
      "651:\tlearn: 266003.8521740\ttotal: 4.1s\tremaining: 2.19s\n",
      "652:\tlearn: 266003.8292277\ttotal: 4.1s\tremaining: 2.18s\n",
      "653:\tlearn: 266003.8056653\ttotal: 4.1s\tremaining: 2.17s\n",
      "654:\tlearn: 266003.7559272\ttotal: 4.11s\tremaining: 2.17s\n",
      "655:\tlearn: 266003.7337055\ttotal: 4.12s\tremaining: 2.16s\n",
      "656:\tlearn: 266003.7176661\ttotal: 4.12s\tremaining: 2.15s\n",
      "657:\tlearn: 266003.7042282\ttotal: 4.12s\tremaining: 2.14s\n",
      "658:\tlearn: 266003.6353025\ttotal: 4.13s\tremaining: 2.13s\n",
      "659:\tlearn: 266003.5089195\ttotal: 4.13s\tremaining: 2.13s\n",
      "660:\tlearn: 266003.4129512\ttotal: 4.13s\tremaining: 2.12s\n",
      "661:\tlearn: 266003.3922968\ttotal: 4.13s\tremaining: 2.11s\n",
      "662:\tlearn: 266003.2480626\ttotal: 4.14s\tremaining: 2.1s\n",
      "663:\tlearn: 266003.1133882\ttotal: 4.14s\tremaining: 2.1s\n",
      "664:\tlearn: 266002.9903501\ttotal: 4.14s\tremaining: 2.09s\n",
      "665:\tlearn: 266002.8489541\ttotal: 4.15s\tremaining: 2.08s\n",
      "666:\tlearn: 266002.6720900\ttotal: 4.15s\tremaining: 2.07s\n",
      "667:\tlearn: 266002.6610538\ttotal: 4.16s\tremaining: 2.06s\n",
      "668:\tlearn: 266002.6497076\ttotal: 4.16s\tremaining: 2.06s\n",
      "669:\tlearn: 266002.6320970\ttotal: 4.16s\tremaining: 2.05s\n",
      "670:\tlearn: 266002.5231689\ttotal: 4.17s\tremaining: 2.04s\n",
      "671:\tlearn: 266002.4536293\ttotal: 4.17s\tremaining: 2.04s\n",
      "672:\tlearn: 266002.4424411\ttotal: 4.17s\tremaining: 2.03s\n",
      "673:\tlearn: 266002.4247379\ttotal: 4.17s\tremaining: 2.02s\n",
      "674:\tlearn: 266002.4064244\ttotal: 4.18s\tremaining: 2.01s\n",
      "675:\tlearn: 266002.2945582\ttotal: 4.19s\tremaining: 2.01s\n",
      "676:\tlearn: 266002.2782236\ttotal: 4.19s\tremaining: 2s\n",
      "677:\tlearn: 266002.2130192\ttotal: 4.19s\tremaining: 1.99s\n",
      "678:\tlearn: 266002.1565748\ttotal: 4.2s\tremaining: 1.98s\n",
      "679:\tlearn: 266002.0966398\ttotal: 4.2s\tremaining: 1.98s\n",
      "680:\tlearn: 266001.9615185\ttotal: 4.2s\tremaining: 1.97s\n",
      "681:\tlearn: 266001.8356682\ttotal: 4.21s\tremaining: 1.96s\n",
      "682:\tlearn: 266001.7564468\ttotal: 4.21s\tremaining: 1.96s\n",
      "683:\tlearn: 266001.6654869\ttotal: 4.22s\tremaining: 1.95s\n",
      "684:\tlearn: 266001.5496687\ttotal: 4.22s\tremaining: 1.94s\n",
      "685:\tlearn: 266001.4273782\ttotal: 4.23s\tremaining: 1.93s\n",
      "686:\tlearn: 266001.3443975\ttotal: 4.23s\tremaining: 1.93s\n",
      "687:\tlearn: 266001.2294039\ttotal: 4.23s\tremaining: 1.92s\n",
      "688:\tlearn: 266001.1300220\ttotal: 4.24s\tremaining: 1.91s\n",
      "689:\tlearn: 266001.0506000\ttotal: 4.24s\tremaining: 1.91s\n",
      "690:\tlearn: 266001.0108012\ttotal: 4.25s\tremaining: 1.9s\n",
      "691:\tlearn: 266000.9959326\ttotal: 4.25s\tremaining: 1.89s\n",
      "692:\tlearn: 266000.9088755\ttotal: 4.26s\tremaining: 1.89s\n",
      "693:\tlearn: 266000.7780716\ttotal: 4.26s\tremaining: 1.88s\n",
      "694:\tlearn: 266000.6630298\ttotal: 4.26s\tremaining: 1.87s\n",
      "695:\tlearn: 266000.5903715\ttotal: 4.27s\tremaining: 1.86s\n",
      "696:\tlearn: 266000.4933874\ttotal: 4.31s\tremaining: 1.87s\n",
      "697:\tlearn: 266000.4046206\ttotal: 4.32s\tremaining: 1.87s\n",
      "698:\tlearn: 266000.3415897\ttotal: 4.33s\tremaining: 1.86s\n",
      "699:\tlearn: 266000.2109189\ttotal: 4.34s\tremaining: 1.86s\n",
      "700:\tlearn: 266000.0664197\ttotal: 4.34s\tremaining: 1.85s\n",
      "701:\tlearn: 265999.9459642\ttotal: 4.35s\tremaining: 1.85s\n",
      "702:\tlearn: 265999.8308338\ttotal: 4.35s\tremaining: 1.84s\n",
      "703:\tlearn: 265999.7751752\ttotal: 4.36s\tremaining: 1.83s\n",
      "704:\tlearn: 265999.6743375\ttotal: 4.37s\tremaining: 1.83s\n",
      "705:\tlearn: 265999.6605910\ttotal: 4.38s\tremaining: 1.82s\n",
      "706:\tlearn: 265999.6085301\ttotal: 4.38s\tremaining: 1.81s\n",
      "707:\tlearn: 265999.5525586\ttotal: 4.38s\tremaining: 1.81s\n",
      "708:\tlearn: 265999.5446527\ttotal: 4.39s\tremaining: 1.8s\n",
      "709:\tlearn: 265999.4695165\ttotal: 4.39s\tremaining: 1.79s\n",
      "710:\tlearn: 265999.4140316\ttotal: 4.39s\tremaining: 1.79s\n",
      "711:\tlearn: 265999.3825145\ttotal: 4.4s\tremaining: 1.78s\n",
      "712:\tlearn: 265999.3581972\ttotal: 4.4s\tremaining: 1.77s\n",
      "713:\tlearn: 265999.3461010\ttotal: 4.41s\tremaining: 1.76s\n",
      "714:\tlearn: 265999.2259429\ttotal: 4.41s\tremaining: 1.76s\n",
      "715:\tlearn: 265999.2188508\ttotal: 4.41s\tremaining: 1.75s\n",
      "716:\tlearn: 265999.2121376\ttotal: 4.42s\tremaining: 1.74s\n",
      "717:\tlearn: 265999.1020578\ttotal: 4.42s\tremaining: 1.74s\n",
      "718:\tlearn: 265999.0943807\ttotal: 4.43s\tremaining: 1.73s\n",
      "719:\tlearn: 265999.0838767\ttotal: 4.43s\tremaining: 1.72s\n",
      "720:\tlearn: 265998.9957843\ttotal: 4.44s\tremaining: 1.72s\n",
      "721:\tlearn: 265998.8853810\ttotal: 4.44s\tremaining: 1.71s\n",
      "722:\tlearn: 265998.8754114\ttotal: 4.45s\tremaining: 1.7s\n",
      "723:\tlearn: 265998.8688973\ttotal: 4.45s\tremaining: 1.7s\n",
      "724:\tlearn: 265998.8637438\ttotal: 4.46s\tremaining: 1.69s\n",
      "725:\tlearn: 265998.7844533\ttotal: 4.47s\tremaining: 1.69s\n",
      "726:\tlearn: 265998.7007682\ttotal: 4.47s\tremaining: 1.68s\n",
      "727:\tlearn: 265998.5908158\ttotal: 4.48s\tremaining: 1.67s\n",
      "728:\tlearn: 265998.4839032\ttotal: 4.48s\tremaining: 1.66s\n",
      "729:\tlearn: 265998.3976363\ttotal: 4.48s\tremaining: 1.66s\n",
      "730:\tlearn: 265998.3254391\ttotal: 4.49s\tremaining: 1.65s\n",
      "731:\tlearn: 265998.2742820\ttotal: 4.49s\tremaining: 1.64s\n",
      "732:\tlearn: 265998.2499943\ttotal: 4.49s\tremaining: 1.64s\n",
      "733:\tlearn: 265998.1927926\ttotal: 4.5s\tremaining: 1.63s\n",
      "734:\tlearn: 265998.1030471\ttotal: 4.5s\tremaining: 1.62s\n",
      "735:\tlearn: 265998.0302876\ttotal: 4.5s\tremaining: 1.61s\n",
      "736:\tlearn: 265997.9481572\ttotal: 4.51s\tremaining: 1.61s\n",
      "737:\tlearn: 265997.8488030\ttotal: 4.51s\tremaining: 1.6s\n",
      "738:\tlearn: 265997.7339494\ttotal: 4.52s\tremaining: 1.59s\n",
      "739:\tlearn: 265997.6719186\ttotal: 4.52s\tremaining: 1.59s\n",
      "740:\tlearn: 265997.6130197\ttotal: 4.52s\tremaining: 1.58s\n",
      "741:\tlearn: 265997.4937242\ttotal: 4.52s\tremaining: 1.57s\n",
      "742:\tlearn: 265997.4010898\ttotal: 4.53s\tremaining: 1.57s\n",
      "743:\tlearn: 265997.3310817\ttotal: 4.53s\tremaining: 1.56s\n",
      "744:\tlearn: 265997.2564431\ttotal: 4.54s\tremaining: 1.55s\n",
      "745:\tlearn: 265997.1968005\ttotal: 4.54s\tremaining: 1.54s\n",
      "746:\tlearn: 265997.1047941\ttotal: 4.54s\tremaining: 1.54s\n",
      "747:\tlearn: 265997.0187176\ttotal: 4.55s\tremaining: 1.53s\n",
      "748:\tlearn: 265996.9569242\ttotal: 4.55s\tremaining: 1.52s\n",
      "749:\tlearn: 265996.8980694\ttotal: 4.55s\tremaining: 1.52s\n",
      "750:\tlearn: 265996.8198593\ttotal: 4.55s\tremaining: 1.51s\n",
      "751:\tlearn: 265996.7175377\ttotal: 4.56s\tremaining: 1.5s\n",
      "752:\tlearn: 265996.6282130\ttotal: 4.56s\tremaining: 1.5s\n",
      "753:\tlearn: 265996.5530061\ttotal: 4.57s\tremaining: 1.49s\n",
      "754:\tlearn: 265996.4658595\ttotal: 4.57s\tremaining: 1.48s\n",
      "755:\tlearn: 265996.4075768\ttotal: 4.57s\tremaining: 1.48s\n",
      "756:\tlearn: 265996.3311740\ttotal: 4.58s\tremaining: 1.47s\n",
      "757:\tlearn: 265996.2671383\ttotal: 4.58s\tremaining: 1.46s\n",
      "758:\tlearn: 265996.1890307\ttotal: 4.58s\tremaining: 1.45s\n",
      "759:\tlearn: 265996.1014881\ttotal: 4.58s\tremaining: 1.45s\n",
      "760:\tlearn: 265996.0266049\ttotal: 4.59s\tremaining: 1.44s\n",
      "761:\tlearn: 265995.9259956\ttotal: 4.59s\tremaining: 1.44s\n",
      "762:\tlearn: 265995.8474924\ttotal: 4.6s\tremaining: 1.43s\n",
      "763:\tlearn: 265995.8084503\ttotal: 4.6s\tremaining: 1.42s\n",
      "764:\tlearn: 265995.7624384\ttotal: 4.61s\tremaining: 1.42s\n",
      "765:\tlearn: 265995.6865880\ttotal: 4.61s\tremaining: 1.41s\n",
      "766:\tlearn: 265995.6181217\ttotal: 4.62s\tremaining: 1.4s\n",
      "767:\tlearn: 265995.5537768\ttotal: 4.62s\tremaining: 1.4s\n",
      "768:\tlearn: 265995.5102864\ttotal: 4.62s\tremaining: 1.39s\n",
      "769:\tlearn: 265995.4499438\ttotal: 4.63s\tremaining: 1.38s\n",
      "770:\tlearn: 265995.3884830\ttotal: 4.63s\tremaining: 1.38s\n",
      "771:\tlearn: 265995.3827153\ttotal: 4.63s\tremaining: 1.37s\n",
      "772:\tlearn: 265995.3305611\ttotal: 4.64s\tremaining: 1.36s\n",
      "773:\tlearn: 265995.2917065\ttotal: 4.64s\tremaining: 1.35s\n",
      "774:\tlearn: 265995.2836898\ttotal: 4.65s\tremaining: 1.35s\n",
      "775:\tlearn: 265995.2761835\ttotal: 4.65s\tremaining: 1.34s\n",
      "776:\tlearn: 265995.1937049\ttotal: 4.66s\tremaining: 1.34s\n",
      "777:\tlearn: 265995.1274585\ttotal: 4.66s\tremaining: 1.33s\n",
      "778:\tlearn: 265995.1161318\ttotal: 4.66s\tremaining: 1.32s\n",
      "779:\tlearn: 265995.0791534\ttotal: 4.67s\tremaining: 1.32s\n",
      "780:\tlearn: 265995.0077305\ttotal: 4.67s\tremaining: 1.31s\n",
      "781:\tlearn: 265994.9259731\ttotal: 4.67s\tremaining: 1.3s\n",
      "782:\tlearn: 265994.8793363\ttotal: 4.68s\tremaining: 1.3s\n",
      "783:\tlearn: 265994.8169087\ttotal: 4.68s\tremaining: 1.29s\n",
      "784:\tlearn: 265994.7789114\ttotal: 4.69s\tremaining: 1.28s\n",
      "785:\tlearn: 265994.7180710\ttotal: 4.69s\tremaining: 1.28s\n",
      "786:\tlearn: 265994.6343291\ttotal: 4.69s\tremaining: 1.27s\n",
      "787:\tlearn: 265994.5608995\ttotal: 4.69s\tremaining: 1.26s\n",
      "788:\tlearn: 265994.5256302\ttotal: 4.7s\tremaining: 1.26s\n",
      "789:\tlearn: 265994.5130457\ttotal: 4.7s\tremaining: 1.25s\n",
      "790:\tlearn: 265994.5090591\ttotal: 4.7s\tremaining: 1.24s\n",
      "791:\tlearn: 265994.5026217\ttotal: 4.71s\tremaining: 1.24s\n",
      "792:\tlearn: 265994.4408295\ttotal: 4.71s\tremaining: 1.23s\n",
      "793:\tlearn: 265994.3684667\ttotal: 4.72s\tremaining: 1.22s\n",
      "794:\tlearn: 265994.3164647\ttotal: 4.72s\tremaining: 1.22s\n",
      "795:\tlearn: 265994.2783684\ttotal: 4.72s\tremaining: 1.21s\n",
      "796:\tlearn: 265994.2489657\ttotal: 4.72s\tremaining: 1.2s\n",
      "797:\tlearn: 265994.1783354\ttotal: 4.73s\tremaining: 1.2s\n",
      "798:\tlearn: 265994.1721395\ttotal: 4.73s\tremaining: 1.19s\n",
      "799:\tlearn: 265994.1110100\ttotal: 4.73s\tremaining: 1.18s\n",
      "800:\tlearn: 265994.1034471\ttotal: 4.74s\tremaining: 1.18s\n",
      "801:\tlearn: 265994.0483020\ttotal: 4.74s\tremaining: 1.17s\n",
      "802:\tlearn: 265993.9883687\ttotal: 4.74s\tremaining: 1.16s\n",
      "803:\tlearn: 265993.9535666\ttotal: 4.75s\tremaining: 1.16s\n",
      "804:\tlearn: 265993.9254467\ttotal: 4.75s\tremaining: 1.15s\n",
      "805:\tlearn: 265993.8711024\ttotal: 4.75s\tremaining: 1.14s\n",
      "806:\tlearn: 265993.8398921\ttotal: 4.75s\tremaining: 1.14s\n",
      "807:\tlearn: 265993.7884562\ttotal: 4.76s\tremaining: 1.13s\n",
      "808:\tlearn: 265993.7310371\ttotal: 4.76s\tremaining: 1.12s\n",
      "809:\tlearn: 265993.7011504\ttotal: 4.76s\tremaining: 1.12s\n",
      "810:\tlearn: 265993.6654677\ttotal: 4.77s\tremaining: 1.11s\n",
      "811:\tlearn: 265993.6055649\ttotal: 4.77s\tremaining: 1.1s\n",
      "812:\tlearn: 265993.5597121\ttotal: 4.78s\tremaining: 1.1s\n",
      "813:\tlearn: 265993.5128880\ttotal: 4.78s\tremaining: 1.09s\n",
      "814:\tlearn: 265993.4839189\ttotal: 4.79s\tremaining: 1.09s\n",
      "815:\tlearn: 265993.4305318\ttotal: 4.8s\tremaining: 1.08s\n",
      "816:\tlearn: 265993.3849145\ttotal: 4.8s\tremaining: 1.07s\n",
      "817:\tlearn: 265993.3018604\ttotal: 4.8s\tremaining: 1.07s\n",
      "818:\tlearn: 265993.2919658\ttotal: 4.81s\tremaining: 1.06s\n",
      "819:\tlearn: 265993.2841171\ttotal: 4.81s\tremaining: 1.06s\n",
      "820:\tlearn: 265993.2349156\ttotal: 4.82s\tremaining: 1.05s\n",
      "821:\tlearn: 265993.1795705\ttotal: 4.82s\tremaining: 1.04s\n",
      "822:\tlearn: 265993.1279924\ttotal: 4.83s\tremaining: 1.04s\n",
      "823:\tlearn: 265993.0671976\ttotal: 4.83s\tremaining: 1.03s\n",
      "824:\tlearn: 265992.9988337\ttotal: 4.83s\tremaining: 1.02s\n",
      "825:\tlearn: 265992.9450803\ttotal: 4.84s\tremaining: 1.02s\n",
      "826:\tlearn: 265992.8971449\ttotal: 4.84s\tremaining: 1.01s\n",
      "827:\tlearn: 265992.8556295\ttotal: 4.85s\tremaining: 1.01s\n",
      "828:\tlearn: 265992.7971375\ttotal: 4.86s\tremaining: 1s\n",
      "829:\tlearn: 265992.7412881\ttotal: 4.86s\tremaining: 996ms\n",
      "830:\tlearn: 265992.6913312\ttotal: 4.87s\tremaining: 990ms\n",
      "831:\tlearn: 265992.6180452\ttotal: 4.87s\tremaining: 984ms\n",
      "832:\tlearn: 265992.5744747\ttotal: 4.88s\tremaining: 978ms\n",
      "833:\tlearn: 265992.5175253\ttotal: 4.88s\tremaining: 971ms\n",
      "834:\tlearn: 265992.4777769\ttotal: 4.88s\tremaining: 965ms\n",
      "835:\tlearn: 265992.4225180\ttotal: 4.89s\tremaining: 959ms\n",
      "836:\tlearn: 265992.4190982\ttotal: 4.89s\tremaining: 952ms\n",
      "837:\tlearn: 265992.3705388\ttotal: 4.89s\tremaining: 946ms\n",
      "838:\tlearn: 265992.3669279\ttotal: 4.89s\tremaining: 939ms\n",
      "839:\tlearn: 265992.3229326\ttotal: 4.9s\tremaining: 933ms\n",
      "840:\tlearn: 265992.2757047\ttotal: 4.9s\tremaining: 927ms\n",
      "841:\tlearn: 265992.2247160\ttotal: 4.91s\tremaining: 921ms\n",
      "842:\tlearn: 265992.1848197\ttotal: 4.91s\tremaining: 914ms\n",
      "843:\tlearn: 265992.1634317\ttotal: 4.91s\tremaining: 908ms\n",
      "844:\tlearn: 265992.1203005\ttotal: 4.92s\tremaining: 902ms\n",
      "845:\tlearn: 265992.0454719\ttotal: 4.92s\tremaining: 896ms\n",
      "846:\tlearn: 265992.0423713\ttotal: 4.92s\tremaining: 889ms\n",
      "847:\tlearn: 265992.0326018\ttotal: 4.93s\tremaining: 883ms\n",
      "848:\tlearn: 265992.0235963\ttotal: 4.93s\tremaining: 877ms\n",
      "849:\tlearn: 265991.9687270\ttotal: 4.93s\tremaining: 871ms\n",
      "850:\tlearn: 265991.9349202\ttotal: 4.94s\tremaining: 865ms\n",
      "851:\tlearn: 265991.9112029\ttotal: 4.94s\tremaining: 858ms\n",
      "852:\tlearn: 265991.8640597\ttotal: 4.94s\tremaining: 852ms\n",
      "853:\tlearn: 265991.8374038\ttotal: 4.95s\tremaining: 846ms\n",
      "854:\tlearn: 265991.7786130\ttotal: 4.95s\tremaining: 840ms\n",
      "855:\tlearn: 265991.7327945\ttotal: 4.95s\tremaining: 834ms\n",
      "856:\tlearn: 265991.6833659\ttotal: 4.96s\tremaining: 827ms\n",
      "857:\tlearn: 265991.6510349\ttotal: 4.96s\tremaining: 821ms\n",
      "858:\tlearn: 265991.6286794\ttotal: 4.97s\tremaining: 815ms\n",
      "859:\tlearn: 265991.5942406\ttotal: 4.97s\tremaining: 809ms\n",
      "860:\tlearn: 265991.5444662\ttotal: 4.97s\tremaining: 803ms\n",
      "861:\tlearn: 265991.4906962\ttotal: 4.97s\tremaining: 796ms\n",
      "862:\tlearn: 265991.4516756\ttotal: 4.98s\tremaining: 790ms\n",
      "863:\tlearn: 265991.4211038\ttotal: 4.98s\tremaining: 785ms\n",
      "864:\tlearn: 265991.3999122\ttotal: 4.99s\tremaining: 778ms\n",
      "865:\tlearn: 265991.3648760\ttotal: 4.99s\tremaining: 772ms\n",
      "866:\tlearn: 265991.3114740\ttotal: 5s\tremaining: 767ms\n",
      "867:\tlearn: 265991.2674180\ttotal: 5s\tremaining: 760ms\n",
      "868:\tlearn: 265991.2605819\ttotal: 5s\tremaining: 754ms\n",
      "869:\tlearn: 265991.1958472\ttotal: 5.01s\tremaining: 748ms\n",
      "870:\tlearn: 265991.1419777\ttotal: 5.01s\tremaining: 743ms\n",
      "871:\tlearn: 265991.1201122\ttotal: 5.02s\tremaining: 737ms\n",
      "872:\tlearn: 265991.1148148\ttotal: 5.02s\tremaining: 731ms\n",
      "873:\tlearn: 265991.0830905\ttotal: 5.03s\tremaining: 725ms\n",
      "874:\tlearn: 265991.0500033\ttotal: 5.03s\tremaining: 719ms\n",
      "875:\tlearn: 265991.0027239\ttotal: 5.03s\tremaining: 713ms\n",
      "876:\tlearn: 265990.9735017\ttotal: 5.04s\tremaining: 707ms\n",
      "877:\tlearn: 265990.9507505\ttotal: 5.04s\tremaining: 701ms\n",
      "878:\tlearn: 265990.9224701\ttotal: 5.05s\tremaining: 695ms\n",
      "879:\tlearn: 265990.8812019\ttotal: 5.05s\tremaining: 689ms\n",
      "880:\tlearn: 265990.8499528\ttotal: 5.06s\tremaining: 683ms\n",
      "881:\tlearn: 265990.8176260\ttotal: 5.06s\tremaining: 677ms\n",
      "882:\tlearn: 265990.7810218\ttotal: 5.06s\tremaining: 671ms\n",
      "883:\tlearn: 265990.7741373\ttotal: 5.06s\tremaining: 665ms\n",
      "884:\tlearn: 265990.7711074\ttotal: 5.07s\tremaining: 659ms\n",
      "885:\tlearn: 265990.7682517\ttotal: 5.07s\tremaining: 653ms\n",
      "886:\tlearn: 265990.7348735\ttotal: 5.08s\tremaining: 647ms\n",
      "887:\tlearn: 265990.6921122\ttotal: 5.08s\tremaining: 641ms\n",
      "888:\tlearn: 265990.6802846\ttotal: 5.08s\tremaining: 635ms\n",
      "889:\tlearn: 265990.6438341\ttotal: 5.08s\tremaining: 628ms\n",
      "890:\tlearn: 265990.6074034\ttotal: 5.09s\tremaining: 623ms\n",
      "891:\tlearn: 265990.5653273\ttotal: 5.09s\tremaining: 616ms\n",
      "892:\tlearn: 265990.5292208\ttotal: 5.09s\tremaining: 611ms\n",
      "893:\tlearn: 265990.5239740\ttotal: 5.1s\tremaining: 605ms\n",
      "894:\tlearn: 265990.4729541\ttotal: 5.1s\tremaining: 598ms\n",
      "895:\tlearn: 265990.4594361\ttotal: 5.11s\tremaining: 593ms\n",
      "896:\tlearn: 265990.4346333\ttotal: 5.11s\tremaining: 587ms\n",
      "897:\tlearn: 265990.3907733\ttotal: 5.11s\tremaining: 581ms\n",
      "898:\tlearn: 265990.3526591\ttotal: 5.12s\tremaining: 575ms\n",
      "899:\tlearn: 265990.3252547\ttotal: 5.12s\tremaining: 569ms\n",
      "900:\tlearn: 265990.2908178\ttotal: 5.12s\tremaining: 563ms\n",
      "901:\tlearn: 265990.2619342\ttotal: 5.13s\tremaining: 557ms\n",
      "902:\tlearn: 265990.2303664\ttotal: 5.13s\tremaining: 551ms\n",
      "903:\tlearn: 265990.2247060\ttotal: 5.13s\tremaining: 545ms\n",
      "904:\tlearn: 265990.2078243\ttotal: 5.14s\tremaining: 539ms\n",
      "905:\tlearn: 265990.1760380\ttotal: 5.14s\tremaining: 533ms\n",
      "906:\tlearn: 265990.1383294\ttotal: 5.14s\tremaining: 527ms\n",
      "907:\tlearn: 265990.1005435\ttotal: 5.15s\tremaining: 521ms\n",
      "908:\tlearn: 265990.0982468\ttotal: 5.15s\tremaining: 516ms\n",
      "909:\tlearn: 265990.0699202\ttotal: 5.15s\tremaining: 510ms\n",
      "910:\tlearn: 265990.0454043\ttotal: 5.16s\tremaining: 504ms\n",
      "911:\tlearn: 265990.0157216\ttotal: 5.16s\tremaining: 498ms\n",
      "912:\tlearn: 265989.9822374\ttotal: 5.16s\tremaining: 492ms\n",
      "913:\tlearn: 265989.9650634\ttotal: 5.17s\tremaining: 486ms\n",
      "914:\tlearn: 265989.9289359\ttotal: 5.17s\tremaining: 480ms\n",
      "915:\tlearn: 265989.8986670\ttotal: 5.17s\tremaining: 474ms\n",
      "916:\tlearn: 265989.8820259\ttotal: 5.17s\tremaining: 468ms\n",
      "917:\tlearn: 265989.8651623\ttotal: 5.18s\tremaining: 463ms\n",
      "918:\tlearn: 265989.8627335\ttotal: 5.18s\tremaining: 457ms\n",
      "919:\tlearn: 265989.8375753\ttotal: 5.19s\tremaining: 451ms\n",
      "920:\tlearn: 265989.8350290\ttotal: 5.19s\tremaining: 445ms\n",
      "921:\tlearn: 265989.8026377\ttotal: 5.2s\tremaining: 440ms\n",
      "922:\tlearn: 265989.7534069\ttotal: 5.2s\tremaining: 434ms\n",
      "923:\tlearn: 265989.7311448\ttotal: 5.2s\tremaining: 428ms\n",
      "924:\tlearn: 265989.7042969\ttotal: 5.21s\tremaining: 422ms\n",
      "925:\tlearn: 265989.6713313\ttotal: 5.21s\tremaining: 416ms\n",
      "926:\tlearn: 265989.6670199\ttotal: 5.21s\tremaining: 411ms\n",
      "927:\tlearn: 265989.6405432\ttotal: 5.25s\tremaining: 408ms\n",
      "928:\tlearn: 265989.6369017\ttotal: 5.26s\tremaining: 402ms\n",
      "929:\tlearn: 265989.5938929\ttotal: 5.27s\tremaining: 397ms\n",
      "930:\tlearn: 265989.5798056\ttotal: 5.28s\tremaining: 391ms\n",
      "931:\tlearn: 265989.5548654\ttotal: 5.3s\tremaining: 386ms\n",
      "932:\tlearn: 265989.5243097\ttotal: 5.3s\tremaining: 381ms\n",
      "933:\tlearn: 265989.4850717\ttotal: 5.3s\tremaining: 375ms\n",
      "934:\tlearn: 265989.4486642\ttotal: 5.31s\tremaining: 369ms\n",
      "935:\tlearn: 265989.4143221\ttotal: 5.32s\tremaining: 364ms\n",
      "936:\tlearn: 265989.3905699\ttotal: 5.33s\tremaining: 358ms\n",
      "937:\tlearn: 265989.3856693\ttotal: 5.33s\tremaining: 353ms\n",
      "938:\tlearn: 265989.3560140\ttotal: 5.34s\tremaining: 347ms\n",
      "939:\tlearn: 265989.3329963\ttotal: 5.34s\tremaining: 341ms\n",
      "940:\tlearn: 265989.2991453\ttotal: 5.35s\tremaining: 335ms\n",
      "941:\tlearn: 265989.2929677\ttotal: 5.35s\tremaining: 329ms\n",
      "942:\tlearn: 265989.2563117\ttotal: 5.36s\tremaining: 324ms\n",
      "943:\tlearn: 265989.2378746\ttotal: 5.36s\tremaining: 318ms\n",
      "944:\tlearn: 265989.1977501\ttotal: 5.36s\tremaining: 312ms\n",
      "945:\tlearn: 265989.1958374\ttotal: 5.37s\tremaining: 306ms\n",
      "946:\tlearn: 265989.1873580\ttotal: 5.37s\tremaining: 301ms\n",
      "947:\tlearn: 265989.1856918\ttotal: 5.38s\tremaining: 295ms\n",
      "948:\tlearn: 265989.1672221\ttotal: 5.38s\tremaining: 289ms\n",
      "949:\tlearn: 265989.1653153\ttotal: 5.39s\tremaining: 284ms\n",
      "950:\tlearn: 265989.1425439\ttotal: 5.39s\tremaining: 278ms\n",
      "951:\tlearn: 265989.1388289\ttotal: 5.39s\tremaining: 272ms\n",
      "952:\tlearn: 265989.1114307\ttotal: 5.4s\tremaining: 266ms\n",
      "953:\tlearn: 265989.0924694\ttotal: 5.41s\tremaining: 261ms\n",
      "954:\tlearn: 265989.0609089\ttotal: 5.41s\tremaining: 255ms\n",
      "955:\tlearn: 265989.0218487\ttotal: 5.41s\tremaining: 249ms\n",
      "956:\tlearn: 265989.0201882\ttotal: 5.42s\tremaining: 243ms\n",
      "957:\tlearn: 265988.9909936\ttotal: 5.42s\tremaining: 238ms\n",
      "958:\tlearn: 265988.9609478\ttotal: 5.43s\tremaining: 232ms\n",
      "959:\tlearn: 265988.9593829\ttotal: 5.43s\tremaining: 226ms\n",
      "960:\tlearn: 265988.9512400\ttotal: 5.44s\tremaining: 221ms\n",
      "961:\tlearn: 265988.9492046\ttotal: 5.44s\tremaining: 215ms\n",
      "962:\tlearn: 265988.9372183\ttotal: 5.45s\tremaining: 209ms\n",
      "963:\tlearn: 265988.9172078\ttotal: 5.45s\tremaining: 204ms\n",
      "964:\tlearn: 265988.8921738\ttotal: 5.45s\tremaining: 198ms\n",
      "965:\tlearn: 265988.8861372\ttotal: 5.46s\tremaining: 192ms\n",
      "966:\tlearn: 265988.8847225\ttotal: 5.46s\tremaining: 186ms\n",
      "967:\tlearn: 265988.8605233\ttotal: 5.47s\tremaining: 181ms\n",
      "968:\tlearn: 265988.8354449\ttotal: 5.47s\tremaining: 175ms\n",
      "969:\tlearn: 265988.8128142\ttotal: 5.48s\tremaining: 169ms\n",
      "970:\tlearn: 265988.7769603\ttotal: 5.48s\tremaining: 164ms\n",
      "971:\tlearn: 265988.7583829\ttotal: 5.49s\tremaining: 158ms\n",
      "972:\tlearn: 265988.7228720\ttotal: 5.49s\tremaining: 152ms\n",
      "973:\tlearn: 265988.7194944\ttotal: 5.5s\tremaining: 147ms\n",
      "974:\tlearn: 265988.6854630\ttotal: 5.5s\tremaining: 141ms\n",
      "975:\tlearn: 265988.6587407\ttotal: 5.5s\tremaining: 135ms\n",
      "976:\tlearn: 265988.6268949\ttotal: 5.51s\tremaining: 130ms\n",
      "977:\tlearn: 265988.6014557\ttotal: 5.51s\tremaining: 124ms\n",
      "978:\tlearn: 265988.5843855\ttotal: 5.52s\tremaining: 118ms\n",
      "979:\tlearn: 265988.5726102\ttotal: 5.52s\tremaining: 113ms\n",
      "980:\tlearn: 265988.5444433\ttotal: 5.52s\tremaining: 107ms\n",
      "981:\tlearn: 265988.5162418\ttotal: 5.53s\tremaining: 101ms\n",
      "982:\tlearn: 265988.4945141\ttotal: 5.53s\tremaining: 95.7ms\n",
      "983:\tlearn: 265988.4653609\ttotal: 5.54s\tremaining: 90ms\n",
      "984:\tlearn: 265988.4453889\ttotal: 5.54s\tremaining: 84.4ms\n",
      "985:\tlearn: 265988.4253399\ttotal: 5.55s\tremaining: 78.8ms\n",
      "986:\tlearn: 265988.4066811\ttotal: 5.55s\tremaining: 73.1ms\n",
      "987:\tlearn: 265988.3757435\ttotal: 5.55s\tremaining: 67.4ms\n",
      "988:\tlearn: 265988.3400681\ttotal: 5.56s\tremaining: 61.8ms\n",
      "989:\tlearn: 265988.3144808\ttotal: 5.56s\tremaining: 56.2ms\n",
      "990:\tlearn: 265988.2978089\ttotal: 5.57s\tremaining: 50.6ms\n",
      "991:\tlearn: 265988.2691625\ttotal: 5.58s\tremaining: 45ms\n",
      "992:\tlearn: 265988.2499608\ttotal: 5.58s\tremaining: 39.3ms\n",
      "993:\tlearn: 265988.2149467\ttotal: 5.58s\tremaining: 33.7ms\n",
      "994:\tlearn: 265988.1899178\ttotal: 5.59s\tremaining: 28.1ms\n",
      "995:\tlearn: 265988.1768085\ttotal: 5.6s\tremaining: 22.5ms\n",
      "996:\tlearn: 265988.1594201\ttotal: 5.61s\tremaining: 16.9ms\n",
      "997:\tlearn: 265988.1292933\ttotal: 5.61s\tremaining: 11.2ms\n",
      "998:\tlearn: 265988.1140965\ttotal: 5.62s\tremaining: 5.62ms\n",
      "999:\tlearn: 265988.1126619\ttotal: 5.62s\tremaining: 0us\n",
      "Prediction for 2024 using CatBoost completed and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor  # Import CatBoostRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=1000, learning_rate=0.1)  # You can adjust hyperparameters as needed\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Add the predicted '2024' column to the DataFrame\n",
    "df['2024'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv', index=False)\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(\"Prediction for 2024 using CatBoost completed and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 979778.2798436\ttotal: 6.16ms\tremaining: 6.15s\n",
      "1:\tlearn: 924575.2951880\ttotal: 12ms\tremaining: 5.99s\n",
      "2:\tlearn: 873926.2246153\ttotal: 17.3ms\tremaining: 5.75s\n",
      "3:\tlearn: 826261.9946553\ttotal: 20.4ms\tremaining: 5.09s\n",
      "4:\tlearn: 782950.4139932\ttotal: 23.4ms\tremaining: 4.66s\n",
      "5:\tlearn: 745534.8449689\ttotal: 28.7ms\tremaining: 4.76s\n",
      "6:\tlearn: 707118.5338080\ttotal: 33.4ms\tremaining: 4.74s\n",
      "7:\tlearn: 671919.6351810\ttotal: 42.5ms\tremaining: 5.27s\n",
      "8:\tlearn: 642821.4875328\ttotal: 45.9ms\tremaining: 5.05s\n",
      "9:\tlearn: 613701.7345898\ttotal: 50ms\tremaining: 4.95s\n",
      "10:\tlearn: 587782.9157241\ttotal: 52.7ms\tremaining: 4.73s\n",
      "11:\tlearn: 561777.1821534\ttotal: 59ms\tremaining: 4.86s\n",
      "12:\tlearn: 538859.0046329\ttotal: 62.3ms\tremaining: 4.73s\n",
      "13:\tlearn: 515522.1503171\ttotal: 65.5ms\tremaining: 4.61s\n",
      "14:\tlearn: 495015.4751998\ttotal: 68.8ms\tremaining: 4.52s\n",
      "15:\tlearn: 477158.6286657\ttotal: 116ms\tremaining: 7.14s\n",
      "16:\tlearn: 460989.2644273\ttotal: 126ms\tremaining: 7.28s\n",
      "17:\tlearn: 445029.8568103\ttotal: 134ms\tremaining: 7.3s\n",
      "18:\tlearn: 431602.0218937\ttotal: 144ms\tremaining: 7.41s\n",
      "19:\tlearn: 419372.5904399\ttotal: 148ms\tremaining: 7.25s\n",
      "20:\tlearn: 406065.3170255\ttotal: 152ms\tremaining: 7.08s\n",
      "21:\tlearn: 396108.6758389\ttotal: 158ms\tremaining: 7.04s\n",
      "22:\tlearn: 385720.6788090\ttotal: 178ms\tremaining: 7.56s\n",
      "23:\tlearn: 376311.4033003\ttotal: 184ms\tremaining: 7.48s\n",
      "24:\tlearn: 367907.0746935\ttotal: 190ms\tremaining: 7.39s\n",
      "25:\tlearn: 360068.2348320\ttotal: 192ms\tremaining: 7.21s\n",
      "26:\tlearn: 352733.1060876\ttotal: 196ms\tremaining: 7.05s\n",
      "27:\tlearn: 345001.3919625\ttotal: 200ms\tremaining: 6.93s\n",
      "28:\tlearn: 338615.9670962\ttotal: 203ms\tremaining: 6.8s\n",
      "29:\tlearn: 333187.3772632\ttotal: 217ms\tremaining: 7.01s\n",
      "30:\tlearn: 327954.0666737\ttotal: 223ms\tremaining: 6.97s\n",
      "31:\tlearn: 322615.7080977\ttotal: 236ms\tremaining: 7.14s\n",
      "32:\tlearn: 317847.6662143\ttotal: 240ms\tremaining: 7.03s\n",
      "33:\tlearn: 313891.4587879\ttotal: 250ms\tremaining: 7.09s\n",
      "34:\tlearn: 310093.1441897\ttotal: 255ms\tremaining: 7.03s\n",
      "35:\tlearn: 306906.7747545\ttotal: 262ms\tremaining: 7.01s\n",
      "36:\tlearn: 303922.8534694\ttotal: 273ms\tremaining: 7.1s\n",
      "37:\tlearn: 300839.3012551\ttotal: 278ms\tremaining: 7.03s\n",
      "38:\tlearn: 298604.7747129\ttotal: 285ms\tremaining: 7.03s\n",
      "39:\tlearn: 296037.0260066\ttotal: 288ms\tremaining: 6.92s\n",
      "40:\tlearn: 293698.7120117\ttotal: 291ms\tremaining: 6.81s\n",
      "41:\tlearn: 291435.2278051\ttotal: 301ms\tremaining: 6.86s\n",
      "42:\tlearn: 290019.7705268\ttotal: 305ms\tremaining: 6.78s\n",
      "43:\tlearn: 288404.4563271\ttotal: 309ms\tremaining: 6.71s\n",
      "44:\tlearn: 286741.4431088\ttotal: 318ms\tremaining: 6.74s\n",
      "45:\tlearn: 285430.8927162\ttotal: 322ms\tremaining: 6.67s\n",
      "46:\tlearn: 284112.2698526\ttotal: 325ms\tremaining: 6.59s\n",
      "47:\tlearn: 282971.6624711\ttotal: 330ms\tremaining: 6.54s\n",
      "48:\tlearn: 281949.5588427\ttotal: 333ms\tremaining: 6.46s\n",
      "49:\tlearn: 280996.7613098\ttotal: 336ms\tremaining: 6.38s\n",
      "50:\tlearn: 280182.9303028\ttotal: 340ms\tremaining: 6.32s\n",
      "51:\tlearn: 279394.2578960\ttotal: 342ms\tremaining: 6.23s\n",
      "52:\tlearn: 278667.7426348\ttotal: 346ms\tremaining: 6.18s\n",
      "53:\tlearn: 278030.5655987\ttotal: 348ms\tremaining: 6.1s\n",
      "54:\tlearn: 277414.8613950\ttotal: 352ms\tremaining: 6.04s\n",
      "55:\tlearn: 276798.0600797\ttotal: 355ms\tremaining: 5.98s\n",
      "56:\tlearn: 276428.9633771\ttotal: 359ms\tremaining: 5.94s\n",
      "57:\tlearn: 275889.2444188\ttotal: 362ms\tremaining: 5.88s\n",
      "58:\tlearn: 275430.4438287\ttotal: 366ms\tremaining: 5.83s\n",
      "59:\tlearn: 275013.9436180\ttotal: 369ms\tremaining: 5.78s\n",
      "60:\tlearn: 274666.3158831\ttotal: 371ms\tremaining: 5.71s\n",
      "61:\tlearn: 274308.2093083\ttotal: 375ms\tremaining: 5.67s\n",
      "62:\tlearn: 273876.1782603\ttotal: 378ms\tremaining: 5.63s\n",
      "63:\tlearn: 273598.8591775\ttotal: 382ms\tremaining: 5.58s\n",
      "64:\tlearn: 273358.7186785\ttotal: 384ms\tremaining: 5.53s\n",
      "65:\tlearn: 273067.0641856\ttotal: 387ms\tremaining: 5.47s\n",
      "66:\tlearn: 272856.5908610\ttotal: 391ms\tremaining: 5.44s\n",
      "67:\tlearn: 272651.8786072\ttotal: 394ms\tremaining: 5.41s\n",
      "68:\tlearn: 272454.1689508\ttotal: 398ms\tremaining: 5.37s\n",
      "69:\tlearn: 272245.9607351\ttotal: 400ms\tremaining: 5.32s\n",
      "70:\tlearn: 271921.4997437\ttotal: 403ms\tremaining: 5.27s\n",
      "71:\tlearn: 271778.7552070\ttotal: 408ms\tremaining: 5.25s\n",
      "72:\tlearn: 271608.0173941\ttotal: 412ms\tremaining: 5.23s\n",
      "73:\tlearn: 271426.2268028\ttotal: 415ms\tremaining: 5.2s\n",
      "74:\tlearn: 271243.8980795\ttotal: 419ms\tremaining: 5.17s\n",
      "75:\tlearn: 271039.5886293\ttotal: 423ms\tremaining: 5.14s\n",
      "76:\tlearn: 270833.3512878\ttotal: 426ms\tremaining: 5.11s\n",
      "77:\tlearn: 270666.3520402\ttotal: 432ms\tremaining: 5.11s\n",
      "78:\tlearn: 270557.9163393\ttotal: 436ms\tremaining: 5.08s\n",
      "79:\tlearn: 270448.3641315\ttotal: 439ms\tremaining: 5.05s\n",
      "80:\tlearn: 270336.7228789\ttotal: 444ms\tremaining: 5.04s\n",
      "81:\tlearn: 270260.4298283\ttotal: 448ms\tremaining: 5.01s\n",
      "82:\tlearn: 270079.5740175\ttotal: 454ms\tremaining: 5.02s\n",
      "83:\tlearn: 269941.8666162\ttotal: 459ms\tremaining: 5s\n",
      "84:\tlearn: 269860.7524230\ttotal: 464ms\tremaining: 4.99s\n",
      "85:\tlearn: 269765.8963447\ttotal: 471ms\tremaining: 5s\n",
      "86:\tlearn: 269652.7487578\ttotal: 473ms\tremaining: 4.97s\n",
      "87:\tlearn: 269586.5984216\ttotal: 477ms\tremaining: 4.95s\n",
      "88:\tlearn: 269473.1248465\ttotal: 483ms\tremaining: 4.95s\n",
      "89:\tlearn: 269371.1321375\ttotal: 488ms\tremaining: 4.93s\n",
      "90:\tlearn: 269253.8058741\ttotal: 491ms\tremaining: 4.9s\n",
      "91:\tlearn: 269175.1277604\ttotal: 501ms\tremaining: 4.94s\n",
      "92:\tlearn: 269069.1025119\ttotal: 508ms\tremaining: 4.95s\n",
      "93:\tlearn: 268991.1051272\ttotal: 518ms\tremaining: 4.99s\n",
      "94:\tlearn: 268910.0557283\ttotal: 521ms\tremaining: 4.97s\n",
      "95:\tlearn: 268849.0302608\ttotal: 524ms\tremaining: 4.93s\n",
      "96:\tlearn: 268763.0408022\ttotal: 528ms\tremaining: 4.91s\n",
      "97:\tlearn: 268702.0096120\ttotal: 534ms\tremaining: 4.91s\n",
      "98:\tlearn: 268626.7948776\ttotal: 537ms\tremaining: 4.88s\n",
      "99:\tlearn: 268568.4426915\ttotal: 539ms\tremaining: 4.85s\n",
      "100:\tlearn: 268501.7435049\ttotal: 543ms\tremaining: 4.83s\n",
      "101:\tlearn: 268435.6999893\ttotal: 550ms\tremaining: 4.84s\n",
      "102:\tlearn: 268361.3877494\ttotal: 553ms\tremaining: 4.82s\n",
      "103:\tlearn: 268276.2559197\ttotal: 556ms\tremaining: 4.79s\n",
      "104:\tlearn: 268238.8324534\ttotal: 559ms\tremaining: 4.76s\n",
      "105:\tlearn: 268198.1153603\ttotal: 566ms\tremaining: 4.77s\n",
      "106:\tlearn: 268132.1064599\ttotal: 571ms\tremaining: 4.76s\n",
      "107:\tlearn: 268081.9305804\ttotal: 574ms\tremaining: 4.74s\n",
      "108:\tlearn: 268028.8465318\ttotal: 579ms\tremaining: 4.73s\n",
      "109:\tlearn: 268002.8586269\ttotal: 583ms\tremaining: 4.72s\n",
      "110:\tlearn: 267933.2355127\ttotal: 587ms\tremaining: 4.7s\n",
      "111:\tlearn: 267883.0514612\ttotal: 589ms\tremaining: 4.67s\n",
      "112:\tlearn: 267820.9382246\ttotal: 593ms\tremaining: 4.66s\n",
      "113:\tlearn: 267790.5713175\ttotal: 596ms\tremaining: 4.63s\n",
      "114:\tlearn: 267731.9342566\ttotal: 600ms\tremaining: 4.62s\n",
      "115:\tlearn: 267679.9847041\ttotal: 603ms\tremaining: 4.59s\n",
      "116:\tlearn: 267650.6363379\ttotal: 605ms\tremaining: 4.57s\n",
      "117:\tlearn: 267607.8296858\ttotal: 611ms\tremaining: 4.57s\n",
      "118:\tlearn: 267561.7571161\ttotal: 616ms\tremaining: 4.56s\n",
      "119:\tlearn: 267516.3256406\ttotal: 618ms\tremaining: 4.54s\n",
      "120:\tlearn: 267486.8852407\ttotal: 621ms\tremaining: 4.51s\n",
      "121:\tlearn: 267446.5476400\ttotal: 627ms\tremaining: 4.51s\n",
      "122:\tlearn: 267410.7204012\ttotal: 647ms\tremaining: 4.61s\n",
      "123:\tlearn: 267395.5378778\ttotal: 649ms\tremaining: 4.59s\n",
      "124:\tlearn: 267364.7909983\ttotal: 652ms\tremaining: 4.57s\n",
      "125:\tlearn: 267330.1597245\ttotal: 660ms\tremaining: 4.58s\n",
      "126:\tlearn: 267316.8848647\ttotal: 666ms\tremaining: 4.58s\n",
      "127:\tlearn: 267304.3605480\ttotal: 669ms\tremaining: 4.55s\n",
      "128:\tlearn: 267275.0517574\ttotal: 674ms\tremaining: 4.55s\n",
      "129:\tlearn: 267240.2692884\ttotal: 678ms\tremaining: 4.54s\n",
      "130:\tlearn: 267228.5197919\ttotal: 681ms\tremaining: 4.52s\n",
      "131:\tlearn: 267202.6443119\ttotal: 685ms\tremaining: 4.5s\n",
      "132:\tlearn: 267182.9481297\ttotal: 690ms\tremaining: 4.5s\n",
      "133:\tlearn: 267159.9128283\ttotal: 693ms\tremaining: 4.48s\n",
      "134:\tlearn: 267142.5185224\ttotal: 697ms\tremaining: 4.47s\n",
      "135:\tlearn: 267126.1689267\ttotal: 705ms\tremaining: 4.48s\n",
      "136:\tlearn: 267104.3928713\ttotal: 708ms\tremaining: 4.46s\n",
      "137:\tlearn: 267089.0090074\ttotal: 711ms\tremaining: 4.44s\n",
      "138:\tlearn: 267075.5899808\ttotal: 714ms\tremaining: 4.42s\n",
      "139:\tlearn: 267061.7394775\ttotal: 719ms\tremaining: 4.42s\n",
      "140:\tlearn: 267036.7126968\ttotal: 722ms\tremaining: 4.4s\n",
      "141:\tlearn: 267006.3433007\ttotal: 724ms\tremaining: 4.38s\n",
      "142:\tlearn: 266993.2080847\ttotal: 728ms\tremaining: 4.36s\n",
      "143:\tlearn: 266975.2296233\ttotal: 731ms\tremaining: 4.35s\n",
      "144:\tlearn: 266958.3888826\ttotal: 738ms\tremaining: 4.35s\n",
      "145:\tlearn: 266936.5692682\ttotal: 741ms\tremaining: 4.33s\n",
      "146:\tlearn: 266920.8132222\ttotal: 743ms\tremaining: 4.31s\n",
      "147:\tlearn: 266909.7138747\ttotal: 748ms\tremaining: 4.3s\n",
      "148:\tlearn: 266899.2393856\ttotal: 753ms\tremaining: 4.3s\n",
      "149:\tlearn: 266877.5350684\ttotal: 755ms\tremaining: 4.28s\n",
      "150:\tlearn: 266868.5248690\ttotal: 758ms\tremaining: 4.26s\n",
      "151:\tlearn: 266854.6876581\ttotal: 761ms\tremaining: 4.25s\n",
      "152:\tlearn: 266839.7931536\ttotal: 767ms\tremaining: 4.25s\n",
      "153:\tlearn: 266827.4776490\ttotal: 771ms\tremaining: 4.24s\n",
      "154:\tlearn: 266815.3332023\ttotal: 773ms\tremaining: 4.21s\n",
      "155:\tlearn: 266804.1585242\ttotal: 777ms\tremaining: 4.21s\n",
      "156:\tlearn: 266783.5351776\ttotal: 782ms\tremaining: 4.2s\n",
      "157:\tlearn: 266775.1678948\ttotal: 786ms\tremaining: 4.19s\n",
      "158:\tlearn: 266765.1932167\ttotal: 788ms\tremaining: 4.17s\n",
      "159:\tlearn: 266757.6126836\ttotal: 796ms\tremaining: 4.18s\n",
      "160:\tlearn: 266746.2316939\ttotal: 799ms\tremaining: 4.17s\n",
      "161:\tlearn: 266733.6728604\ttotal: 802ms\tremaining: 4.15s\n",
      "162:\tlearn: 266716.6994489\ttotal: 806ms\tremaining: 4.14s\n",
      "163:\tlearn: 266701.3574360\ttotal: 813ms\tremaining: 4.14s\n",
      "164:\tlearn: 266691.9941243\ttotal: 816ms\tremaining: 4.13s\n",
      "165:\tlearn: 266683.3275697\ttotal: 819ms\tremaining: 4.11s\n",
      "166:\tlearn: 266666.6694997\ttotal: 823ms\tremaining: 4.11s\n",
      "167:\tlearn: 266662.9165887\ttotal: 829ms\tremaining: 4.11s\n",
      "168:\tlearn: 266655.0153510\ttotal: 834ms\tremaining: 4.1s\n",
      "169:\tlearn: 266647.6872612\ttotal: 837ms\tremaining: 4.08s\n",
      "170:\tlearn: 266641.0387989\ttotal: 845ms\tremaining: 4.09s\n",
      "171:\tlearn: 266628.8713378\ttotal: 848ms\tremaining: 4.08s\n",
      "172:\tlearn: 266622.5587708\ttotal: 851ms\tremaining: 4.07s\n",
      "173:\tlearn: 266610.8448489\ttotal: 897ms\tremaining: 4.26s\n",
      "174:\tlearn: 266607.3982474\ttotal: 910ms\tremaining: 4.29s\n",
      "175:\tlearn: 266601.7171577\ttotal: 928ms\tremaining: 4.34s\n",
      "176:\tlearn: 266596.2809974\ttotal: 935ms\tremaining: 4.35s\n",
      "177:\tlearn: 266584.7286818\ttotal: 948ms\tremaining: 4.38s\n",
      "178:\tlearn: 266570.3329877\ttotal: 958ms\tremaining: 4.39s\n",
      "179:\tlearn: 266564.4734984\ttotal: 966ms\tremaining: 4.4s\n",
      "180:\tlearn: 266561.2003374\ttotal: 982ms\tremaining: 4.44s\n",
      "181:\tlearn: 266556.6359299\ttotal: 987ms\tremaining: 4.44s\n",
      "182:\tlearn: 266551.5011366\ttotal: 991ms\tremaining: 4.42s\n",
      "183:\tlearn: 266546.2679260\ttotal: 994ms\tremaining: 4.41s\n",
      "184:\tlearn: 266537.7275317\ttotal: 997ms\tremaining: 4.39s\n",
      "185:\tlearn: 266534.7556869\ttotal: 1s\tremaining: 4.39s\n",
      "186:\tlearn: 266521.9367081\ttotal: 1.01s\tremaining: 4.38s\n",
      "187:\tlearn: 266510.9383980\ttotal: 1.01s\tremaining: 4.37s\n",
      "188:\tlearn: 266508.1239413\ttotal: 1.01s\tremaining: 4.35s\n",
      "189:\tlearn: 266503.7230227\ttotal: 1.02s\tremaining: 4.35s\n",
      "190:\tlearn: 266499.6511208\ttotal: 1.02s\tremaining: 4.33s\n",
      "191:\tlearn: 266489.3713745\ttotal: 1.03s\tremaining: 4.32s\n",
      "192:\tlearn: 266485.5899593\ttotal: 1.03s\tremaining: 4.32s\n",
      "193:\tlearn: 266478.6125592\ttotal: 1.04s\tremaining: 4.31s\n",
      "194:\tlearn: 266475.9814798\ttotal: 1.04s\tremaining: 4.3s\n",
      "195:\tlearn: 266467.6498955\ttotal: 1.04s\tremaining: 4.28s\n",
      "196:\tlearn: 266465.0170211\ttotal: 1.05s\tremaining: 4.29s\n",
      "197:\tlearn: 266457.0101506\ttotal: 1.06s\tremaining: 4.28s\n",
      "198:\tlearn: 266452.4679365\ttotal: 1.06s\tremaining: 4.26s\n",
      "199:\tlearn: 266448.0836488\ttotal: 1.06s\tremaining: 4.26s\n",
      "200:\tlearn: 266444.0036186\ttotal: 1.07s\tremaining: 4.26s\n",
      "201:\tlearn: 266440.2198944\ttotal: 1.07s\tremaining: 4.24s\n",
      "202:\tlearn: 266428.2618449\ttotal: 1.08s\tremaining: 4.23s\n",
      "203:\tlearn: 266420.1952733\ttotal: 1.08s\tremaining: 4.22s\n",
      "204:\tlearn: 266416.6802487\ttotal: 1.09s\tremaining: 4.22s\n",
      "205:\tlearn: 266413.0882747\ttotal: 1.09s\tremaining: 4.2s\n",
      "206:\tlearn: 266406.5760110\ttotal: 1.09s\tremaining: 4.2s\n",
      "207:\tlearn: 266403.5568967\ttotal: 1.1s\tremaining: 4.19s\n",
      "208:\tlearn: 266400.3998984\ttotal: 1.1s\tremaining: 4.18s\n",
      "209:\tlearn: 266397.7535787\ttotal: 1.11s\tremaining: 4.18s\n",
      "210:\tlearn: 266391.8250845\ttotal: 1.11s\tremaining: 4.17s\n",
      "211:\tlearn: 266385.5450266\ttotal: 1.12s\tremaining: 4.15s\n",
      "212:\tlearn: 266379.2052291\ttotal: 1.12s\tremaining: 4.14s\n",
      "213:\tlearn: 266372.1079210\ttotal: 1.13s\tremaining: 4.14s\n",
      "214:\tlearn: 266369.3153942\ttotal: 1.13s\tremaining: 4.13s\n",
      "215:\tlearn: 266361.9135001\ttotal: 1.14s\tremaining: 4.12s\n",
      "216:\tlearn: 266356.4503966\ttotal: 1.14s\tremaining: 4.11s\n",
      "217:\tlearn: 266349.6815548\ttotal: 1.14s\tremaining: 4.1s\n",
      "218:\tlearn: 266343.3143669\ttotal: 1.15s\tremaining: 4.09s\n",
      "219:\tlearn: 266336.0749093\ttotal: 1.15s\tremaining: 4.08s\n",
      "220:\tlearn: 266331.4915902\ttotal: 1.15s\tremaining: 4.07s\n",
      "221:\tlearn: 266329.2408414\ttotal: 1.16s\tremaining: 4.06s\n",
      "222:\tlearn: 266327.5507138\ttotal: 1.16s\tremaining: 4.05s\n",
      "223:\tlearn: 266323.6604153\ttotal: 1.17s\tremaining: 4.05s\n",
      "224:\tlearn: 266321.6022221\ttotal: 1.18s\tremaining: 4.05s\n",
      "225:\tlearn: 266317.3326593\ttotal: 1.18s\tremaining: 4.04s\n",
      "226:\tlearn: 266314.7969331\ttotal: 1.18s\tremaining: 4.03s\n",
      "227:\tlearn: 266308.9463974\ttotal: 1.19s\tremaining: 4.03s\n",
      "228:\tlearn: 266304.8691400\ttotal: 1.19s\tremaining: 4.02s\n",
      "229:\tlearn: 266303.1478606\ttotal: 1.2s\tremaining: 4s\n",
      "230:\tlearn: 266296.1444022\ttotal: 1.2s\tremaining: 3.99s\n",
      "231:\tlearn: 266290.6380773\ttotal: 1.2s\tremaining: 3.99s\n",
      "232:\tlearn: 266288.9046702\ttotal: 1.21s\tremaining: 3.97s\n",
      "233:\tlearn: 266283.7622078\ttotal: 1.21s\tremaining: 3.96s\n",
      "234:\tlearn: 266281.8241135\ttotal: 1.22s\tremaining: 3.96s\n",
      "235:\tlearn: 266280.2555224\ttotal: 1.22s\tremaining: 3.95s\n",
      "236:\tlearn: 266278.7954596\ttotal: 1.22s\tremaining: 3.94s\n",
      "237:\tlearn: 266274.0278062\ttotal: 1.22s\tremaining: 3.92s\n",
      "238:\tlearn: 266272.5593148\ttotal: 1.23s\tremaining: 3.93s\n",
      "239:\tlearn: 266268.7774362\ttotal: 1.24s\tremaining: 3.92s\n",
      "240:\tlearn: 266267.6841256\ttotal: 1.24s\tremaining: 3.9s\n",
      "241:\tlearn: 266264.1159559\ttotal: 1.24s\tremaining: 3.9s\n",
      "242:\tlearn: 266262.9083167\ttotal: 1.25s\tremaining: 3.89s\n",
      "243:\tlearn: 266258.8534823\ttotal: 1.25s\tremaining: 3.89s\n",
      "244:\tlearn: 266254.6848217\ttotal: 1.26s\tremaining: 3.88s\n",
      "245:\tlearn: 266253.4795313\ttotal: 1.27s\tremaining: 3.88s\n",
      "246:\tlearn: 266248.4139839\ttotal: 1.27s\tremaining: 3.87s\n",
      "247:\tlearn: 266244.3517224\ttotal: 1.27s\tremaining: 3.86s\n",
      "248:\tlearn: 266243.3132993\ttotal: 1.27s\tremaining: 3.85s\n",
      "249:\tlearn: 266241.9870971\ttotal: 1.28s\tremaining: 3.85s\n",
      "250:\tlearn: 266240.8754697\ttotal: 1.28s\tremaining: 3.83s\n",
      "251:\tlearn: 266237.7564063\ttotal: 1.29s\tremaining: 3.82s\n",
      "252:\tlearn: 266236.7096476\ttotal: 1.29s\tremaining: 3.81s\n",
      "253:\tlearn: 266234.7048838\ttotal: 1.3s\tremaining: 3.82s\n",
      "254:\tlearn: 266233.8087244\ttotal: 1.3s\tremaining: 3.8s\n",
      "255:\tlearn: 266229.3435131\ttotal: 1.3s\tremaining: 3.79s\n",
      "256:\tlearn: 266226.0035884\ttotal: 1.31s\tremaining: 3.78s\n",
      "257:\tlearn: 266222.5902244\ttotal: 1.31s\tremaining: 3.78s\n",
      "258:\tlearn: 266219.3574453\ttotal: 1.32s\tremaining: 3.77s\n",
      "259:\tlearn: 266218.0947722\ttotal: 1.32s\tremaining: 3.75s\n",
      "260:\tlearn: 266215.1696326\ttotal: 1.32s\tremaining: 3.74s\n",
      "261:\tlearn: 266211.7869982\ttotal: 1.33s\tremaining: 3.74s\n",
      "262:\tlearn: 266209.2270183\ttotal: 1.33s\tremaining: 3.73s\n",
      "263:\tlearn: 266205.7578691\ttotal: 1.33s\tremaining: 3.72s\n",
      "264:\tlearn: 266204.1847472\ttotal: 1.33s\tremaining: 3.7s\n",
      "265:\tlearn: 266201.2092950\ttotal: 1.34s\tremaining: 3.69s\n",
      "266:\tlearn: 266198.2337270\ttotal: 1.34s\tremaining: 3.69s\n",
      "267:\tlearn: 266194.6694516\ttotal: 1.35s\tremaining: 3.68s\n",
      "268:\tlearn: 266193.8838848\ttotal: 1.35s\tremaining: 3.67s\n",
      "269:\tlearn: 266192.2909721\ttotal: 1.35s\tremaining: 3.65s\n",
      "270:\tlearn: 266190.1749796\ttotal: 1.36s\tremaining: 3.65s\n",
      "271:\tlearn: 266187.7025932\ttotal: 1.36s\tremaining: 3.65s\n",
      "272:\tlearn: 266184.9703256\ttotal: 1.37s\tremaining: 3.64s\n",
      "273:\tlearn: 266182.7359815\ttotal: 1.37s\tremaining: 3.63s\n",
      "274:\tlearn: 266181.8668146\ttotal: 1.37s\tremaining: 3.62s\n",
      "275:\tlearn: 266181.1743720\ttotal: 1.38s\tremaining: 3.61s\n",
      "276:\tlearn: 266178.5202343\ttotal: 1.38s\tremaining: 3.6s\n",
      "277:\tlearn: 266177.7354073\ttotal: 1.38s\tremaining: 3.59s\n",
      "278:\tlearn: 266175.5205392\ttotal: 1.38s\tremaining: 3.58s\n",
      "279:\tlearn: 266172.8066452\ttotal: 1.39s\tremaining: 3.57s\n",
      "280:\tlearn: 266169.8787246\ttotal: 1.39s\tremaining: 3.56s\n",
      "281:\tlearn: 266167.4184097\ttotal: 1.4s\tremaining: 3.55s\n",
      "282:\tlearn: 266165.0403855\ttotal: 1.4s\tremaining: 3.55s\n",
      "283:\tlearn: 266164.3306966\ttotal: 1.4s\tremaining: 3.54s\n",
      "284:\tlearn: 266163.7545698\ttotal: 1.41s\tremaining: 3.53s\n",
      "285:\tlearn: 266162.6163543\ttotal: 1.41s\tremaining: 3.52s\n",
      "286:\tlearn: 266160.4926959\ttotal: 1.41s\tremaining: 3.51s\n",
      "287:\tlearn: 266159.9653128\ttotal: 1.42s\tremaining: 3.51s\n",
      "288:\tlearn: 266157.6350159\ttotal: 1.42s\tremaining: 3.5s\n",
      "289:\tlearn: 266156.5395555\ttotal: 1.43s\tremaining: 3.49s\n",
      "290:\tlearn: 266154.0505808\ttotal: 1.43s\tremaining: 3.49s\n",
      "291:\tlearn: 266153.0856678\ttotal: 1.44s\tremaining: 3.48s\n",
      "292:\tlearn: 266151.0667280\ttotal: 1.44s\tremaining: 3.48s\n",
      "293:\tlearn: 266149.7455428\ttotal: 1.45s\tremaining: 3.47s\n",
      "294:\tlearn: 266147.5894570\ttotal: 1.45s\tremaining: 3.48s\n",
      "295:\tlearn: 266146.6546989\ttotal: 1.46s\tremaining: 3.47s\n",
      "296:\tlearn: 266144.8508674\ttotal: 1.46s\tremaining: 3.46s\n",
      "297:\tlearn: 266143.1215748\ttotal: 1.47s\tremaining: 3.46s\n",
      "298:\tlearn: 266141.7842788\ttotal: 1.47s\tremaining: 3.45s\n",
      "299:\tlearn: 266141.2514733\ttotal: 1.47s\tremaining: 3.44s\n",
      "300:\tlearn: 266139.9434211\ttotal: 1.47s\tremaining: 3.42s\n",
      "301:\tlearn: 266139.0008818\ttotal: 1.48s\tremaining: 3.41s\n",
      "302:\tlearn: 266138.2056737\ttotal: 1.48s\tremaining: 3.41s\n",
      "303:\tlearn: 266136.5524028\ttotal: 1.49s\tremaining: 3.4s\n",
      "304:\tlearn: 266136.1425871\ttotal: 1.49s\tremaining: 3.4s\n",
      "305:\tlearn: 266134.6010664\ttotal: 1.49s\tremaining: 3.39s\n",
      "306:\tlearn: 266132.2437351\ttotal: 1.5s\tremaining: 3.38s\n",
      "307:\tlearn: 266131.4134334\ttotal: 1.5s\tremaining: 3.38s\n",
      "308:\tlearn: 266130.3834669\ttotal: 1.5s\tremaining: 3.37s\n",
      "309:\tlearn: 266129.1795461\ttotal: 1.51s\tremaining: 3.35s\n",
      "310:\tlearn: 266127.6041516\ttotal: 1.51s\tremaining: 3.35s\n",
      "311:\tlearn: 266125.9625257\ttotal: 1.51s\tremaining: 3.34s\n",
      "312:\tlearn: 266125.6012686\ttotal: 1.52s\tremaining: 3.33s\n",
      "313:\tlearn: 266123.9660123\ttotal: 1.52s\tremaining: 3.32s\n",
      "314:\tlearn: 266121.7593442\ttotal: 1.52s\tremaining: 3.31s\n",
      "315:\tlearn: 266120.9404740\ttotal: 1.52s\tremaining: 3.3s\n",
      "316:\tlearn: 266119.7680899\ttotal: 1.53s\tremaining: 3.3s\n",
      "317:\tlearn: 266118.3488986\ttotal: 1.53s\tremaining: 3.29s\n",
      "318:\tlearn: 266117.0518400\ttotal: 1.53s\tremaining: 3.28s\n",
      "319:\tlearn: 266115.8246039\ttotal: 1.54s\tremaining: 3.27s\n",
      "320:\tlearn: 266114.2591826\ttotal: 1.54s\tremaining: 3.26s\n",
      "321:\tlearn: 266112.4402082\ttotal: 1.55s\tremaining: 3.26s\n",
      "322:\tlearn: 266110.9916845\ttotal: 1.55s\tremaining: 3.25s\n",
      "323:\tlearn: 266109.4687120\ttotal: 1.55s\tremaining: 3.24s\n",
      "324:\tlearn: 266107.6263110\ttotal: 1.55s\tremaining: 3.23s\n",
      "325:\tlearn: 266106.5003759\ttotal: 1.56s\tremaining: 3.23s\n",
      "326:\tlearn: 266105.9655608\ttotal: 1.56s\tremaining: 3.22s\n",
      "327:\tlearn: 266104.8964447\ttotal: 1.57s\tremaining: 3.21s\n",
      "328:\tlearn: 266104.4063786\ttotal: 1.57s\tremaining: 3.2s\n",
      "329:\tlearn: 266102.5464895\ttotal: 1.57s\tremaining: 3.2s\n",
      "330:\tlearn: 266102.1734697\ttotal: 1.58s\tremaining: 3.19s\n",
      "331:\tlearn: 266101.8903935\ttotal: 1.58s\tremaining: 3.18s\n",
      "332:\tlearn: 266101.6062984\ttotal: 1.58s\tremaining: 3.17s\n",
      "333:\tlearn: 266101.3498510\ttotal: 1.58s\tremaining: 3.16s\n",
      "334:\tlearn: 266100.1186337\ttotal: 1.59s\tremaining: 3.15s\n",
      "335:\tlearn: 266098.9105042\ttotal: 1.59s\tremaining: 3.15s\n",
      "336:\tlearn: 266097.5165854\ttotal: 1.6s\tremaining: 3.14s\n",
      "337:\tlearn: 266096.1954973\ttotal: 1.6s\tremaining: 3.13s\n",
      "338:\tlearn: 266094.6605870\ttotal: 1.6s\tremaining: 3.13s\n",
      "339:\tlearn: 266093.5997010\ttotal: 1.61s\tremaining: 3.12s\n",
      "340:\tlearn: 266093.2895104\ttotal: 1.61s\tremaining: 3.11s\n",
      "341:\tlearn: 266093.0558382\ttotal: 1.61s\tremaining: 3.1s\n",
      "342:\tlearn: 266092.0042585\ttotal: 1.61s\tremaining: 3.09s\n",
      "343:\tlearn: 266090.8308576\ttotal: 1.62s\tremaining: 3.09s\n",
      "344:\tlearn: 266089.6999334\ttotal: 1.62s\tremaining: 3.08s\n",
      "345:\tlearn: 266088.7848127\ttotal: 1.63s\tremaining: 3.08s\n",
      "346:\tlearn: 266088.2524762\ttotal: 1.63s\tremaining: 3.07s\n",
      "347:\tlearn: 266087.3214386\ttotal: 1.64s\tremaining: 3.07s\n",
      "348:\tlearn: 266086.0863964\ttotal: 1.64s\tremaining: 3.06s\n",
      "349:\tlearn: 266085.8504309\ttotal: 1.64s\tremaining: 3.05s\n",
      "350:\tlearn: 266084.8694871\ttotal: 1.65s\tremaining: 3.04s\n",
      "351:\tlearn: 266083.8320210\ttotal: 1.66s\tremaining: 3.05s\n",
      "352:\tlearn: 266082.7233990\ttotal: 1.66s\tremaining: 3.04s\n",
      "353:\tlearn: 266081.8608464\ttotal: 1.66s\tremaining: 3.03s\n",
      "354:\tlearn: 266080.9448904\ttotal: 1.67s\tremaining: 3.03s\n",
      "355:\tlearn: 266079.9685900\ttotal: 1.67s\tremaining: 3.02s\n",
      "356:\tlearn: 266079.7312301\ttotal: 1.68s\tremaining: 3.02s\n",
      "357:\tlearn: 266078.6741952\ttotal: 1.68s\tremaining: 3.01s\n",
      "358:\tlearn: 266078.4490998\ttotal: 1.72s\tremaining: 3.08s\n",
      "359:\tlearn: 266077.6538074\ttotal: 1.74s\tremaining: 3.08s\n",
      "360:\tlearn: 266076.7857275\ttotal: 1.74s\tremaining: 3.09s\n",
      "361:\tlearn: 266076.5737161\ttotal: 1.76s\tremaining: 3.1s\n",
      "362:\tlearn: 266075.6112945\ttotal: 1.76s\tremaining: 3.1s\n",
      "363:\tlearn: 266074.8069146\ttotal: 1.77s\tremaining: 3.09s\n",
      "364:\tlearn: 266073.8036137\ttotal: 1.77s\tremaining: 3.09s\n",
      "365:\tlearn: 266073.3701730\ttotal: 1.79s\tremaining: 3.11s\n",
      "366:\tlearn: 266072.5544197\ttotal: 1.8s\tremaining: 3.1s\n",
      "367:\tlearn: 266071.4658176\ttotal: 1.8s\tremaining: 3.1s\n",
      "368:\tlearn: 266070.6687427\ttotal: 1.81s\tremaining: 3.09s\n",
      "369:\tlearn: 266069.9455484\ttotal: 1.81s\tremaining: 3.08s\n",
      "370:\tlearn: 266069.0369172\ttotal: 1.81s\tremaining: 3.08s\n",
      "371:\tlearn: 266068.2273136\ttotal: 1.82s\tremaining: 3.07s\n",
      "372:\tlearn: 266068.0441125\ttotal: 1.82s\tremaining: 3.06s\n",
      "373:\tlearn: 266067.3420032\ttotal: 1.83s\tremaining: 3.06s\n",
      "374:\tlearn: 266067.1097458\ttotal: 1.83s\tremaining: 3.05s\n",
      "375:\tlearn: 266066.2378634\ttotal: 1.83s\tremaining: 3.04s\n",
      "376:\tlearn: 266065.9372523\ttotal: 1.84s\tremaining: 3.04s\n",
      "377:\tlearn: 266065.6565493\ttotal: 1.84s\tremaining: 3.03s\n",
      "378:\tlearn: 266064.7155184\ttotal: 1.85s\tremaining: 3.03s\n",
      "379:\tlearn: 266064.0369000\ttotal: 1.85s\tremaining: 3.02s\n",
      "380:\tlearn: 266063.8312138\ttotal: 1.86s\tremaining: 3.02s\n",
      "381:\tlearn: 266063.4896242\ttotal: 1.86s\tremaining: 3.02s\n",
      "382:\tlearn: 266062.8751668\ttotal: 1.87s\tremaining: 3.01s\n",
      "383:\tlearn: 266062.2944878\ttotal: 1.87s\tremaining: 3s\n",
      "384:\tlearn: 266061.4949607\ttotal: 1.88s\tremaining: 3s\n",
      "385:\tlearn: 266061.2472656\ttotal: 1.88s\tremaining: 2.99s\n",
      "386:\tlearn: 266060.6409359\ttotal: 1.89s\tremaining: 2.99s\n",
      "387:\tlearn: 266060.4279805\ttotal: 1.9s\tremaining: 2.99s\n",
      "388:\tlearn: 266059.9927318\ttotal: 1.91s\tremaining: 2.99s\n",
      "389:\tlearn: 266059.8181823\ttotal: 1.91s\tremaining: 2.99s\n",
      "390:\tlearn: 266059.5996062\ttotal: 1.92s\tremaining: 2.98s\n",
      "391:\tlearn: 266059.3954389\ttotal: 1.92s\tremaining: 2.98s\n",
      "392:\tlearn: 266059.2405896\ttotal: 1.93s\tremaining: 2.98s\n",
      "393:\tlearn: 266058.5081769\ttotal: 1.93s\tremaining: 2.97s\n",
      "394:\tlearn: 266057.8279655\ttotal: 1.94s\tremaining: 2.97s\n",
      "395:\tlearn: 266057.1341570\ttotal: 1.94s\tremaining: 2.96s\n",
      "396:\tlearn: 266056.8214103\ttotal: 1.94s\tremaining: 2.95s\n",
      "397:\tlearn: 266056.1094784\ttotal: 1.95s\tremaining: 2.95s\n",
      "398:\tlearn: 266055.4091835\ttotal: 1.95s\tremaining: 2.94s\n",
      "399:\tlearn: 266055.2286660\ttotal: 1.96s\tremaining: 2.94s\n",
      "400:\tlearn: 266054.6245290\ttotal: 1.96s\tremaining: 2.93s\n",
      "401:\tlearn: 266053.9440320\ttotal: 1.96s\tremaining: 2.92s\n",
      "402:\tlearn: 266053.2030107\ttotal: 1.97s\tremaining: 2.92s\n",
      "403:\tlearn: 266052.5889328\ttotal: 1.97s\tremaining: 2.91s\n",
      "404:\tlearn: 266052.4187200\ttotal: 1.97s\tremaining: 2.9s\n",
      "405:\tlearn: 266051.7535689\ttotal: 1.98s\tremaining: 2.89s\n",
      "406:\tlearn: 266050.9252742\ttotal: 1.98s\tremaining: 2.89s\n",
      "407:\tlearn: 266050.3675543\ttotal: 1.99s\tremaining: 2.88s\n",
      "408:\tlearn: 266049.8507866\ttotal: 1.99s\tremaining: 2.87s\n",
      "409:\tlearn: 266049.6534628\ttotal: 1.99s\tremaining: 2.86s\n",
      "410:\tlearn: 266049.1314897\ttotal: 2s\tremaining: 2.86s\n",
      "411:\tlearn: 266048.9757991\ttotal: 2s\tremaining: 2.85s\n",
      "412:\tlearn: 266048.8303116\ttotal: 2s\tremaining: 2.85s\n",
      "413:\tlearn: 266048.3151802\ttotal: 2.01s\tremaining: 2.84s\n",
      "414:\tlearn: 266048.1789826\ttotal: 2.01s\tremaining: 2.84s\n",
      "415:\tlearn: 266047.7150365\ttotal: 2.02s\tremaining: 2.83s\n",
      "416:\tlearn: 266047.0875537\ttotal: 2.02s\tremaining: 2.83s\n",
      "417:\tlearn: 266046.8349928\ttotal: 2.03s\tremaining: 2.82s\n",
      "418:\tlearn: 266046.0425412\ttotal: 2.03s\tremaining: 2.82s\n",
      "419:\tlearn: 266045.5039679\ttotal: 2.04s\tremaining: 2.81s\n",
      "420:\tlearn: 266045.0533138\ttotal: 2.04s\tremaining: 2.81s\n",
      "421:\tlearn: 266044.3811617\ttotal: 2.05s\tremaining: 2.81s\n",
      "422:\tlearn: 266044.2536957\ttotal: 2.05s\tremaining: 2.8s\n",
      "423:\tlearn: 266043.8583953\ttotal: 2.06s\tremaining: 2.8s\n",
      "424:\tlearn: 266043.5824656\ttotal: 2.06s\tremaining: 2.79s\n",
      "425:\tlearn: 266043.4774585\ttotal: 2.06s\tremaining: 2.78s\n",
      "426:\tlearn: 266043.3495494\ttotal: 2.07s\tremaining: 2.78s\n",
      "427:\tlearn: 266043.2300072\ttotal: 2.07s\tremaining: 2.77s\n",
      "428:\tlearn: 266042.5801784\ttotal: 2.08s\tremaining: 2.77s\n",
      "429:\tlearn: 266042.1266663\ttotal: 2.08s\tremaining: 2.76s\n",
      "430:\tlearn: 266041.5362981\ttotal: 2.08s\tremaining: 2.75s\n",
      "431:\tlearn: 266041.0106938\ttotal: 2.09s\tremaining: 2.75s\n",
      "432:\tlearn: 266040.9049395\ttotal: 2.09s\tremaining: 2.74s\n",
      "433:\tlearn: 266040.3779615\ttotal: 2.1s\tremaining: 2.73s\n",
      "434:\tlearn: 266039.8726537\ttotal: 2.1s\tremaining: 2.73s\n",
      "435:\tlearn: 266039.3481634\ttotal: 2.11s\tremaining: 2.73s\n",
      "436:\tlearn: 266038.8944693\ttotal: 2.11s\tremaining: 2.72s\n",
      "437:\tlearn: 266038.4201680\ttotal: 2.11s\tremaining: 2.71s\n",
      "438:\tlearn: 266038.0854312\ttotal: 2.12s\tremaining: 2.71s\n",
      "439:\tlearn: 266037.6945870\ttotal: 2.12s\tremaining: 2.7s\n",
      "440:\tlearn: 266037.4797193\ttotal: 2.13s\tremaining: 2.69s\n",
      "441:\tlearn: 266036.9105744\ttotal: 2.13s\tremaining: 2.69s\n",
      "442:\tlearn: 266036.8586958\ttotal: 2.13s\tremaining: 2.68s\n",
      "443:\tlearn: 266036.3041586\ttotal: 2.14s\tremaining: 2.68s\n",
      "444:\tlearn: 266036.1065783\ttotal: 2.14s\tremaining: 2.67s\n",
      "445:\tlearn: 266035.6570011\ttotal: 2.14s\tremaining: 2.66s\n",
      "446:\tlearn: 266035.6074402\ttotal: 2.15s\tremaining: 2.65s\n",
      "447:\tlearn: 266035.5675247\ttotal: 2.15s\tremaining: 2.65s\n",
      "448:\tlearn: 266034.9955879\ttotal: 2.15s\tremaining: 2.64s\n",
      "449:\tlearn: 266034.6003021\ttotal: 2.15s\tremaining: 2.63s\n",
      "450:\tlearn: 266034.5552444\ttotal: 2.16s\tremaining: 2.63s\n",
      "451:\tlearn: 266034.5067462\ttotal: 2.16s\tremaining: 2.62s\n",
      "452:\tlearn: 266034.4724647\ttotal: 2.16s\tremaining: 2.61s\n",
      "453:\tlearn: 266034.0314816\ttotal: 2.17s\tremaining: 2.61s\n",
      "454:\tlearn: 266033.5868446\ttotal: 2.17s\tremaining: 2.6s\n",
      "455:\tlearn: 266033.3133434\ttotal: 2.17s\tremaining: 2.59s\n",
      "456:\tlearn: 266033.1811925\ttotal: 2.18s\tremaining: 2.58s\n",
      "457:\tlearn: 266033.1486044\ttotal: 2.18s\tremaining: 2.58s\n",
      "458:\tlearn: 266033.1176306\ttotal: 2.18s\tremaining: 2.57s\n",
      "459:\tlearn: 266032.8800471\ttotal: 2.18s\tremaining: 2.56s\n",
      "460:\tlearn: 266032.4910311\ttotal: 2.19s\tremaining: 2.56s\n",
      "461:\tlearn: 266032.4326073\ttotal: 2.19s\tremaining: 2.55s\n",
      "462:\tlearn: 266032.0866045\ttotal: 2.19s\tremaining: 2.54s\n",
      "463:\tlearn: 266031.9607975\ttotal: 2.2s\tremaining: 2.54s\n",
      "464:\tlearn: 266031.6244644\ttotal: 2.2s\tremaining: 2.53s\n",
      "465:\tlearn: 266031.1791541\ttotal: 2.2s\tremaining: 2.52s\n",
      "466:\tlearn: 266031.0276555\ttotal: 2.21s\tremaining: 2.52s\n",
      "467:\tlearn: 266030.8734684\ttotal: 2.21s\tremaining: 2.51s\n",
      "468:\tlearn: 266030.3691380\ttotal: 2.21s\tremaining: 2.51s\n",
      "469:\tlearn: 266029.9581662\ttotal: 2.22s\tremaining: 2.5s\n",
      "470:\tlearn: 266029.5633185\ttotal: 2.22s\tremaining: 2.49s\n",
      "471:\tlearn: 266029.2506054\ttotal: 2.23s\tremaining: 2.49s\n",
      "472:\tlearn: 266028.8561904\ttotal: 2.23s\tremaining: 2.48s\n",
      "473:\tlearn: 266028.5581363\ttotal: 2.23s\tremaining: 2.48s\n",
      "474:\tlearn: 266028.5269067\ttotal: 2.24s\tremaining: 2.47s\n",
      "475:\tlearn: 266028.0770904\ttotal: 2.24s\tremaining: 2.47s\n",
      "476:\tlearn: 266027.6754304\ttotal: 2.25s\tremaining: 2.46s\n",
      "477:\tlearn: 266027.6457156\ttotal: 2.25s\tremaining: 2.46s\n",
      "478:\tlearn: 266027.6174877\ttotal: 2.26s\tremaining: 2.46s\n",
      "479:\tlearn: 266027.2721602\ttotal: 2.26s\tremaining: 2.45s\n",
      "480:\tlearn: 266026.9707999\ttotal: 2.26s\tremaining: 2.44s\n",
      "481:\tlearn: 266026.5812281\ttotal: 2.27s\tremaining: 2.44s\n",
      "482:\tlearn: 266026.5543145\ttotal: 2.27s\tremaining: 2.44s\n",
      "483:\tlearn: 266026.3616845\ttotal: 2.28s\tremaining: 2.43s\n",
      "484:\tlearn: 266026.3362049\ttotal: 2.28s\tremaining: 2.42s\n",
      "485:\tlearn: 266025.9036765\ttotal: 2.29s\tremaining: 2.42s\n",
      "486:\tlearn: 266025.5360505\ttotal: 2.29s\tremaining: 2.41s\n",
      "487:\tlearn: 266025.2632938\ttotal: 2.29s\tremaining: 2.41s\n",
      "488:\tlearn: 266025.2388131\ttotal: 2.3s\tremaining: 2.4s\n",
      "489:\tlearn: 266024.8432556\ttotal: 2.3s\tremaining: 2.39s\n",
      "490:\tlearn: 266024.5866680\ttotal: 2.31s\tremaining: 2.39s\n",
      "491:\tlearn: 266024.2510274\ttotal: 2.31s\tremaining: 2.38s\n",
      "492:\tlearn: 266023.9856003\ttotal: 2.31s\tremaining: 2.38s\n",
      "493:\tlearn: 266023.6050903\ttotal: 2.31s\tremaining: 2.37s\n",
      "494:\tlearn: 266023.2211007\ttotal: 2.32s\tremaining: 2.37s\n",
      "495:\tlearn: 266023.0310489\ttotal: 2.32s\tremaining: 2.36s\n",
      "496:\tlearn: 266022.7071304\ttotal: 2.33s\tremaining: 2.35s\n",
      "497:\tlearn: 266022.6851671\ttotal: 2.33s\tremaining: 2.35s\n",
      "498:\tlearn: 266022.3472731\ttotal: 2.33s\tremaining: 2.34s\n",
      "499:\tlearn: 266022.0592148\ttotal: 2.34s\tremaining: 2.34s\n",
      "500:\tlearn: 266021.7987564\ttotal: 2.34s\tremaining: 2.33s\n",
      "501:\tlearn: 266021.4975623\ttotal: 2.34s\tremaining: 2.33s\n",
      "502:\tlearn: 266021.4767179\ttotal: 2.35s\tremaining: 2.32s\n",
      "503:\tlearn: 266021.2549553\ttotal: 2.35s\tremaining: 2.32s\n",
      "504:\tlearn: 266020.9105771\ttotal: 2.36s\tremaining: 2.31s\n",
      "505:\tlearn: 266020.6373008\ttotal: 2.36s\tremaining: 2.3s\n",
      "506:\tlearn: 266020.5194098\ttotal: 2.36s\tremaining: 2.3s\n",
      "507:\tlearn: 266020.5016856\ttotal: 2.37s\tremaining: 2.29s\n",
      "508:\tlearn: 266020.4829182\ttotal: 2.37s\tremaining: 2.29s\n",
      "509:\tlearn: 266020.2304696\ttotal: 2.37s\tremaining: 2.28s\n",
      "510:\tlearn: 266019.9405655\ttotal: 2.38s\tremaining: 2.27s\n",
      "511:\tlearn: 266019.6817912\ttotal: 2.38s\tremaining: 2.27s\n",
      "512:\tlearn: 266019.5714272\ttotal: 2.39s\tremaining: 2.27s\n",
      "513:\tlearn: 266019.5535200\ttotal: 2.39s\tremaining: 2.26s\n",
      "514:\tlearn: 266019.1950320\ttotal: 2.39s\tremaining: 2.25s\n",
      "515:\tlearn: 266019.0734089\ttotal: 2.4s\tremaining: 2.25s\n",
      "516:\tlearn: 266018.7738841\ttotal: 2.4s\tremaining: 2.24s\n",
      "517:\tlearn: 266018.7574241\ttotal: 2.4s\tremaining: 2.23s\n",
      "518:\tlearn: 266018.5247799\ttotal: 2.41s\tremaining: 2.23s\n",
      "519:\tlearn: 266018.2462147\ttotal: 2.41s\tremaining: 2.23s\n",
      "520:\tlearn: 266018.0012098\ttotal: 2.42s\tremaining: 2.22s\n",
      "521:\tlearn: 266017.9854709\ttotal: 2.42s\tremaining: 2.22s\n",
      "522:\tlearn: 266017.7450211\ttotal: 2.43s\tremaining: 2.21s\n",
      "523:\tlearn: 266017.4303571\ttotal: 2.43s\tremaining: 2.21s\n",
      "524:\tlearn: 266017.1792083\ttotal: 2.43s\tremaining: 2.2s\n",
      "525:\tlearn: 266016.8529049\ttotal: 2.44s\tremaining: 2.19s\n",
      "526:\tlearn: 266016.7433614\ttotal: 2.44s\tremaining: 2.19s\n",
      "527:\tlearn: 266016.4685404\ttotal: 2.45s\tremaining: 2.19s\n",
      "528:\tlearn: 266016.3587549\ttotal: 2.45s\tremaining: 2.18s\n",
      "529:\tlearn: 266016.1850284\ttotal: 2.45s\tremaining: 2.17s\n",
      "530:\tlearn: 266015.9959197\ttotal: 2.46s\tremaining: 2.17s\n",
      "531:\tlearn: 266015.7808862\ttotal: 2.46s\tremaining: 2.17s\n",
      "532:\tlearn: 266015.5100706\ttotal: 2.51s\tremaining: 2.2s\n",
      "533:\tlearn: 266015.3661943\ttotal: 2.53s\tremaining: 2.21s\n",
      "534:\tlearn: 266015.2752397\ttotal: 2.53s\tremaining: 2.2s\n",
      "535:\tlearn: 266015.0440362\ttotal: 2.53s\tremaining: 2.19s\n",
      "536:\tlearn: 266014.8026462\ttotal: 2.54s\tremaining: 2.19s\n",
      "537:\tlearn: 266014.6517890\ttotal: 2.55s\tremaining: 2.19s\n",
      "538:\tlearn: 266014.4677452\ttotal: 2.56s\tremaining: 2.19s\n",
      "539:\tlearn: 266014.1950364\ttotal: 2.56s\tremaining: 2.18s\n",
      "540:\tlearn: 266013.9949723\ttotal: 2.56s\tremaining: 2.18s\n",
      "541:\tlearn: 266013.7924215\ttotal: 2.57s\tremaining: 2.17s\n",
      "542:\tlearn: 266013.5232966\ttotal: 2.58s\tremaining: 2.17s\n",
      "543:\tlearn: 266013.3741034\ttotal: 2.58s\tremaining: 2.16s\n",
      "544:\tlearn: 266013.2205348\ttotal: 2.58s\tremaining: 2.15s\n",
      "545:\tlearn: 266012.9961532\ttotal: 2.59s\tremaining: 2.15s\n",
      "546:\tlearn: 266012.8011205\ttotal: 2.59s\tremaining: 2.15s\n",
      "547:\tlearn: 266012.7368354\ttotal: 2.6s\tremaining: 2.14s\n",
      "548:\tlearn: 266012.6512844\ttotal: 2.6s\tremaining: 2.13s\n",
      "549:\tlearn: 266012.4830432\ttotal: 2.6s\tremaining: 2.13s\n",
      "550:\tlearn: 266012.2397731\ttotal: 2.61s\tremaining: 2.12s\n",
      "551:\tlearn: 266012.0384345\ttotal: 2.61s\tremaining: 2.12s\n",
      "552:\tlearn: 266011.8491547\ttotal: 2.61s\tremaining: 2.11s\n",
      "553:\tlearn: 266011.7581405\ttotal: 2.62s\tremaining: 2.11s\n",
      "554:\tlearn: 266011.5554932\ttotal: 2.62s\tremaining: 2.1s\n",
      "555:\tlearn: 266011.3924248\ttotal: 2.63s\tremaining: 2.1s\n",
      "556:\tlearn: 266011.2220527\ttotal: 2.63s\tremaining: 2.09s\n",
      "557:\tlearn: 266011.1189451\ttotal: 2.63s\tremaining: 2.09s\n",
      "558:\tlearn: 266010.9423529\ttotal: 2.64s\tremaining: 2.08s\n",
      "559:\tlearn: 266010.7679510\ttotal: 2.64s\tremaining: 2.08s\n",
      "560:\tlearn: 266010.5826079\ttotal: 2.65s\tremaining: 2.07s\n",
      "561:\tlearn: 266010.3691870\ttotal: 2.65s\tremaining: 2.07s\n",
      "562:\tlearn: 266010.1494163\ttotal: 2.65s\tremaining: 2.06s\n",
      "563:\tlearn: 266010.0132933\ttotal: 2.66s\tremaining: 2.06s\n",
      "564:\tlearn: 266009.8132880\ttotal: 2.66s\tremaining: 2.05s\n",
      "565:\tlearn: 266009.7141020\ttotal: 2.67s\tremaining: 2.04s\n",
      "566:\tlearn: 266009.5562342\ttotal: 2.67s\tremaining: 2.04s\n",
      "567:\tlearn: 266009.4633935\ttotal: 2.68s\tremaining: 2.04s\n",
      "568:\tlearn: 266009.2646307\ttotal: 2.68s\tremaining: 2.03s\n",
      "569:\tlearn: 266009.0471892\ttotal: 2.68s\tremaining: 2.02s\n",
      "570:\tlearn: 266008.8701735\ttotal: 2.69s\tremaining: 2.02s\n",
      "571:\tlearn: 266008.8566212\ttotal: 2.69s\tremaining: 2.01s\n",
      "572:\tlearn: 266008.7842140\ttotal: 2.69s\tremaining: 2.01s\n",
      "573:\tlearn: 266008.6062633\ttotal: 2.69s\tremaining: 2s\n",
      "574:\tlearn: 266008.3672894\ttotal: 2.7s\tremaining: 2s\n",
      "575:\tlearn: 266008.3042885\ttotal: 2.7s\tremaining: 1.99s\n",
      "576:\tlearn: 266008.1454559\ttotal: 2.71s\tremaining: 1.98s\n",
      "577:\tlearn: 266008.0619037\ttotal: 2.71s\tremaining: 1.98s\n",
      "578:\tlearn: 266007.9683291\ttotal: 2.71s\tremaining: 1.97s\n",
      "579:\tlearn: 266007.7007989\ttotal: 2.71s\tremaining: 1.97s\n",
      "580:\tlearn: 266007.5611779\ttotal: 2.72s\tremaining: 1.96s\n",
      "581:\tlearn: 266007.3168226\ttotal: 2.72s\tremaining: 1.96s\n",
      "582:\tlearn: 266007.2146914\ttotal: 2.73s\tremaining: 1.95s\n",
      "583:\tlearn: 266007.0810295\ttotal: 2.73s\tremaining: 1.94s\n",
      "584:\tlearn: 266007.0167319\ttotal: 2.73s\tremaining: 1.94s\n",
      "585:\tlearn: 266006.9183659\ttotal: 2.73s\tremaining: 1.93s\n",
      "586:\tlearn: 266006.8199373\ttotal: 2.74s\tremaining: 1.93s\n",
      "587:\tlearn: 266006.6601677\ttotal: 2.75s\tremaining: 1.92s\n",
      "588:\tlearn: 266006.5267551\ttotal: 2.75s\tremaining: 1.92s\n",
      "589:\tlearn: 266006.3526793\ttotal: 2.75s\tremaining: 1.91s\n",
      "590:\tlearn: 266006.2101534\ttotal: 2.75s\tremaining: 1.91s\n",
      "591:\tlearn: 266006.0593967\ttotal: 2.76s\tremaining: 1.9s\n",
      "592:\tlearn: 266005.8890500\ttotal: 2.76s\tremaining: 1.9s\n",
      "593:\tlearn: 266005.7967970\ttotal: 2.76s\tremaining: 1.89s\n",
      "594:\tlearn: 266005.6621678\ttotal: 2.77s\tremaining: 1.88s\n",
      "595:\tlearn: 266005.6428165\ttotal: 2.77s\tremaining: 1.88s\n",
      "596:\tlearn: 266005.4623291\ttotal: 2.78s\tremaining: 1.87s\n",
      "597:\tlearn: 266005.3044428\ttotal: 2.78s\tremaining: 1.87s\n",
      "598:\tlearn: 266005.2583737\ttotal: 2.78s\tremaining: 1.86s\n",
      "599:\tlearn: 266005.1806418\ttotal: 2.79s\tremaining: 1.86s\n",
      "600:\tlearn: 266005.0173721\ttotal: 2.79s\tremaining: 1.85s\n",
      "601:\tlearn: 266004.8932170\ttotal: 2.79s\tremaining: 1.85s\n",
      "602:\tlearn: 266004.7797513\ttotal: 2.79s\tremaining: 1.84s\n",
      "603:\tlearn: 266004.7691166\ttotal: 2.8s\tremaining: 1.83s\n",
      "604:\tlearn: 266004.6449855\ttotal: 2.8s\tremaining: 1.83s\n",
      "605:\tlearn: 266004.5442910\ttotal: 2.81s\tremaining: 1.82s\n",
      "606:\tlearn: 266004.3569410\ttotal: 2.81s\tremaining: 1.82s\n",
      "607:\tlearn: 266004.1927912\ttotal: 2.82s\tremaining: 1.82s\n",
      "608:\tlearn: 266004.1827264\ttotal: 2.82s\tremaining: 1.81s\n",
      "609:\tlearn: 266004.0597890\ttotal: 2.83s\tremaining: 1.81s\n",
      "610:\tlearn: 266004.0115588\ttotal: 2.83s\tremaining: 1.8s\n",
      "611:\tlearn: 266003.8344723\ttotal: 2.83s\tremaining: 1.8s\n",
      "612:\tlearn: 266003.6960375\ttotal: 2.84s\tremaining: 1.79s\n",
      "613:\tlearn: 266003.5990599\ttotal: 2.85s\tremaining: 1.79s\n",
      "614:\tlearn: 266003.4386909\ttotal: 2.85s\tremaining: 1.78s\n",
      "615:\tlearn: 266003.3014872\ttotal: 2.86s\tremaining: 1.78s\n",
      "616:\tlearn: 266003.1672042\ttotal: 2.86s\tremaining: 1.78s\n",
      "617:\tlearn: 266003.0550262\ttotal: 2.87s\tremaining: 1.77s\n",
      "618:\tlearn: 266002.8891680\ttotal: 2.87s\tremaining: 1.77s\n",
      "619:\tlearn: 266002.7215363\ttotal: 2.88s\tremaining: 1.76s\n",
      "620:\tlearn: 266002.7131280\ttotal: 2.88s\tremaining: 1.76s\n",
      "621:\tlearn: 266002.5798382\ttotal: 2.89s\tremaining: 1.75s\n",
      "622:\tlearn: 266002.4687325\ttotal: 2.89s\tremaining: 1.75s\n",
      "623:\tlearn: 266002.3906179\ttotal: 2.89s\tremaining: 1.74s\n",
      "624:\tlearn: 266002.3268392\ttotal: 2.9s\tremaining: 1.74s\n",
      "625:\tlearn: 266002.2690064\ttotal: 2.9s\tremaining: 1.73s\n",
      "626:\tlearn: 266002.1698404\ttotal: 2.9s\tremaining: 1.73s\n",
      "627:\tlearn: 266002.0187542\ttotal: 2.91s\tremaining: 1.72s\n",
      "628:\tlearn: 266001.9258170\ttotal: 2.91s\tremaining: 1.72s\n",
      "629:\tlearn: 266001.8690604\ttotal: 2.91s\tremaining: 1.71s\n",
      "630:\tlearn: 266001.8543751\ttotal: 2.92s\tremaining: 1.71s\n",
      "631:\tlearn: 266001.7669899\ttotal: 2.92s\tremaining: 1.7s\n",
      "632:\tlearn: 266001.6262552\ttotal: 2.93s\tremaining: 1.7s\n",
      "633:\tlearn: 266001.5763553\ttotal: 2.93s\tremaining: 1.69s\n",
      "634:\tlearn: 266001.5657595\ttotal: 2.93s\tremaining: 1.69s\n",
      "635:\tlearn: 266001.5585143\ttotal: 2.94s\tremaining: 1.68s\n",
      "636:\tlearn: 266001.5496640\ttotal: 2.94s\tremaining: 1.68s\n",
      "637:\tlearn: 266001.4224605\ttotal: 2.94s\tremaining: 1.67s\n",
      "638:\tlearn: 266001.3156182\ttotal: 2.95s\tremaining: 1.66s\n",
      "639:\tlearn: 266001.1615208\ttotal: 2.95s\tremaining: 1.66s\n",
      "640:\tlearn: 266001.1179825\ttotal: 2.95s\tremaining: 1.65s\n",
      "641:\tlearn: 266001.1106237\ttotal: 2.96s\tremaining: 1.65s\n",
      "642:\tlearn: 266001.0647193\ttotal: 2.96s\tremaining: 1.64s\n",
      "643:\tlearn: 266000.9203699\ttotal: 2.96s\tremaining: 1.64s\n",
      "644:\tlearn: 266000.8039014\ttotal: 2.96s\tremaining: 1.63s\n",
      "645:\tlearn: 266000.6781795\ttotal: 2.97s\tremaining: 1.63s\n",
      "646:\tlearn: 266000.5981715\ttotal: 2.97s\tremaining: 1.62s\n",
      "647:\tlearn: 266000.4719031\ttotal: 2.97s\tremaining: 1.61s\n",
      "648:\tlearn: 266000.3624329\ttotal: 2.98s\tremaining: 1.61s\n",
      "649:\tlearn: 266000.2963953\ttotal: 2.98s\tremaining: 1.6s\n",
      "650:\tlearn: 266000.2178238\ttotal: 2.98s\tremaining: 1.6s\n",
      "651:\tlearn: 266000.1769546\ttotal: 2.99s\tremaining: 1.59s\n",
      "652:\tlearn: 266000.0616443\ttotal: 2.99s\tremaining: 1.59s\n",
      "653:\tlearn: 266000.0544237\ttotal: 2.99s\tremaining: 1.58s\n",
      "654:\tlearn: 266000.0476257\ttotal: 3s\tremaining: 1.58s\n",
      "655:\tlearn: 265999.9289312\ttotal: 3s\tremaining: 1.57s\n",
      "656:\tlearn: 265999.8212214\ttotal: 3.01s\tremaining: 1.57s\n",
      "657:\tlearn: 265999.7791429\ttotal: 3.01s\tremaining: 1.56s\n",
      "658:\tlearn: 265999.7123283\ttotal: 3.02s\tremaining: 1.56s\n",
      "659:\tlearn: 265999.5856940\ttotal: 3.02s\tremaining: 1.56s\n",
      "660:\tlearn: 265999.5534594\ttotal: 3.02s\tremaining: 1.55s\n",
      "661:\tlearn: 265999.5248883\ttotal: 3.03s\tremaining: 1.55s\n",
      "662:\tlearn: 265999.4171912\ttotal: 3.03s\tremaining: 1.54s\n",
      "663:\tlearn: 265999.2997463\ttotal: 3.03s\tremaining: 1.53s\n",
      "664:\tlearn: 265999.2016925\ttotal: 3.04s\tremaining: 1.53s\n",
      "665:\tlearn: 265999.1118898\ttotal: 3.04s\tremaining: 1.52s\n",
      "666:\tlearn: 265999.0117944\ttotal: 3.04s\tremaining: 1.52s\n",
      "667:\tlearn: 265998.9199718\ttotal: 3.05s\tremaining: 1.51s\n",
      "668:\tlearn: 265998.8479417\ttotal: 3.05s\tremaining: 1.51s\n",
      "669:\tlearn: 265998.7400353\ttotal: 3.06s\tremaining: 1.51s\n",
      "670:\tlearn: 265998.6659860\ttotal: 3.06s\tremaining: 1.5s\n",
      "671:\tlearn: 265998.5611061\ttotal: 3.07s\tremaining: 1.5s\n",
      "672:\tlearn: 265998.4682335\ttotal: 3.07s\tremaining: 1.49s\n",
      "673:\tlearn: 265998.4613665\ttotal: 3.07s\tremaining: 1.49s\n",
      "674:\tlearn: 265998.3667229\ttotal: 3.08s\tremaining: 1.48s\n",
      "675:\tlearn: 265998.2642732\ttotal: 3.08s\tremaining: 1.48s\n",
      "676:\tlearn: 265998.1590468\ttotal: 3.08s\tremaining: 1.47s\n",
      "677:\tlearn: 265998.1532986\ttotal: 3.08s\tremaining: 1.47s\n",
      "678:\tlearn: 265998.1219889\ttotal: 3.09s\tremaining: 1.46s\n",
      "679:\tlearn: 265998.0540841\ttotal: 3.09s\tremaining: 1.46s\n",
      "680:\tlearn: 265997.9770683\ttotal: 3.1s\tremaining: 1.45s\n",
      "681:\tlearn: 265997.8916202\ttotal: 3.1s\tremaining: 1.44s\n",
      "682:\tlearn: 265997.8848569\ttotal: 3.1s\tremaining: 1.44s\n",
      "683:\tlearn: 265997.7952836\ttotal: 3.11s\tremaining: 1.44s\n",
      "684:\tlearn: 265997.7244280\ttotal: 3.11s\tremaining: 1.43s\n",
      "685:\tlearn: 265997.6481821\ttotal: 3.12s\tremaining: 1.43s\n",
      "686:\tlearn: 265997.5537197\ttotal: 3.12s\tremaining: 1.42s\n",
      "687:\tlearn: 265997.4301434\ttotal: 3.13s\tremaining: 1.42s\n",
      "688:\tlearn: 265997.3221921\ttotal: 3.13s\tremaining: 1.41s\n",
      "689:\tlearn: 265997.2149285\ttotal: 3.13s\tremaining: 1.41s\n",
      "690:\tlearn: 265997.1793205\ttotal: 3.14s\tremaining: 1.4s\n",
      "691:\tlearn: 265997.1340038\ttotal: 3.14s\tremaining: 1.4s\n",
      "692:\tlearn: 265997.0571143\ttotal: 3.14s\tremaining: 1.39s\n",
      "693:\tlearn: 265997.0512457\ttotal: 3.14s\tremaining: 1.39s\n",
      "694:\tlearn: 265996.9491282\ttotal: 3.15s\tremaining: 1.38s\n",
      "695:\tlearn: 265996.8777108\ttotal: 3.15s\tremaining: 1.38s\n",
      "696:\tlearn: 265996.8145927\ttotal: 3.15s\tremaining: 1.37s\n",
      "697:\tlearn: 265996.7193286\ttotal: 3.16s\tremaining: 1.37s\n",
      "698:\tlearn: 265996.6738953\ttotal: 3.16s\tremaining: 1.36s\n",
      "699:\tlearn: 265996.6196107\ttotal: 3.16s\tremaining: 1.35s\n",
      "700:\tlearn: 265996.5156767\ttotal: 3.17s\tremaining: 1.35s\n",
      "701:\tlearn: 265996.4819970\ttotal: 3.17s\tremaining: 1.34s\n",
      "702:\tlearn: 265996.4236959\ttotal: 3.17s\tremaining: 1.34s\n",
      "703:\tlearn: 265996.3743697\ttotal: 3.17s\tremaining: 1.33s\n",
      "704:\tlearn: 265996.3108984\ttotal: 3.18s\tremaining: 1.33s\n",
      "705:\tlearn: 265996.2314576\ttotal: 3.18s\tremaining: 1.32s\n",
      "706:\tlearn: 265996.1439543\ttotal: 3.19s\tremaining: 1.32s\n",
      "707:\tlearn: 265996.0920752\ttotal: 3.19s\tremaining: 1.31s\n",
      "708:\tlearn: 265996.0215219\ttotal: 3.19s\tremaining: 1.31s\n",
      "709:\tlearn: 265995.9761111\ttotal: 3.19s\tremaining: 1.3s\n",
      "710:\tlearn: 265995.8874006\ttotal: 3.2s\tremaining: 1.3s\n",
      "711:\tlearn: 265995.8211239\ttotal: 3.2s\tremaining: 1.3s\n",
      "712:\tlearn: 265995.7538986\ttotal: 3.21s\tremaining: 1.29s\n",
      "713:\tlearn: 265995.6914840\ttotal: 3.21s\tremaining: 1.29s\n",
      "714:\tlearn: 265995.6500073\ttotal: 3.22s\tremaining: 1.28s\n",
      "715:\tlearn: 265995.6106324\ttotal: 3.22s\tremaining: 1.28s\n",
      "716:\tlearn: 265995.5371611\ttotal: 3.23s\tremaining: 1.27s\n",
      "717:\tlearn: 265995.4555477\ttotal: 3.27s\tremaining: 1.28s\n",
      "718:\tlearn: 265995.3980016\ttotal: 3.3s\tremaining: 1.29s\n",
      "719:\tlearn: 265995.3101488\ttotal: 3.3s\tremaining: 1.28s\n",
      "720:\tlearn: 265995.2215407\ttotal: 3.31s\tremaining: 1.28s\n",
      "721:\tlearn: 265995.1353498\ttotal: 3.31s\tremaining: 1.27s\n",
      "722:\tlearn: 265995.0706678\ttotal: 3.33s\tremaining: 1.27s\n",
      "723:\tlearn: 265995.0035630\ttotal: 3.33s\tremaining: 1.27s\n",
      "724:\tlearn: 265994.9770765\ttotal: 3.34s\tremaining: 1.26s\n",
      "725:\tlearn: 265994.9664518\ttotal: 3.34s\tremaining: 1.26s\n",
      "726:\tlearn: 265994.9239269\ttotal: 3.35s\tremaining: 1.26s\n",
      "727:\tlearn: 265994.9195039\ttotal: 3.35s\tremaining: 1.25s\n",
      "728:\tlearn: 265994.8337088\ttotal: 3.36s\tremaining: 1.25s\n",
      "729:\tlearn: 265994.7824874\ttotal: 3.36s\tremaining: 1.24s\n",
      "730:\tlearn: 265994.7032387\ttotal: 3.37s\tremaining: 1.24s\n",
      "731:\tlearn: 265994.6663023\ttotal: 3.37s\tremaining: 1.23s\n",
      "732:\tlearn: 265994.6474369\ttotal: 3.37s\tremaining: 1.23s\n",
      "733:\tlearn: 265994.5936831\ttotal: 3.38s\tremaining: 1.22s\n",
      "734:\tlearn: 265994.5227113\ttotal: 3.38s\tremaining: 1.22s\n",
      "735:\tlearn: 265994.4605675\ttotal: 3.38s\tremaining: 1.21s\n",
      "736:\tlearn: 265994.4563228\ttotal: 3.38s\tremaining: 1.21s\n",
      "737:\tlearn: 265994.3804640\ttotal: 3.39s\tremaining: 1.2s\n",
      "738:\tlearn: 265994.3159831\ttotal: 3.39s\tremaining: 1.2s\n",
      "739:\tlearn: 265994.2733847\ttotal: 3.4s\tremaining: 1.19s\n",
      "740:\tlearn: 265994.2444450\ttotal: 3.4s\tremaining: 1.19s\n",
      "741:\tlearn: 265994.2069164\ttotal: 3.41s\tremaining: 1.18s\n",
      "742:\tlearn: 265994.1476472\ttotal: 3.41s\tremaining: 1.18s\n",
      "743:\tlearn: 265994.1384072\ttotal: 3.41s\tremaining: 1.17s\n",
      "744:\tlearn: 265994.1046835\ttotal: 3.42s\tremaining: 1.17s\n",
      "745:\tlearn: 265994.0668755\ttotal: 3.42s\tremaining: 1.17s\n",
      "746:\tlearn: 265994.0079679\ttotal: 3.42s\tremaining: 1.16s\n",
      "747:\tlearn: 265993.9339135\ttotal: 3.43s\tremaining: 1.15s\n",
      "748:\tlearn: 265993.8991842\ttotal: 3.43s\tremaining: 1.15s\n",
      "749:\tlearn: 265993.8530091\ttotal: 3.44s\tremaining: 1.15s\n",
      "750:\tlearn: 265993.7743780\ttotal: 3.44s\tremaining: 1.14s\n",
      "751:\tlearn: 265993.7435078\ttotal: 3.44s\tremaining: 1.14s\n",
      "752:\tlearn: 265993.7062895\ttotal: 3.44s\tremaining: 1.13s\n",
      "753:\tlearn: 265993.6663673\ttotal: 3.45s\tremaining: 1.13s\n",
      "754:\tlearn: 265993.6421317\ttotal: 3.45s\tremaining: 1.12s\n",
      "755:\tlearn: 265993.6209951\ttotal: 3.46s\tremaining: 1.12s\n",
      "756:\tlearn: 265993.5614273\ttotal: 3.46s\tremaining: 1.11s\n",
      "757:\tlearn: 265993.4986963\ttotal: 3.46s\tremaining: 1.11s\n",
      "758:\tlearn: 265993.4468321\ttotal: 3.47s\tremaining: 1.1s\n",
      "759:\tlearn: 265993.3989155\ttotal: 3.47s\tremaining: 1.1s\n",
      "760:\tlearn: 265993.3586614\ttotal: 3.47s\tremaining: 1.09s\n",
      "761:\tlearn: 265993.2881048\ttotal: 3.48s\tremaining: 1.08s\n",
      "762:\tlearn: 265993.2478023\ttotal: 3.48s\tremaining: 1.08s\n",
      "763:\tlearn: 265993.2402071\ttotal: 3.48s\tremaining: 1.08s\n",
      "764:\tlearn: 265993.1760160\ttotal: 3.49s\tremaining: 1.07s\n",
      "765:\tlearn: 265993.1131398\ttotal: 3.49s\tremaining: 1.07s\n",
      "766:\tlearn: 265993.0572452\ttotal: 3.49s\tremaining: 1.06s\n",
      "767:\tlearn: 265993.0135899\ttotal: 3.5s\tremaining: 1.06s\n",
      "768:\tlearn: 265993.0000645\ttotal: 3.5s\tremaining: 1.05s\n",
      "769:\tlearn: 265992.9490347\ttotal: 3.5s\tremaining: 1.05s\n",
      "770:\tlearn: 265992.8910901\ttotal: 3.5s\tremaining: 1.04s\n",
      "771:\tlearn: 265992.8260614\ttotal: 3.51s\tremaining: 1.04s\n",
      "772:\tlearn: 265992.7638719\ttotal: 3.51s\tremaining: 1.03s\n",
      "773:\tlearn: 265992.6801616\ttotal: 3.51s\tremaining: 1.03s\n",
      "774:\tlearn: 265992.6769188\ttotal: 3.52s\tremaining: 1.02s\n",
      "775:\tlearn: 265992.6483152\ttotal: 3.52s\tremaining: 1.02s\n",
      "776:\tlearn: 265992.6135626\ttotal: 3.52s\tremaining: 1.01s\n",
      "777:\tlearn: 265992.6105241\ttotal: 3.52s\tremaining: 1s\n",
      "778:\tlearn: 265992.5948048\ttotal: 3.53s\tremaining: 1s\n",
      "779:\tlearn: 265992.5833636\ttotal: 3.53s\tremaining: 996ms\n",
      "780:\tlearn: 265992.5268280\ttotal: 3.54s\tremaining: 991ms\n",
      "781:\tlearn: 265992.4983129\ttotal: 3.54s\tremaining: 987ms\n",
      "782:\tlearn: 265992.4572209\ttotal: 3.54s\tremaining: 982ms\n",
      "783:\tlearn: 265992.3965616\ttotal: 3.55s\tremaining: 977ms\n",
      "784:\tlearn: 265992.3878384\ttotal: 3.55s\tremaining: 972ms\n",
      "785:\tlearn: 265992.3313412\ttotal: 3.55s\tremaining: 968ms\n",
      "786:\tlearn: 265992.2945571\ttotal: 3.56s\tremaining: 962ms\n",
      "787:\tlearn: 265992.2658058\ttotal: 3.56s\tremaining: 958ms\n",
      "788:\tlearn: 265992.2096417\ttotal: 3.56s\tremaining: 953ms\n",
      "789:\tlearn: 265992.1435234\ttotal: 3.57s\tremaining: 948ms\n",
      "790:\tlearn: 265992.1030130\ttotal: 3.57s\tremaining: 943ms\n",
      "791:\tlearn: 265992.0403174\ttotal: 3.57s\tremaining: 938ms\n",
      "792:\tlearn: 265992.0048933\ttotal: 3.58s\tremaining: 934ms\n",
      "793:\tlearn: 265991.9786415\ttotal: 3.58s\tremaining: 929ms\n",
      "794:\tlearn: 265991.9495259\ttotal: 3.58s\tremaining: 924ms\n",
      "795:\tlearn: 265991.9082641\ttotal: 3.59s\tremaining: 919ms\n",
      "796:\tlearn: 265991.9033164\ttotal: 3.59s\tremaining: 915ms\n",
      "797:\tlearn: 265991.8604183\ttotal: 3.6s\tremaining: 911ms\n",
      "798:\tlearn: 265991.8241029\ttotal: 3.6s\tremaining: 905ms\n",
      "799:\tlearn: 265991.8218009\ttotal: 3.6s\tremaining: 900ms\n",
      "800:\tlearn: 265991.8109059\ttotal: 3.6s\tremaining: 896ms\n",
      "801:\tlearn: 265991.7556963\ttotal: 3.61s\tremaining: 891ms\n",
      "802:\tlearn: 265991.7470362\ttotal: 3.61s\tremaining: 886ms\n",
      "803:\tlearn: 265991.7231666\ttotal: 3.62s\tremaining: 881ms\n",
      "804:\tlearn: 265991.6564409\ttotal: 3.62s\tremaining: 877ms\n",
      "805:\tlearn: 265991.6084241\ttotal: 3.62s\tremaining: 872ms\n",
      "806:\tlearn: 265991.5830955\ttotal: 3.63s\tremaining: 868ms\n",
      "807:\tlearn: 265991.5305186\ttotal: 3.63s\tremaining: 863ms\n",
      "808:\tlearn: 265991.4829984\ttotal: 3.63s\tremaining: 858ms\n",
      "809:\tlearn: 265991.4808894\ttotal: 3.64s\tremaining: 853ms\n",
      "810:\tlearn: 265991.4455362\ttotal: 3.64s\tremaining: 849ms\n",
      "811:\tlearn: 265991.4213914\ttotal: 3.64s\tremaining: 844ms\n",
      "812:\tlearn: 265991.3836235\ttotal: 3.65s\tremaining: 839ms\n",
      "813:\tlearn: 265991.3195881\ttotal: 3.65s\tremaining: 835ms\n",
      "814:\tlearn: 265991.2759541\ttotal: 3.66s\tremaining: 830ms\n",
      "815:\tlearn: 265991.2326937\ttotal: 3.66s\tremaining: 825ms\n",
      "816:\tlearn: 265991.2243608\ttotal: 3.66s\tremaining: 820ms\n",
      "817:\tlearn: 265991.1809391\ttotal: 3.67s\tremaining: 816ms\n",
      "818:\tlearn: 265991.1685968\ttotal: 3.67s\tremaining: 811ms\n",
      "819:\tlearn: 265991.1645326\ttotal: 3.67s\tremaining: 806ms\n",
      "820:\tlearn: 265991.1362490\ttotal: 3.67s\tremaining: 801ms\n",
      "821:\tlearn: 265991.1308880\ttotal: 3.68s\tremaining: 796ms\n",
      "822:\tlearn: 265991.1284244\ttotal: 3.68s\tremaining: 792ms\n",
      "823:\tlearn: 265991.0719698\ttotal: 3.69s\tremaining: 787ms\n",
      "824:\tlearn: 265991.0417566\ttotal: 3.69s\tremaining: 782ms\n",
      "825:\tlearn: 265990.9995789\ttotal: 3.69s\tremaining: 778ms\n",
      "826:\tlearn: 265990.9946794\ttotal: 3.7s\tremaining: 773ms\n",
      "827:\tlearn: 265990.9688813\ttotal: 3.7s\tremaining: 768ms\n",
      "828:\tlearn: 265990.9515133\ttotal: 3.7s\tremaining: 764ms\n",
      "829:\tlearn: 265990.9316728\ttotal: 3.7s\tremaining: 759ms\n",
      "830:\tlearn: 265990.8815043\ttotal: 3.71s\tremaining: 754ms\n",
      "831:\tlearn: 265990.8513038\ttotal: 3.71s\tremaining: 749ms\n",
      "832:\tlearn: 265990.8048973\ttotal: 3.71s\tremaining: 745ms\n",
      "833:\tlearn: 265990.7419267\ttotal: 3.72s\tremaining: 740ms\n",
      "834:\tlearn: 265990.7003607\ttotal: 3.72s\tremaining: 735ms\n",
      "835:\tlearn: 265990.6843770\ttotal: 3.72s\tremaining: 730ms\n",
      "836:\tlearn: 265990.6313956\ttotal: 3.73s\tremaining: 725ms\n",
      "837:\tlearn: 265990.5851969\ttotal: 3.73s\tremaining: 721ms\n",
      "838:\tlearn: 265990.5354921\ttotal: 3.73s\tremaining: 716ms\n",
      "839:\tlearn: 265990.5103624\ttotal: 3.74s\tremaining: 712ms\n",
      "840:\tlearn: 265990.5087205\ttotal: 3.74s\tremaining: 707ms\n",
      "841:\tlearn: 265990.5062604\ttotal: 3.74s\tremaining: 702ms\n",
      "842:\tlearn: 265990.4878756\ttotal: 3.74s\tremaining: 697ms\n",
      "843:\tlearn: 265990.4836294\ttotal: 3.75s\tremaining: 693ms\n",
      "844:\tlearn: 265990.4405275\ttotal: 3.75s\tremaining: 688ms\n",
      "845:\tlearn: 265990.4048904\ttotal: 3.75s\tremaining: 683ms\n",
      "846:\tlearn: 265990.3583911\ttotal: 3.76s\tremaining: 679ms\n",
      "847:\tlearn: 265990.3150082\ttotal: 3.77s\tremaining: 675ms\n",
      "848:\tlearn: 265990.2695538\ttotal: 3.77s\tremaining: 670ms\n",
      "849:\tlearn: 265990.2481912\ttotal: 3.77s\tremaining: 666ms\n",
      "850:\tlearn: 265990.2225443\ttotal: 3.78s\tremaining: 662ms\n",
      "851:\tlearn: 265990.1853135\ttotal: 3.8s\tremaining: 660ms\n",
      "852:\tlearn: 265990.1448285\ttotal: 3.81s\tremaining: 657ms\n",
      "853:\tlearn: 265990.1239756\ttotal: 3.81s\tremaining: 652ms\n",
      "854:\tlearn: 265990.0897187\ttotal: 3.82s\tremaining: 648ms\n",
      "855:\tlearn: 265990.0526196\ttotal: 3.83s\tremaining: 644ms\n",
      "856:\tlearn: 265990.0267719\ttotal: 3.83s\tremaining: 640ms\n",
      "857:\tlearn: 265990.0011018\ttotal: 3.84s\tremaining: 635ms\n",
      "858:\tlearn: 265989.9775499\ttotal: 3.84s\tremaining: 631ms\n",
      "859:\tlearn: 265989.9621745\ttotal: 3.85s\tremaining: 626ms\n",
      "860:\tlearn: 265989.9303814\ttotal: 3.85s\tremaining: 622ms\n",
      "861:\tlearn: 265989.9023321\ttotal: 3.86s\tremaining: 618ms\n",
      "862:\tlearn: 265989.8760644\ttotal: 3.86s\tremaining: 613ms\n",
      "863:\tlearn: 265989.8166438\ttotal: 3.87s\tremaining: 609ms\n",
      "864:\tlearn: 265989.7953838\ttotal: 3.87s\tremaining: 604ms\n",
      "865:\tlearn: 265989.7860913\ttotal: 3.87s\tremaining: 599ms\n",
      "866:\tlearn: 265989.7456579\ttotal: 3.88s\tremaining: 595ms\n",
      "867:\tlearn: 265989.7176825\ttotal: 3.88s\tremaining: 590ms\n",
      "868:\tlearn: 265989.6923054\ttotal: 3.93s\tremaining: 592ms\n",
      "869:\tlearn: 265989.6551604\ttotal: 3.94s\tremaining: 589ms\n",
      "870:\tlearn: 265989.6259679\ttotal: 3.95s\tremaining: 585ms\n",
      "871:\tlearn: 265989.5895182\ttotal: 3.96s\tremaining: 581ms\n",
      "872:\tlearn: 265989.5637693\ttotal: 3.97s\tremaining: 577ms\n",
      "873:\tlearn: 265989.5577826\ttotal: 3.98s\tremaining: 574ms\n",
      "874:\tlearn: 265989.5256215\ttotal: 3.99s\tremaining: 570ms\n",
      "875:\tlearn: 265989.5054866\ttotal: 4s\tremaining: 566ms\n",
      "876:\tlearn: 265989.4794768\ttotal: 4s\tremaining: 562ms\n",
      "877:\tlearn: 265989.4426625\ttotal: 4.01s\tremaining: 557ms\n",
      "878:\tlearn: 265989.4129454\ttotal: 4.02s\tremaining: 553ms\n",
      "879:\tlearn: 265989.3756565\ttotal: 4.02s\tremaining: 549ms\n",
      "880:\tlearn: 265989.3414999\ttotal: 4.03s\tremaining: 545ms\n",
      "881:\tlearn: 265989.3206873\ttotal: 4.04s\tremaining: 541ms\n",
      "882:\tlearn: 265989.2903222\ttotal: 4.05s\tremaining: 537ms\n",
      "883:\tlearn: 265989.2889077\ttotal: 4.05s\tremaining: 532ms\n",
      "884:\tlearn: 265989.2535058\ttotal: 4.06s\tremaining: 527ms\n",
      "885:\tlearn: 265989.2173702\ttotal: 4.06s\tremaining: 523ms\n",
      "886:\tlearn: 265989.2096315\ttotal: 4.07s\tremaining: 519ms\n",
      "887:\tlearn: 265989.2075404\ttotal: 4.08s\tremaining: 514ms\n",
      "888:\tlearn: 265989.1708369\ttotal: 4.08s\tremaining: 510ms\n",
      "889:\tlearn: 265989.1338829\ttotal: 4.08s\tremaining: 505ms\n",
      "890:\tlearn: 265989.1229052\ttotal: 4.09s\tremaining: 500ms\n",
      "891:\tlearn: 265989.0882154\ttotal: 4.09s\tremaining: 496ms\n",
      "892:\tlearn: 265989.0823465\ttotal: 4.1s\tremaining: 491ms\n",
      "893:\tlearn: 265989.0767994\ttotal: 4.1s\tremaining: 486ms\n",
      "894:\tlearn: 265989.0489978\ttotal: 4.1s\tremaining: 481ms\n",
      "895:\tlearn: 265989.0177657\ttotal: 4.11s\tremaining: 477ms\n",
      "896:\tlearn: 265988.9825017\ttotal: 4.11s\tremaining: 472ms\n",
      "897:\tlearn: 265988.9673169\ttotal: 4.12s\tremaining: 468ms\n",
      "898:\tlearn: 265988.9569918\ttotal: 4.12s\tremaining: 463ms\n",
      "899:\tlearn: 265988.9381538\ttotal: 4.13s\tremaining: 459ms\n",
      "900:\tlearn: 265988.9017841\ttotal: 4.13s\tremaining: 454ms\n",
      "901:\tlearn: 265988.8690010\ttotal: 4.13s\tremaining: 449ms\n",
      "902:\tlearn: 265988.8381372\ttotal: 4.14s\tremaining: 445ms\n",
      "903:\tlearn: 265988.8000645\ttotal: 4.14s\tremaining: 440ms\n",
      "904:\tlearn: 265988.7820095\ttotal: 4.15s\tremaining: 435ms\n",
      "905:\tlearn: 265988.7451224\ttotal: 4.15s\tremaining: 431ms\n",
      "906:\tlearn: 265988.7267169\ttotal: 4.16s\tremaining: 426ms\n",
      "907:\tlearn: 265988.6745503\ttotal: 4.16s\tremaining: 422ms\n",
      "908:\tlearn: 265988.6431634\ttotal: 4.16s\tremaining: 417ms\n",
      "909:\tlearn: 265988.6214046\ttotal: 4.17s\tremaining: 413ms\n",
      "910:\tlearn: 265988.5916611\ttotal: 4.17s\tremaining: 408ms\n",
      "911:\tlearn: 265988.5667394\ttotal: 4.18s\tremaining: 403ms\n",
      "912:\tlearn: 265988.5397171\ttotal: 4.18s\tremaining: 399ms\n",
      "913:\tlearn: 265988.5095925\ttotal: 4.19s\tremaining: 394ms\n",
      "914:\tlearn: 265988.4901147\ttotal: 4.19s\tremaining: 389ms\n",
      "915:\tlearn: 265988.4839849\ttotal: 4.19s\tremaining: 385ms\n",
      "916:\tlearn: 265988.4591298\ttotal: 4.2s\tremaining: 380ms\n",
      "917:\tlearn: 265988.4362114\ttotal: 4.2s\tremaining: 375ms\n",
      "918:\tlearn: 265988.4155809\ttotal: 4.21s\tremaining: 371ms\n",
      "919:\tlearn: 265988.3839251\ttotal: 4.21s\tremaining: 366ms\n",
      "920:\tlearn: 265988.3531807\ttotal: 4.22s\tremaining: 362ms\n",
      "921:\tlearn: 265988.3424250\ttotal: 4.22s\tremaining: 357ms\n",
      "922:\tlearn: 265988.3203736\ttotal: 4.22s\tremaining: 352ms\n",
      "923:\tlearn: 265988.3050810\ttotal: 4.23s\tremaining: 348ms\n",
      "924:\tlearn: 265988.2827449\ttotal: 4.24s\tremaining: 344ms\n",
      "925:\tlearn: 265988.2528641\ttotal: 4.24s\tremaining: 339ms\n",
      "926:\tlearn: 265988.2246121\ttotal: 4.25s\tremaining: 334ms\n",
      "927:\tlearn: 265988.2004233\ttotal: 4.25s\tremaining: 330ms\n",
      "928:\tlearn: 265988.1765159\ttotal: 4.25s\tremaining: 325ms\n",
      "929:\tlearn: 265988.1504782\ttotal: 4.26s\tremaining: 320ms\n",
      "930:\tlearn: 265988.1253991\ttotal: 4.26s\tremaining: 316ms\n",
      "931:\tlearn: 265988.1242809\ttotal: 4.27s\tremaining: 311ms\n",
      "932:\tlearn: 265988.0978456\ttotal: 4.27s\tremaining: 307ms\n",
      "933:\tlearn: 265988.0868209\ttotal: 4.27s\tremaining: 302ms\n",
      "934:\tlearn: 265988.0713165\ttotal: 4.28s\tremaining: 297ms\n",
      "935:\tlearn: 265988.0473517\ttotal: 4.28s\tremaining: 293ms\n",
      "936:\tlearn: 265988.0169907\ttotal: 4.28s\tremaining: 288ms\n",
      "937:\tlearn: 265987.9933606\ttotal: 4.29s\tremaining: 283ms\n",
      "938:\tlearn: 265987.9720012\ttotal: 4.29s\tremaining: 279ms\n",
      "939:\tlearn: 265987.9458940\ttotal: 4.3s\tremaining: 274ms\n",
      "940:\tlearn: 265987.9340403\ttotal: 4.3s\tremaining: 270ms\n",
      "941:\tlearn: 265987.9066299\ttotal: 4.31s\tremaining: 265ms\n",
      "942:\tlearn: 265987.8890089\ttotal: 4.31s\tremaining: 261ms\n",
      "943:\tlearn: 265987.8607118\ttotal: 4.32s\tremaining: 256ms\n",
      "944:\tlearn: 265987.8512349\ttotal: 4.33s\tremaining: 252ms\n",
      "945:\tlearn: 265987.8240573\ttotal: 4.33s\tremaining: 247ms\n",
      "946:\tlearn: 265987.8049523\ttotal: 4.34s\tremaining: 243ms\n",
      "947:\tlearn: 265987.7883521\ttotal: 4.34s\tremaining: 238ms\n",
      "948:\tlearn: 265987.7564839\ttotal: 4.35s\tremaining: 234ms\n",
      "949:\tlearn: 265987.7532423\ttotal: 4.35s\tremaining: 229ms\n",
      "950:\tlearn: 265987.7449848\ttotal: 4.36s\tremaining: 224ms\n",
      "951:\tlearn: 265987.7302501\ttotal: 4.36s\tremaining: 220ms\n",
      "952:\tlearn: 265987.7244957\ttotal: 4.37s\tremaining: 216ms\n",
      "953:\tlearn: 265987.7069490\ttotal: 4.38s\tremaining: 211ms\n",
      "954:\tlearn: 265987.6904163\ttotal: 4.38s\tremaining: 206ms\n",
      "955:\tlearn: 265987.6564811\ttotal: 4.38s\tremaining: 202ms\n",
      "956:\tlearn: 265987.6304570\ttotal: 4.39s\tremaining: 197ms\n",
      "957:\tlearn: 265987.6058048\ttotal: 4.39s\tremaining: 193ms\n",
      "958:\tlearn: 265987.5866752\ttotal: 4.4s\tremaining: 188ms\n",
      "959:\tlearn: 265987.5605495\ttotal: 4.41s\tremaining: 184ms\n",
      "960:\tlearn: 265987.5432680\ttotal: 4.41s\tremaining: 179ms\n",
      "961:\tlearn: 265987.5291095\ttotal: 4.42s\tremaining: 175ms\n",
      "962:\tlearn: 265987.5246707\ttotal: 4.42s\tremaining: 170ms\n",
      "963:\tlearn: 265987.5066134\ttotal: 4.43s\tremaining: 165ms\n",
      "964:\tlearn: 265987.5035683\ttotal: 4.43s\tremaining: 161ms\n",
      "965:\tlearn: 265987.4988226\ttotal: 4.44s\tremaining: 156ms\n",
      "966:\tlearn: 265987.4803184\ttotal: 4.44s\tremaining: 152ms\n",
      "967:\tlearn: 265987.4770754\ttotal: 4.44s\tremaining: 147ms\n",
      "968:\tlearn: 265987.4527469\ttotal: 4.45s\tremaining: 142ms\n",
      "969:\tlearn: 265987.4321484\ttotal: 4.46s\tremaining: 138ms\n",
      "970:\tlearn: 265987.4053586\ttotal: 4.46s\tremaining: 133ms\n",
      "971:\tlearn: 265987.3817300\ttotal: 4.46s\tremaining: 128ms\n",
      "972:\tlearn: 265987.3569987\ttotal: 4.47s\tremaining: 124ms\n",
      "973:\tlearn: 265987.3476678\ttotal: 4.47s\tremaining: 119ms\n",
      "974:\tlearn: 265987.3261675\ttotal: 4.47s\tremaining: 115ms\n",
      "975:\tlearn: 265987.3104025\ttotal: 4.48s\tremaining: 110ms\n",
      "976:\tlearn: 265987.2945823\ttotal: 4.48s\tremaining: 106ms\n",
      "977:\tlearn: 265987.2864250\ttotal: 4.49s\tremaining: 101ms\n",
      "978:\tlearn: 265987.2696010\ttotal: 4.49s\tremaining: 96.4ms\n",
      "979:\tlearn: 265987.2479175\ttotal: 4.5s\tremaining: 91.8ms\n",
      "980:\tlearn: 265987.2252562\ttotal: 4.5s\tremaining: 87.2ms\n",
      "981:\tlearn: 265987.1920602\ttotal: 4.51s\tremaining: 82.6ms\n",
      "982:\tlearn: 265987.1847257\ttotal: 4.51s\tremaining: 78ms\n",
      "983:\tlearn: 265987.1775340\ttotal: 4.51s\tremaining: 73.4ms\n",
      "984:\tlearn: 265987.1496070\ttotal: 4.52s\tremaining: 68.8ms\n",
      "985:\tlearn: 265987.1364392\ttotal: 4.52s\tremaining: 64.2ms\n",
      "986:\tlearn: 265987.1080763\ttotal: 4.53s\tremaining: 59.6ms\n",
      "987:\tlearn: 265987.1009121\ttotal: 4.53s\tremaining: 55ms\n",
      "988:\tlearn: 265987.0912359\ttotal: 4.53s\tremaining: 50.4ms\n",
      "989:\tlearn: 265987.0758404\ttotal: 4.54s\tremaining: 45.9ms\n",
      "990:\tlearn: 265987.0561051\ttotal: 4.54s\tremaining: 41.3ms\n",
      "991:\tlearn: 265987.0435599\ttotal: 4.54s\tremaining: 36.7ms\n",
      "992:\tlearn: 265987.0217681\ttotal: 4.55s\tremaining: 32.1ms\n",
      "993:\tlearn: 265986.9964073\ttotal: 4.56s\tremaining: 27.5ms\n",
      "994:\tlearn: 265986.9770935\ttotal: 4.62s\tremaining: 23.2ms\n",
      "995:\tlearn: 265986.9563359\ttotal: 4.63s\tremaining: 18.6ms\n",
      "996:\tlearn: 265986.9367109\ttotal: 4.64s\tremaining: 14ms\n",
      "997:\tlearn: 265986.9241986\ttotal: 4.66s\tremaining: 9.33ms\n",
      "998:\tlearn: 265986.9057992\ttotal: 4.67s\tremaining: 4.67ms\n",
      "999:\tlearn: 265986.8931640\ttotal: 4.68s\tremaining: 0us\n",
      "Prediction for 2025 using CatBoost completed and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor  # Import CatBoostRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=1000, learning_rate=0.1)  # You can adjust hyperparameters as needed\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2025\n",
    "prediction_2025 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2025[prediction_2025 < 0] = 0\n",
    "\n",
    "# Add the predicted '2025' column to the DataFrame\n",
    "df['2025'] = prediction_2025\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv', index=False)\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(\"Prediction for 2025 using CatBoost completed and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 979845.9695515\ttotal: 4.24ms\tremaining: 4.24s\n",
      "1:\tlearn: 922413.1307573\ttotal: 9.06ms\tremaining: 4.52s\n",
      "2:\tlearn: 867073.3256649\ttotal: 12.8ms\tremaining: 4.25s\n",
      "3:\tlearn: 819789.3356097\ttotal: 15.9ms\tremaining: 3.95s\n",
      "4:\tlearn: 778879.3217112\ttotal: 18.8ms\tremaining: 3.75s\n",
      "5:\tlearn: 739625.3618595\ttotal: 22.2ms\tremaining: 3.68s\n",
      "6:\tlearn: 702828.4245149\ttotal: 26.1ms\tremaining: 3.7s\n",
      "7:\tlearn: 667530.1606872\ttotal: 30.9ms\tremaining: 3.84s\n",
      "8:\tlearn: 634855.9168395\ttotal: 35.1ms\tremaining: 3.87s\n",
      "9:\tlearn: 606486.4663626\ttotal: 37.9ms\tremaining: 3.75s\n",
      "10:\tlearn: 581595.0611459\ttotal: 74.4ms\tremaining: 6.69s\n",
      "11:\tlearn: 556543.1004199\ttotal: 97.4ms\tremaining: 8.02s\n",
      "12:\tlearn: 533708.8794989\ttotal: 111ms\tremaining: 8.41s\n",
      "13:\tlearn: 514072.5861726\ttotal: 115ms\tremaining: 8.09s\n",
      "14:\tlearn: 494075.0064074\ttotal: 118ms\tremaining: 7.72s\n",
      "15:\tlearn: 477181.5525408\ttotal: 120ms\tremaining: 7.4s\n",
      "16:\tlearn: 460171.2808642\ttotal: 125ms\tremaining: 7.22s\n",
      "17:\tlearn: 443036.6700706\ttotal: 136ms\tremaining: 7.44s\n",
      "18:\tlearn: 428993.4475044\ttotal: 142ms\tremaining: 7.31s\n",
      "19:\tlearn: 416269.8766219\ttotal: 146ms\tremaining: 7.15s\n",
      "20:\tlearn: 403864.1606114\ttotal: 149ms\tremaining: 6.95s\n",
      "21:\tlearn: 393264.1646552\ttotal: 151ms\tremaining: 6.73s\n",
      "22:\tlearn: 382964.0500525\ttotal: 156ms\tremaining: 6.64s\n",
      "23:\tlearn: 373718.7673975\ttotal: 159ms\tremaining: 6.47s\n",
      "24:\tlearn: 365221.0738915\ttotal: 162ms\tremaining: 6.32s\n",
      "25:\tlearn: 357136.1120721\ttotal: 164ms\tremaining: 6.16s\n",
      "26:\tlearn: 350323.1121600\ttotal: 166ms\tremaining: 6s\n",
      "27:\tlearn: 343922.2561418\ttotal: 169ms\tremaining: 5.87s\n",
      "28:\tlearn: 337842.8500097\ttotal: 173ms\tremaining: 5.79s\n",
      "29:\tlearn: 332249.3310374\ttotal: 175ms\tremaining: 5.67s\n",
      "30:\tlearn: 327152.2123488\ttotal: 178ms\tremaining: 5.56s\n",
      "31:\tlearn: 322727.8909140\ttotal: 181ms\tremaining: 5.46s\n",
      "32:\tlearn: 318071.0468935\ttotal: 189ms\tremaining: 5.54s\n",
      "33:\tlearn: 313359.1152339\ttotal: 193ms\tremaining: 5.47s\n",
      "34:\tlearn: 309064.6016635\ttotal: 195ms\tremaining: 5.38s\n",
      "35:\tlearn: 305997.2715201\ttotal: 198ms\tremaining: 5.31s\n",
      "36:\tlearn: 302926.1314935\ttotal: 204ms\tremaining: 5.31s\n",
      "37:\tlearn: 300283.6610891\ttotal: 208ms\tremaining: 5.26s\n",
      "38:\tlearn: 297861.3893361\ttotal: 210ms\tremaining: 5.18s\n",
      "39:\tlearn: 295430.6163514\ttotal: 213ms\tremaining: 5.11s\n",
      "40:\tlearn: 293145.8857082\ttotal: 218ms\tremaining: 5.1s\n",
      "41:\tlearn: 291178.4058882\ttotal: 221ms\tremaining: 5.05s\n",
      "42:\tlearn: 289266.6094716\ttotal: 225ms\tremaining: 5s\n",
      "43:\tlearn: 287576.1774573\ttotal: 228ms\tremaining: 4.95s\n",
      "44:\tlearn: 285993.8979703\ttotal: 232ms\tremaining: 4.93s\n",
      "45:\tlearn: 284569.1205568\ttotal: 236ms\tremaining: 4.89s\n",
      "46:\tlearn: 283252.2126803\ttotal: 239ms\tremaining: 4.85s\n",
      "47:\tlearn: 282184.3017226\ttotal: 244ms\tremaining: 4.83s\n",
      "48:\tlearn: 280978.1448558\ttotal: 247ms\tremaining: 4.8s\n",
      "49:\tlearn: 279906.1181149\ttotal: 251ms\tremaining: 4.77s\n",
      "50:\tlearn: 279135.7758031\ttotal: 254ms\tremaining: 4.72s\n",
      "51:\tlearn: 278446.5078608\ttotal: 256ms\tremaining: 4.67s\n",
      "52:\tlearn: 277927.0022678\ttotal: 260ms\tremaining: 4.64s\n",
      "53:\tlearn: 277173.2200599\ttotal: 269ms\tremaining: 4.71s\n",
      "54:\tlearn: 276665.7153193\ttotal: 273ms\tremaining: 4.7s\n",
      "55:\tlearn: 276147.3586404\ttotal: 281ms\tremaining: 4.74s\n",
      "56:\tlearn: 275598.0412107\ttotal: 287ms\tremaining: 4.74s\n",
      "57:\tlearn: 275034.1518913\ttotal: 292ms\tremaining: 4.75s\n",
      "58:\tlearn: 274637.4605781\ttotal: 299ms\tremaining: 4.77s\n",
      "59:\tlearn: 274298.3070856\ttotal: 303ms\tremaining: 4.75s\n",
      "60:\tlearn: 274028.9594369\ttotal: 306ms\tremaining: 4.72s\n",
      "61:\tlearn: 273606.9827387\ttotal: 312ms\tremaining: 4.73s\n",
      "62:\tlearn: 273236.0456858\ttotal: 316ms\tremaining: 4.7s\n",
      "63:\tlearn: 272892.9454484\ttotal: 319ms\tremaining: 4.66s\n",
      "64:\tlearn: 272687.2656519\ttotal: 321ms\tremaining: 4.62s\n",
      "65:\tlearn: 272393.8585297\ttotal: 324ms\tremaining: 4.58s\n",
      "66:\tlearn: 272210.8308713\ttotal: 328ms\tremaining: 4.57s\n",
      "67:\tlearn: 271977.7461233\ttotal: 331ms\tremaining: 4.54s\n",
      "68:\tlearn: 271800.6307919\ttotal: 336ms\tremaining: 4.53s\n",
      "69:\tlearn: 271638.0211313\ttotal: 340ms\tremaining: 4.51s\n",
      "70:\tlearn: 271366.3464454\ttotal: 343ms\tremaining: 4.48s\n",
      "71:\tlearn: 271245.1206504\ttotal: 345ms\tremaining: 4.45s\n",
      "72:\tlearn: 271121.9540132\ttotal: 348ms\tremaining: 4.42s\n",
      "73:\tlearn: 270989.5808102\ttotal: 350ms\tremaining: 4.38s\n",
      "74:\tlearn: 270792.6618807\ttotal: 354ms\tremaining: 4.36s\n",
      "75:\tlearn: 270638.1526454\ttotal: 357ms\tremaining: 4.34s\n",
      "76:\tlearn: 270475.6018352\ttotal: 360ms\tremaining: 4.31s\n",
      "77:\tlearn: 270402.7721268\ttotal: 362ms\tremaining: 4.28s\n",
      "78:\tlearn: 270253.5506803\ttotal: 364ms\tremaining: 4.24s\n",
      "79:\tlearn: 270148.7334324\ttotal: 366ms\tremaining: 4.21s\n",
      "80:\tlearn: 270026.8768492\ttotal: 369ms\tremaining: 4.18s\n",
      "81:\tlearn: 269875.6993382\ttotal: 372ms\tremaining: 4.17s\n",
      "82:\tlearn: 269762.4978095\ttotal: 375ms\tremaining: 4.14s\n",
      "83:\tlearn: 269701.0164124\ttotal: 377ms\tremaining: 4.11s\n",
      "84:\tlearn: 269625.2500844\ttotal: 379ms\tremaining: 4.08s\n",
      "85:\tlearn: 269513.2272010\ttotal: 381ms\tremaining: 4.05s\n",
      "86:\tlearn: 269385.7670106\ttotal: 383ms\tremaining: 4.02s\n",
      "87:\tlearn: 269264.9771835\ttotal: 387ms\tremaining: 4.01s\n",
      "88:\tlearn: 269203.3772522\ttotal: 390ms\tremaining: 3.99s\n",
      "89:\tlearn: 269130.4897266\ttotal: 392ms\tremaining: 3.96s\n",
      "90:\tlearn: 269023.7023279\ttotal: 394ms\tremaining: 3.94s\n",
      "91:\tlearn: 268965.9212935\ttotal: 396ms\tremaining: 3.91s\n",
      "92:\tlearn: 268895.4910558\ttotal: 398ms\tremaining: 3.88s\n",
      "93:\tlearn: 268818.7630387\ttotal: 403ms\tremaining: 3.88s\n",
      "94:\tlearn: 268739.0703001\ttotal: 407ms\tremaining: 3.88s\n",
      "95:\tlearn: 268683.5372277\ttotal: 411ms\tremaining: 3.87s\n",
      "96:\tlearn: 268605.6725028\ttotal: 413ms\tremaining: 3.85s\n",
      "97:\tlearn: 268546.5532689\ttotal: 415ms\tremaining: 3.82s\n",
      "98:\tlearn: 268461.0641812\ttotal: 420ms\tremaining: 3.82s\n",
      "99:\tlearn: 268388.3366826\ttotal: 422ms\tremaining: 3.8s\n",
      "100:\tlearn: 268324.5877288\ttotal: 425ms\tremaining: 3.79s\n",
      "101:\tlearn: 268265.8889994\ttotal: 428ms\tremaining: 3.77s\n",
      "102:\tlearn: 268213.3643970\ttotal: 432ms\tremaining: 3.77s\n",
      "103:\tlearn: 268126.2735247\ttotal: 437ms\tremaining: 3.76s\n",
      "104:\tlearn: 268069.5906841\ttotal: 440ms\tremaining: 3.75s\n",
      "105:\tlearn: 268017.9948413\ttotal: 443ms\tremaining: 3.74s\n",
      "106:\tlearn: 267930.6534529\ttotal: 446ms\tremaining: 3.72s\n",
      "107:\tlearn: 267878.3267209\ttotal: 451ms\tremaining: 3.72s\n",
      "108:\tlearn: 267833.8111643\ttotal: 453ms\tremaining: 3.71s\n",
      "109:\tlearn: 267810.7517706\ttotal: 456ms\tremaining: 3.69s\n",
      "110:\tlearn: 267765.4955949\ttotal: 459ms\tremaining: 3.67s\n",
      "111:\tlearn: 267727.6426851\ttotal: 463ms\tremaining: 3.67s\n",
      "112:\tlearn: 267687.6617770\ttotal: 466ms\tremaining: 3.66s\n",
      "113:\tlearn: 267645.1331105\ttotal: 469ms\tremaining: 3.65s\n",
      "114:\tlearn: 267605.6620503\ttotal: 472ms\tremaining: 3.63s\n",
      "115:\tlearn: 267575.5578887\ttotal: 475ms\tremaining: 3.62s\n",
      "116:\tlearn: 267538.5597093\ttotal: 481ms\tremaining: 3.63s\n",
      "117:\tlearn: 267494.0991055\ttotal: 485ms\tremaining: 3.62s\n",
      "118:\tlearn: 267456.0185922\ttotal: 488ms\tremaining: 3.61s\n",
      "119:\tlearn: 267421.1841245\ttotal: 491ms\tremaining: 3.6s\n",
      "120:\tlearn: 267386.5372146\ttotal: 497ms\tremaining: 3.61s\n",
      "121:\tlearn: 267368.1396787\ttotal: 500ms\tremaining: 3.6s\n",
      "122:\tlearn: 267331.1560245\ttotal: 503ms\tremaining: 3.58s\n",
      "123:\tlearn: 267285.5112842\ttotal: 505ms\tremaining: 3.57s\n",
      "124:\tlearn: 267258.4113966\ttotal: 508ms\tremaining: 3.56s\n",
      "125:\tlearn: 267242.0151617\ttotal: 512ms\tremaining: 3.55s\n",
      "126:\tlearn: 267229.8193660\ttotal: 515ms\tremaining: 3.54s\n",
      "127:\tlearn: 267205.4544580\ttotal: 517ms\tremaining: 3.52s\n",
      "128:\tlearn: 267193.9273562\ttotal: 520ms\tremaining: 3.51s\n",
      "129:\tlearn: 267183.0216026\ttotal: 523ms\tremaining: 3.5s\n",
      "130:\tlearn: 267163.9699802\ttotal: 527ms\tremaining: 3.49s\n",
      "131:\tlearn: 267135.9678539\ttotal: 530ms\tremaining: 3.48s\n",
      "132:\tlearn: 267118.8051904\ttotal: 532ms\tremaining: 3.47s\n",
      "133:\tlearn: 267101.5342350\ttotal: 535ms\tremaining: 3.46s\n",
      "134:\tlearn: 267078.6401973\ttotal: 538ms\tremaining: 3.45s\n",
      "135:\tlearn: 267062.6943625\ttotal: 542ms\tremaining: 3.44s\n",
      "136:\tlearn: 267052.7361086\ttotal: 545ms\tremaining: 3.43s\n",
      "137:\tlearn: 267041.7309432\ttotal: 547ms\tremaining: 3.42s\n",
      "138:\tlearn: 267026.8459743\ttotal: 549ms\tremaining: 3.4s\n",
      "139:\tlearn: 267016.5850938\ttotal: 552ms\tremaining: 3.39s\n",
      "140:\tlearn: 267006.9319983\ttotal: 556ms\tremaining: 3.39s\n",
      "141:\tlearn: 266982.6142362\ttotal: 559ms\tremaining: 3.38s\n",
      "142:\tlearn: 266969.5118229\ttotal: 562ms\tremaining: 3.37s\n",
      "143:\tlearn: 266961.7848423\ttotal: 564ms\tremaining: 3.35s\n",
      "144:\tlearn: 266939.4719731\ttotal: 566ms\tremaining: 3.34s\n",
      "145:\tlearn: 266912.7212482\ttotal: 570ms\tremaining: 3.33s\n",
      "146:\tlearn: 266905.2523694\ttotal: 573ms\tremaining: 3.33s\n",
      "147:\tlearn: 266897.3521826\ttotal: 576ms\tremaining: 3.31s\n",
      "148:\tlearn: 266889.9155529\ttotal: 578ms\tremaining: 3.3s\n",
      "149:\tlearn: 266882.9124327\ttotal: 580ms\tremaining: 3.29s\n",
      "150:\tlearn: 266872.2941477\ttotal: 582ms\tremaining: 3.27s\n",
      "151:\tlearn: 266865.7454790\ttotal: 587ms\tremaining: 3.27s\n",
      "152:\tlearn: 266855.7378533\ttotal: 590ms\tremaining: 3.27s\n",
      "153:\tlearn: 266832.7545871\ttotal: 593ms\tremaining: 3.26s\n",
      "154:\tlearn: 266826.6542642\ttotal: 595ms\tremaining: 3.24s\n",
      "155:\tlearn: 266820.8986330\ttotal: 597ms\tremaining: 3.23s\n",
      "156:\tlearn: 266813.0481983\ttotal: 601ms\tremaining: 3.23s\n",
      "157:\tlearn: 266807.9130947\ttotal: 604ms\tremaining: 3.22s\n",
      "158:\tlearn: 266788.4381841\ttotal: 608ms\tremaining: 3.21s\n",
      "159:\tlearn: 266773.3829161\ttotal: 611ms\tremaining: 3.21s\n",
      "160:\tlearn: 266768.5123627\ttotal: 613ms\tremaining: 3.19s\n",
      "161:\tlearn: 266761.6747998\ttotal: 617ms\tremaining: 3.19s\n",
      "162:\tlearn: 266755.1933622\ttotal: 620ms\tremaining: 3.19s\n",
      "163:\tlearn: 266750.5844737\ttotal: 623ms\tremaining: 3.17s\n",
      "164:\tlearn: 266744.3925186\ttotal: 626ms\tremaining: 3.17s\n",
      "165:\tlearn: 266740.0379353\ttotal: 628ms\tremaining: 3.16s\n",
      "166:\tlearn: 266723.7148217\ttotal: 633ms\tremaining: 3.16s\n",
      "167:\tlearn: 266704.9890630\ttotal: 636ms\tremaining: 3.15s\n",
      "168:\tlearn: 266700.9288001\ttotal: 639ms\tremaining: 3.14s\n",
      "169:\tlearn: 266696.6795385\ttotal: 641ms\tremaining: 3.13s\n",
      "170:\tlearn: 266683.4142522\ttotal: 644ms\tremaining: 3.12s\n",
      "171:\tlearn: 266668.5234260\ttotal: 649ms\tremaining: 3.12s\n",
      "172:\tlearn: 266656.5715975\ttotal: 652ms\tremaining: 3.11s\n",
      "173:\tlearn: 266643.7689761\ttotal: 654ms\tremaining: 3.1s\n",
      "174:\tlearn: 266640.0866027\ttotal: 657ms\tremaining: 3.1s\n",
      "175:\tlearn: 266624.7865959\ttotal: 660ms\tremaining: 3.09s\n",
      "176:\tlearn: 266621.3119676\ttotal: 665ms\tremaining: 3.09s\n",
      "177:\tlearn: 266618.0205540\ttotal: 667ms\tremaining: 3.08s\n",
      "178:\tlearn: 266614.5594501\ttotal: 670ms\tremaining: 3.07s\n",
      "179:\tlearn: 266608.1490625\ttotal: 672ms\tremaining: 3.06s\n",
      "180:\tlearn: 266604.9057136\ttotal: 674ms\tremaining: 3.05s\n",
      "181:\tlearn: 266599.7896633\ttotal: 677ms\tremaining: 3.04s\n",
      "182:\tlearn: 266588.4701584\ttotal: 680ms\tremaining: 3.04s\n",
      "183:\tlearn: 266585.6651576\ttotal: 683ms\tremaining: 3.03s\n",
      "184:\tlearn: 266582.9995577\ttotal: 685ms\tremaining: 3.02s\n",
      "185:\tlearn: 266577.1989802\ttotal: 687ms\tremaining: 3s\n",
      "186:\tlearn: 266574.3365906\ttotal: 689ms\tremaining: 3s\n",
      "187:\tlearn: 266569.7199060\ttotal: 691ms\tremaining: 2.98s\n",
      "188:\tlearn: 266565.3498321\ttotal: 695ms\tremaining: 2.98s\n",
      "189:\tlearn: 266562.9563299\ttotal: 698ms\tremaining: 2.97s\n",
      "190:\tlearn: 266560.6871709\ttotal: 700ms\tremaining: 2.96s\n",
      "191:\tlearn: 266550.5756698\ttotal: 702ms\tremaining: 2.95s\n",
      "192:\tlearn: 266546.6008673\ttotal: 704ms\tremaining: 2.94s\n",
      "193:\tlearn: 266544.2075457\ttotal: 706ms\tremaining: 2.93s\n",
      "194:\tlearn: 266542.1603923\ttotal: 711ms\tremaining: 2.93s\n",
      "195:\tlearn: 266536.7326300\ttotal: 713ms\tremaining: 2.92s\n",
      "196:\tlearn: 266534.5763683\ttotal: 715ms\tremaining: 2.92s\n",
      "197:\tlearn: 266524.8737812\ttotal: 718ms\tremaining: 2.91s\n",
      "198:\tlearn: 266519.8424103\ttotal: 720ms\tremaining: 2.9s\n",
      "199:\tlearn: 266517.8027586\ttotal: 722ms\tremaining: 2.89s\n",
      "200:\tlearn: 266513.1177826\ttotal: 727ms\tremaining: 2.89s\n",
      "201:\tlearn: 266511.1926133\ttotal: 729ms\tremaining: 2.88s\n",
      "202:\tlearn: 266500.7409301\ttotal: 732ms\tremaining: 2.87s\n",
      "203:\tlearn: 266489.6259367\ttotal: 734ms\tremaining: 2.86s\n",
      "204:\tlearn: 266487.7435369\ttotal: 737ms\tremaining: 2.86s\n",
      "205:\tlearn: 266485.1247726\ttotal: 739ms\tremaining: 2.85s\n",
      "206:\tlearn: 266483.4215145\ttotal: 743ms\tremaining: 2.85s\n",
      "207:\tlearn: 266481.8042360\ttotal: 745ms\tremaining: 2.84s\n",
      "208:\tlearn: 266478.5904523\ttotal: 747ms\tremaining: 2.83s\n",
      "209:\tlearn: 266470.6834887\ttotal: 749ms\tremaining: 2.82s\n",
      "210:\tlearn: 266469.3154693\ttotal: 751ms\tremaining: 2.81s\n",
      "211:\tlearn: 266465.9569185\ttotal: 753ms\tremaining: 2.8s\n",
      "212:\tlearn: 266464.5049943\ttotal: 757ms\tremaining: 2.8s\n",
      "213:\tlearn: 266458.8737711\ttotal: 760ms\tremaining: 2.79s\n",
      "214:\tlearn: 266457.5053652\ttotal: 762ms\tremaining: 2.78s\n",
      "215:\tlearn: 266456.2132713\ttotal: 764ms\tremaining: 2.77s\n",
      "216:\tlearn: 266453.2461095\ttotal: 766ms\tremaining: 2.76s\n",
      "217:\tlearn: 266449.8412929\ttotal: 768ms\tremaining: 2.75s\n",
      "218:\tlearn: 266441.6344011\ttotal: 772ms\tremaining: 2.75s\n",
      "219:\tlearn: 266433.0548195\ttotal: 775ms\tremaining: 2.75s\n",
      "220:\tlearn: 266431.3763506\ttotal: 777ms\tremaining: 2.74s\n",
      "221:\tlearn: 266424.6800772\ttotal: 780ms\tremaining: 2.73s\n",
      "222:\tlearn: 266423.1022319\ttotal: 782ms\tremaining: 2.72s\n",
      "223:\tlearn: 266421.9378006\ttotal: 784ms\tremaining: 2.71s\n",
      "224:\tlearn: 266420.9685091\ttotal: 788ms\tremaining: 2.71s\n",
      "225:\tlearn: 266413.6415124\ttotal: 792ms\tremaining: 2.71s\n",
      "226:\tlearn: 266406.2192427\ttotal: 794ms\tremaining: 2.7s\n",
      "227:\tlearn: 266404.8361997\ttotal: 796ms\tremaining: 2.69s\n",
      "228:\tlearn: 266398.1536173\ttotal: 798ms\tremaining: 2.69s\n",
      "229:\tlearn: 266396.8528950\ttotal: 800ms\tremaining: 2.68s\n",
      "230:\tlearn: 266388.6128448\ttotal: 805ms\tremaining: 2.68s\n",
      "231:\tlearn: 266385.7338794\ttotal: 849ms\tremaining: 2.81s\n",
      "232:\tlearn: 266379.5920285\ttotal: 859ms\tremaining: 2.83s\n",
      "233:\tlearn: 266373.1517771\ttotal: 870ms\tremaining: 2.85s\n",
      "234:\tlearn: 266372.2507523\ttotal: 875ms\tremaining: 2.85s\n",
      "235:\tlearn: 266371.3960428\ttotal: 878ms\tremaining: 2.84s\n",
      "236:\tlearn: 266366.0580185\ttotal: 881ms\tremaining: 2.83s\n",
      "237:\tlearn: 266360.5603049\ttotal: 885ms\tremaining: 2.83s\n",
      "238:\tlearn: 266354.5880774\ttotal: 890ms\tremaining: 2.83s\n",
      "239:\tlearn: 266351.1872160\ttotal: 893ms\tremaining: 2.83s\n",
      "240:\tlearn: 266344.9548477\ttotal: 901ms\tremaining: 2.84s\n",
      "241:\tlearn: 266344.2412358\ttotal: 904ms\tremaining: 2.83s\n",
      "242:\tlearn: 266342.2508963\ttotal: 907ms\tremaining: 2.82s\n",
      "243:\tlearn: 266341.5743460\ttotal: 909ms\tremaining: 2.82s\n",
      "244:\tlearn: 266336.3814929\ttotal: 912ms\tremaining: 2.81s\n",
      "245:\tlearn: 266335.7323737\ttotal: 916ms\tremaining: 2.81s\n",
      "246:\tlearn: 266334.0471549\ttotal: 919ms\tremaining: 2.8s\n",
      "247:\tlearn: 266333.1195248\ttotal: 922ms\tremaining: 2.8s\n",
      "248:\tlearn: 266328.3835199\ttotal: 926ms\tremaining: 2.79s\n",
      "249:\tlearn: 266323.2516688\ttotal: 932ms\tremaining: 2.79s\n",
      "250:\tlearn: 266318.5331286\ttotal: 935ms\tremaining: 2.79s\n",
      "251:\tlearn: 266317.9452360\ttotal: 937ms\tremaining: 2.78s\n",
      "252:\tlearn: 266314.0798716\ttotal: 939ms\tremaining: 2.77s\n",
      "253:\tlearn: 266313.5227275\ttotal: 942ms\tremaining: 2.77s\n",
      "254:\tlearn: 266309.3554842\ttotal: 944ms\tremaining: 2.76s\n",
      "255:\tlearn: 266307.8276051\ttotal: 949ms\tremaining: 2.76s\n",
      "256:\tlearn: 266307.2999225\ttotal: 951ms\tremaining: 2.75s\n",
      "257:\tlearn: 266301.4008549\ttotal: 954ms\tremaining: 2.74s\n",
      "258:\tlearn: 266299.6896814\ttotal: 956ms\tremaining: 2.73s\n",
      "259:\tlearn: 266295.6866531\ttotal: 958ms\tremaining: 2.73s\n",
      "260:\tlearn: 266291.8430476\ttotal: 963ms\tremaining: 2.73s\n",
      "261:\tlearn: 266287.9430817\ttotal: 966ms\tremaining: 2.72s\n",
      "262:\tlearn: 266287.3572887\ttotal: 969ms\tremaining: 2.72s\n",
      "263:\tlearn: 266286.9064691\ttotal: 972ms\tremaining: 2.71s\n",
      "264:\tlearn: 266283.4067840\ttotal: 974ms\tremaining: 2.7s\n",
      "265:\tlearn: 266282.9794756\ttotal: 978ms\tremaining: 2.7s\n",
      "266:\tlearn: 266278.2245607\ttotal: 982ms\tremaining: 2.7s\n",
      "267:\tlearn: 266276.5808249\ttotal: 985ms\tremaining: 2.69s\n",
      "268:\tlearn: 266276.1759543\ttotal: 989ms\tremaining: 2.69s\n",
      "269:\tlearn: 266271.8519811\ttotal: 991ms\tremaining: 2.68s\n",
      "270:\tlearn: 266270.0086328\ttotal: 995ms\tremaining: 2.68s\n",
      "271:\tlearn: 266265.4943436\ttotal: 998ms\tremaining: 2.67s\n",
      "272:\tlearn: 266261.8445338\ttotal: 1s\tremaining: 2.67s\n",
      "273:\tlearn: 266258.4258112\ttotal: 1s\tremaining: 2.66s\n",
      "274:\tlearn: 266257.1104478\ttotal: 1.01s\tremaining: 2.65s\n",
      "275:\tlearn: 266253.2754641\ttotal: 1.01s\tremaining: 2.65s\n",
      "276:\tlearn: 266249.3422093\ttotal: 1.01s\tremaining: 2.65s\n",
      "277:\tlearn: 266248.1155969\ttotal: 1.02s\tremaining: 2.65s\n",
      "278:\tlearn: 266247.7424156\ttotal: 1.02s\tremaining: 2.64s\n",
      "279:\tlearn: 266244.6281560\ttotal: 1.03s\tremaining: 2.65s\n",
      "280:\tlearn: 266244.2746197\ttotal: 1.03s\tremaining: 2.64s\n",
      "281:\tlearn: 266242.4660477\ttotal: 1.04s\tremaining: 2.64s\n",
      "282:\tlearn: 266239.5571712\ttotal: 1.05s\tremaining: 2.65s\n",
      "283:\tlearn: 266239.2265074\ttotal: 1.05s\tremaining: 2.65s\n",
      "284:\tlearn: 266238.0821764\ttotal: 1.05s\tremaining: 2.65s\n",
      "285:\tlearn: 266237.0036505\ttotal: 1.06s\tremaining: 2.65s\n",
      "286:\tlearn: 266236.5540642\ttotal: 1.06s\tremaining: 2.64s\n",
      "287:\tlearn: 266235.3418153\ttotal: 1.07s\tremaining: 2.64s\n",
      "288:\tlearn: 266232.6571549\ttotal: 1.07s\tremaining: 2.64s\n",
      "289:\tlearn: 266229.6296371\ttotal: 1.08s\tremaining: 2.64s\n",
      "290:\tlearn: 266228.1955988\ttotal: 1.08s\tremaining: 2.63s\n",
      "291:\tlearn: 266227.8954209\ttotal: 1.08s\tremaining: 2.63s\n",
      "292:\tlearn: 266227.0027472\ttotal: 1.09s\tremaining: 2.62s\n",
      "293:\tlearn: 266226.7181480\ttotal: 1.09s\tremaining: 2.62s\n",
      "294:\tlearn: 266225.8714639\ttotal: 1.09s\tremaining: 2.61s\n",
      "295:\tlearn: 266225.5639104\ttotal: 1.1s\tremaining: 2.61s\n",
      "296:\tlearn: 266222.8168779\ttotal: 1.1s\tremaining: 2.6s\n",
      "297:\tlearn: 266221.4069996\ttotal: 1.1s\tremaining: 2.6s\n",
      "298:\tlearn: 266218.7488787\ttotal: 1.11s\tremaining: 2.59s\n",
      "299:\tlearn: 266214.9466601\ttotal: 1.11s\tremaining: 2.59s\n",
      "300:\tlearn: 266214.5333483\ttotal: 1.11s\tremaining: 2.58s\n",
      "301:\tlearn: 266213.3515866\ttotal: 1.11s\tremaining: 2.57s\n",
      "302:\tlearn: 266213.0912989\ttotal: 1.11s\tremaining: 2.57s\n",
      "303:\tlearn: 266212.8438987\ttotal: 1.12s\tremaining: 2.56s\n",
      "304:\tlearn: 266211.6876634\ttotal: 1.12s\tremaining: 2.56s\n",
      "305:\tlearn: 266211.4523389\ttotal: 1.13s\tremaining: 2.55s\n",
      "306:\tlearn: 266210.4660563\ttotal: 1.13s\tremaining: 2.54s\n",
      "307:\tlearn: 266209.7483141\ttotal: 1.13s\tremaining: 2.54s\n",
      "308:\tlearn: 266206.4214161\ttotal: 1.13s\tremaining: 2.53s\n",
      "309:\tlearn: 266203.3223883\ttotal: 1.14s\tremaining: 2.53s\n",
      "310:\tlearn: 266201.0459913\ttotal: 1.14s\tremaining: 2.52s\n",
      "311:\tlearn: 266200.8235476\ttotal: 1.14s\tremaining: 2.52s\n",
      "312:\tlearn: 266197.4688037\ttotal: 1.14s\tremaining: 2.51s\n",
      "313:\tlearn: 266195.0166985\ttotal: 1.15s\tremaining: 2.5s\n",
      "314:\tlearn: 266193.1105795\ttotal: 1.15s\tremaining: 2.5s\n",
      "315:\tlearn: 266190.6357940\ttotal: 1.15s\tremaining: 2.5s\n",
      "316:\tlearn: 266187.1483275\ttotal: 1.16s\tremaining: 2.49s\n",
      "317:\tlearn: 266186.9365903\ttotal: 1.16s\tremaining: 2.49s\n",
      "318:\tlearn: 266184.3013159\ttotal: 1.16s\tremaining: 2.48s\n",
      "319:\tlearn: 266182.0314102\ttotal: 1.17s\tremaining: 2.48s\n",
      "320:\tlearn: 266180.0843444\ttotal: 1.17s\tremaining: 2.47s\n",
      "321:\tlearn: 266178.7406875\ttotal: 1.17s\tremaining: 2.47s\n",
      "322:\tlearn: 266177.7820353\ttotal: 1.17s\tremaining: 2.46s\n",
      "323:\tlearn: 266175.9756507\ttotal: 1.18s\tremaining: 2.46s\n",
      "324:\tlearn: 266173.6991883\ttotal: 1.18s\tremaining: 2.45s\n",
      "325:\tlearn: 266171.8193675\ttotal: 1.18s\tremaining: 2.45s\n",
      "326:\tlearn: 266169.4985571\ttotal: 1.19s\tremaining: 2.44s\n",
      "327:\tlearn: 266166.9474845\ttotal: 1.19s\tremaining: 2.44s\n",
      "328:\tlearn: 266164.0596202\ttotal: 1.19s\tremaining: 2.43s\n",
      "329:\tlearn: 266162.3832644\ttotal: 1.19s\tremaining: 2.42s\n",
      "330:\tlearn: 266159.8401825\ttotal: 1.2s\tremaining: 2.42s\n",
      "331:\tlearn: 266157.6366276\ttotal: 1.2s\tremaining: 2.42s\n",
      "332:\tlearn: 266155.3076266\ttotal: 1.2s\tremaining: 2.41s\n",
      "333:\tlearn: 266153.3111590\ttotal: 1.21s\tremaining: 2.41s\n",
      "334:\tlearn: 266152.2248384\ttotal: 1.21s\tremaining: 2.4s\n",
      "335:\tlearn: 266151.9164637\ttotal: 1.21s\tremaining: 2.4s\n",
      "336:\tlearn: 266150.5257981\ttotal: 1.22s\tremaining: 2.4s\n",
      "337:\tlearn: 266150.3429578\ttotal: 1.22s\tremaining: 2.39s\n",
      "338:\tlearn: 266150.0632990\ttotal: 1.22s\tremaining: 2.38s\n",
      "339:\tlearn: 266149.0658117\ttotal: 1.23s\tremaining: 2.38s\n",
      "340:\tlearn: 266148.4188570\ttotal: 1.23s\tremaining: 2.38s\n",
      "341:\tlearn: 266147.4284281\ttotal: 1.24s\tremaining: 2.38s\n",
      "342:\tlearn: 266144.9519279\ttotal: 1.24s\tremaining: 2.37s\n",
      "343:\tlearn: 266143.0687310\ttotal: 1.24s\tremaining: 2.37s\n",
      "344:\tlearn: 266141.0441250\ttotal: 1.25s\tremaining: 2.37s\n",
      "345:\tlearn: 266139.9850716\ttotal: 1.25s\tremaining: 2.36s\n",
      "346:\tlearn: 266138.3576588\ttotal: 1.25s\tremaining: 2.36s\n",
      "347:\tlearn: 266136.8816060\ttotal: 1.25s\tremaining: 2.35s\n",
      "348:\tlearn: 266135.5322790\ttotal: 1.26s\tremaining: 2.36s\n",
      "349:\tlearn: 266133.7273819\ttotal: 1.27s\tremaining: 2.35s\n",
      "350:\tlearn: 266132.8072017\ttotal: 1.27s\tremaining: 2.35s\n",
      "351:\tlearn: 266130.9525235\ttotal: 1.28s\tremaining: 2.35s\n",
      "352:\tlearn: 266129.3829137\ttotal: 1.28s\tremaining: 2.35s\n",
      "353:\tlearn: 266128.5468628\ttotal: 1.28s\tremaining: 2.34s\n",
      "354:\tlearn: 266127.7786927\ttotal: 1.28s\tremaining: 2.33s\n",
      "355:\tlearn: 266127.0182612\ttotal: 1.29s\tremaining: 2.33s\n",
      "356:\tlearn: 266124.9279416\ttotal: 1.29s\tremaining: 2.33s\n",
      "357:\tlearn: 266123.4055082\ttotal: 1.3s\tremaining: 2.33s\n",
      "358:\tlearn: 266122.8799541\ttotal: 1.3s\tremaining: 2.32s\n",
      "359:\tlearn: 266122.2135837\ttotal: 1.3s\tremaining: 2.32s\n",
      "360:\tlearn: 266121.7174595\ttotal: 1.31s\tremaining: 2.31s\n",
      "361:\tlearn: 266121.2465151\ttotal: 1.31s\tremaining: 2.31s\n",
      "362:\tlearn: 266120.3103615\ttotal: 1.31s\tremaining: 2.3s\n",
      "363:\tlearn: 266118.2741770\ttotal: 1.31s\tremaining: 2.3s\n",
      "364:\tlearn: 266116.9150761\ttotal: 1.32s\tremaining: 2.29s\n",
      "365:\tlearn: 266115.8812351\ttotal: 1.32s\tremaining: 2.29s\n",
      "366:\tlearn: 266114.3288776\ttotal: 1.32s\tremaining: 2.29s\n",
      "367:\tlearn: 266113.4799370\ttotal: 1.33s\tremaining: 2.28s\n",
      "368:\tlearn: 266111.8490020\ttotal: 1.33s\tremaining: 2.27s\n",
      "369:\tlearn: 266110.5056737\ttotal: 1.33s\tremaining: 2.27s\n",
      "370:\tlearn: 266109.3700277\ttotal: 1.34s\tremaining: 2.27s\n",
      "371:\tlearn: 266108.9788652\ttotal: 1.34s\tremaining: 2.26s\n",
      "372:\tlearn: 266108.2126855\ttotal: 1.34s\tremaining: 2.26s\n",
      "373:\tlearn: 266108.0835292\ttotal: 1.35s\tremaining: 2.26s\n",
      "374:\tlearn: 266106.4078490\ttotal: 1.35s\tremaining: 2.25s\n",
      "375:\tlearn: 266106.2852134\ttotal: 1.35s\tremaining: 2.25s\n",
      "376:\tlearn: 266106.1689712\ttotal: 1.36s\tremaining: 2.25s\n",
      "377:\tlearn: 266106.0587780\ttotal: 1.36s\tremaining: 2.24s\n",
      "378:\tlearn: 266105.7346283\ttotal: 1.37s\tremaining: 2.24s\n",
      "379:\tlearn: 266104.3502715\ttotal: 1.37s\tremaining: 2.23s\n",
      "380:\tlearn: 266102.8378257\ttotal: 1.37s\tremaining: 2.23s\n",
      "381:\tlearn: 266102.5384078\ttotal: 1.38s\tremaining: 2.23s\n",
      "382:\tlearn: 266101.4592048\ttotal: 1.38s\tremaining: 2.22s\n",
      "383:\tlearn: 266100.4155618\ttotal: 1.39s\tremaining: 2.22s\n",
      "384:\tlearn: 266099.2288447\ttotal: 1.39s\tremaining: 2.22s\n",
      "385:\tlearn: 266098.4885662\ttotal: 1.39s\tremaining: 2.21s\n",
      "386:\tlearn: 266098.2927425\ttotal: 1.4s\tremaining: 2.21s\n",
      "387:\tlearn: 266096.9346903\ttotal: 1.4s\tremaining: 2.21s\n",
      "388:\tlearn: 266096.2100767\ttotal: 1.41s\tremaining: 2.21s\n",
      "389:\tlearn: 266096.1233434\ttotal: 1.41s\tremaining: 2.2s\n",
      "390:\tlearn: 266096.0410496\ttotal: 1.41s\tremaining: 2.2s\n",
      "391:\tlearn: 266095.9049037\ttotal: 1.42s\tremaining: 2.2s\n",
      "392:\tlearn: 266095.0609327\ttotal: 1.42s\tremaining: 2.19s\n",
      "393:\tlearn: 266094.9107612\ttotal: 1.42s\tremaining: 2.19s\n",
      "394:\tlearn: 266094.0535468\ttotal: 1.43s\tremaining: 2.19s\n",
      "395:\tlearn: 266093.1765580\ttotal: 1.43s\tremaining: 2.19s\n",
      "396:\tlearn: 266091.6727791\ttotal: 1.44s\tremaining: 2.18s\n",
      "397:\tlearn: 266090.9633417\ttotal: 1.44s\tremaining: 2.18s\n",
      "398:\tlearn: 266089.1674043\ttotal: 1.45s\tremaining: 2.18s\n",
      "399:\tlearn: 266088.4541643\ttotal: 1.45s\tremaining: 2.17s\n",
      "400:\tlearn: 266087.7057174\ttotal: 1.45s\tremaining: 2.17s\n",
      "401:\tlearn: 266087.3157279\ttotal: 1.46s\tremaining: 2.16s\n",
      "402:\tlearn: 266086.1767791\ttotal: 1.46s\tremaining: 2.16s\n",
      "403:\tlearn: 266085.3193037\ttotal: 1.46s\tremaining: 2.16s\n",
      "404:\tlearn: 266085.1983633\ttotal: 1.47s\tremaining: 2.16s\n",
      "405:\tlearn: 266085.0860077\ttotal: 1.51s\tremaining: 2.21s\n",
      "406:\tlearn: 266084.9815597\ttotal: 1.52s\tremaining: 2.21s\n",
      "407:\tlearn: 266083.9484695\ttotal: 1.53s\tremaining: 2.22s\n",
      "408:\tlearn: 266083.0608843\ttotal: 1.53s\tremaining: 2.22s\n",
      "409:\tlearn: 266082.9135001\ttotal: 1.54s\tremaining: 2.21s\n",
      "410:\tlearn: 266081.9638785\ttotal: 1.54s\tremaining: 2.21s\n",
      "411:\tlearn: 266080.8850148\ttotal: 1.55s\tremaining: 2.21s\n",
      "412:\tlearn: 266080.6376213\ttotal: 1.55s\tremaining: 2.2s\n",
      "413:\tlearn: 266079.3878068\ttotal: 1.56s\tremaining: 2.2s\n",
      "414:\tlearn: 266079.0131595\ttotal: 1.56s\tremaining: 2.2s\n",
      "415:\tlearn: 266077.9492602\ttotal: 1.56s\tremaining: 2.19s\n",
      "416:\tlearn: 266077.1859841\ttotal: 1.56s\tremaining: 2.19s\n",
      "417:\tlearn: 266076.6488474\ttotal: 1.57s\tremaining: 2.18s\n",
      "418:\tlearn: 266076.1834818\ttotal: 1.57s\tremaining: 2.18s\n",
      "419:\tlearn: 266075.2942070\ttotal: 1.57s\tremaining: 2.17s\n",
      "420:\tlearn: 266074.8591281\ttotal: 1.57s\tremaining: 2.17s\n",
      "421:\tlearn: 266074.2220803\ttotal: 1.58s\tremaining: 2.16s\n",
      "422:\tlearn: 266073.8171058\ttotal: 1.58s\tremaining: 2.15s\n",
      "423:\tlearn: 266072.8856177\ttotal: 1.58s\tremaining: 2.15s\n",
      "424:\tlearn: 266072.5521870\ttotal: 1.58s\tremaining: 2.15s\n",
      "425:\tlearn: 266072.2392158\ttotal: 1.59s\tremaining: 2.14s\n",
      "426:\tlearn: 266071.8679805\ttotal: 1.59s\tremaining: 2.13s\n",
      "427:\tlearn: 266071.7662208\ttotal: 1.59s\tremaining: 2.13s\n",
      "428:\tlearn: 266070.5156737\ttotal: 1.59s\tremaining: 2.12s\n",
      "429:\tlearn: 266070.2101244\ttotal: 1.6s\tremaining: 2.12s\n",
      "430:\tlearn: 266069.4243650\ttotal: 1.6s\tremaining: 2.12s\n",
      "431:\tlearn: 266068.7294182\ttotal: 1.6s\tremaining: 2.11s\n",
      "432:\tlearn: 266068.4754669\ttotal: 1.61s\tremaining: 2.11s\n",
      "433:\tlearn: 266068.2855984\ttotal: 1.61s\tremaining: 2.1s\n",
      "434:\tlearn: 266067.6962460\ttotal: 1.61s\tremaining: 2.1s\n",
      "435:\tlearn: 266066.8348669\ttotal: 1.62s\tremaining: 2.09s\n",
      "436:\tlearn: 266066.1238172\ttotal: 1.62s\tremaining: 2.09s\n",
      "437:\tlearn: 266065.8641308\ttotal: 1.62s\tremaining: 2.08s\n",
      "438:\tlearn: 266065.6918655\ttotal: 1.63s\tremaining: 2.08s\n",
      "439:\tlearn: 266065.1691559\ttotal: 1.63s\tremaining: 2.07s\n",
      "440:\tlearn: 266064.2412113\ttotal: 1.63s\tremaining: 2.07s\n",
      "441:\tlearn: 266064.1537939\ttotal: 1.64s\tremaining: 2.06s\n",
      "442:\tlearn: 266063.6928736\ttotal: 1.64s\tremaining: 2.06s\n",
      "443:\tlearn: 266063.4606673\ttotal: 1.64s\tremaining: 2.05s\n",
      "444:\tlearn: 266062.8201052\ttotal: 1.64s\tremaining: 2.05s\n",
      "445:\tlearn: 266061.6443667\ttotal: 1.65s\tremaining: 2.04s\n",
      "446:\tlearn: 266061.3273039\ttotal: 1.65s\tremaining: 2.04s\n",
      "447:\tlearn: 266061.0889241\ttotal: 1.65s\tremaining: 2.04s\n",
      "448:\tlearn: 266060.3911481\ttotal: 1.65s\tremaining: 2.03s\n",
      "449:\tlearn: 266059.6082070\ttotal: 1.66s\tremaining: 2.02s\n",
      "450:\tlearn: 266059.1836737\ttotal: 1.66s\tremaining: 2.02s\n",
      "451:\tlearn: 266058.9767325\ttotal: 1.66s\tremaining: 2.01s\n",
      "452:\tlearn: 266058.7820336\ttotal: 1.66s\tremaining: 2.01s\n",
      "453:\tlearn: 266058.1511878\ttotal: 1.67s\tremaining: 2s\n",
      "454:\tlearn: 266057.4983141\ttotal: 1.67s\tremaining: 2s\n",
      "455:\tlearn: 266056.3450970\ttotal: 1.67s\tremaining: 1.99s\n",
      "456:\tlearn: 266056.1615320\ttotal: 1.67s\tremaining: 1.99s\n",
      "457:\tlearn: 266055.8184713\ttotal: 1.68s\tremaining: 1.98s\n",
      "458:\tlearn: 266055.2611282\ttotal: 1.68s\tremaining: 1.98s\n",
      "459:\tlearn: 266054.5149698\ttotal: 1.68s\tremaining: 1.97s\n",
      "460:\tlearn: 266053.5776516\ttotal: 1.68s\tremaining: 1.97s\n",
      "461:\tlearn: 266053.0288341\ttotal: 1.69s\tremaining: 1.96s\n",
      "462:\tlearn: 266052.2974015\ttotal: 1.69s\tremaining: 1.96s\n",
      "463:\tlearn: 266052.0539227\ttotal: 1.69s\tremaining: 1.95s\n",
      "464:\tlearn: 266051.8373599\ttotal: 1.7s\tremaining: 1.95s\n",
      "465:\tlearn: 266051.2115569\ttotal: 1.7s\tremaining: 1.95s\n",
      "466:\tlearn: 266050.8683115\ttotal: 1.7s\tremaining: 1.94s\n",
      "467:\tlearn: 266049.9786507\ttotal: 1.7s\tremaining: 1.93s\n",
      "468:\tlearn: 266049.7553336\ttotal: 1.7s\tremaining: 1.93s\n",
      "469:\tlearn: 266049.5496326\ttotal: 1.71s\tremaining: 1.92s\n",
      "470:\tlearn: 266049.4080496\ttotal: 1.71s\tremaining: 1.92s\n",
      "471:\tlearn: 266049.2631656\ttotal: 1.71s\tremaining: 1.91s\n",
      "472:\tlearn: 266049.0590878\ttotal: 1.71s\tremaining: 1.91s\n",
      "473:\tlearn: 266048.7065254\ttotal: 1.72s\tremaining: 1.9s\n",
      "474:\tlearn: 266048.4761381\ttotal: 1.72s\tremaining: 1.9s\n",
      "475:\tlearn: 266048.2851398\ttotal: 1.72s\tremaining: 1.89s\n",
      "476:\tlearn: 266047.4956086\ttotal: 1.72s\tremaining: 1.89s\n",
      "477:\tlearn: 266046.3817284\ttotal: 1.73s\tremaining: 1.88s\n",
      "478:\tlearn: 266045.8816231\ttotal: 1.73s\tremaining: 1.88s\n",
      "479:\tlearn: 266045.5406680\ttotal: 1.73s\tremaining: 1.87s\n",
      "480:\tlearn: 266044.8535833\ttotal: 1.73s\tremaining: 1.87s\n",
      "481:\tlearn: 266044.5302582\ttotal: 1.73s\tremaining: 1.86s\n",
      "482:\tlearn: 266044.4878484\ttotal: 1.74s\tremaining: 1.86s\n",
      "483:\tlearn: 266044.1891113\ttotal: 1.74s\tremaining: 1.85s\n",
      "484:\tlearn: 266044.1280761\ttotal: 1.74s\tremaining: 1.85s\n",
      "485:\tlearn: 266043.7333259\ttotal: 1.74s\tremaining: 1.84s\n",
      "486:\tlearn: 266043.1356155\ttotal: 1.75s\tremaining: 1.84s\n",
      "487:\tlearn: 266042.7270861\ttotal: 1.75s\tremaining: 1.83s\n",
      "488:\tlearn: 266042.0951039\ttotal: 1.75s\tremaining: 1.83s\n",
      "489:\tlearn: 266041.6013551\ttotal: 1.75s\tremaining: 1.82s\n",
      "490:\tlearn: 266041.1812115\ttotal: 1.76s\tremaining: 1.82s\n",
      "491:\tlearn: 266040.3687866\ttotal: 1.76s\tremaining: 1.82s\n",
      "492:\tlearn: 266039.5653784\ttotal: 1.76s\tremaining: 1.81s\n",
      "493:\tlearn: 266039.0827220\ttotal: 1.76s\tremaining: 1.81s\n",
      "494:\tlearn: 266038.9092868\ttotal: 1.77s\tremaining: 1.8s\n",
      "495:\tlearn: 266038.4174278\ttotal: 1.77s\tremaining: 1.8s\n",
      "496:\tlearn: 266038.2657946\ttotal: 1.77s\tremaining: 1.79s\n",
      "497:\tlearn: 266037.7914383\ttotal: 1.77s\tremaining: 1.79s\n",
      "498:\tlearn: 266037.2594663\ttotal: 1.78s\tremaining: 1.78s\n",
      "499:\tlearn: 266036.7366327\ttotal: 1.78s\tremaining: 1.78s\n",
      "500:\tlearn: 266036.5713427\ttotal: 1.78s\tremaining: 1.78s\n",
      "501:\tlearn: 266036.5182290\ttotal: 1.79s\tremaining: 1.77s\n",
      "502:\tlearn: 266036.2866654\ttotal: 1.79s\tremaining: 1.77s\n",
      "503:\tlearn: 266036.2378126\ttotal: 1.79s\tremaining: 1.77s\n",
      "504:\tlearn: 266035.7275151\ttotal: 1.8s\tremaining: 1.76s\n",
      "505:\tlearn: 266035.3777593\ttotal: 1.8s\tremaining: 1.76s\n",
      "506:\tlearn: 266035.3270289\ttotal: 1.8s\tremaining: 1.75s\n",
      "507:\tlearn: 266035.1553381\ttotal: 1.81s\tremaining: 1.75s\n",
      "508:\tlearn: 266034.8174512\ttotal: 1.81s\tremaining: 1.75s\n",
      "509:\tlearn: 266034.6157405\ttotal: 1.81s\tremaining: 1.74s\n",
      "510:\tlearn: 266034.5003924\ttotal: 1.82s\tremaining: 1.74s\n",
      "511:\tlearn: 266034.3981581\ttotal: 1.82s\tremaining: 1.74s\n",
      "512:\tlearn: 266034.3012170\ttotal: 1.82s\tremaining: 1.73s\n",
      "513:\tlearn: 266033.6563325\ttotal: 1.83s\tremaining: 1.73s\n",
      "514:\tlearn: 266033.5195233\ttotal: 1.83s\tremaining: 1.72s\n",
      "515:\tlearn: 266033.2909512\ttotal: 1.83s\tremaining: 1.72s\n",
      "516:\tlearn: 266032.7026887\ttotal: 1.84s\tremaining: 1.72s\n",
      "517:\tlearn: 266032.2230995\ttotal: 1.84s\tremaining: 1.71s\n",
      "518:\tlearn: 266031.8090861\ttotal: 1.84s\tremaining: 1.71s\n",
      "519:\tlearn: 266031.2594621\ttotal: 1.85s\tremaining: 1.71s\n",
      "520:\tlearn: 266030.9655836\ttotal: 1.85s\tremaining: 1.7s\n",
      "521:\tlearn: 266030.7666657\ttotal: 1.85s\tremaining: 1.7s\n",
      "522:\tlearn: 266030.3154721\ttotal: 1.86s\tremaining: 1.69s\n",
      "523:\tlearn: 266029.9438985\ttotal: 1.86s\tremaining: 1.69s\n",
      "524:\tlearn: 266029.6264720\ttotal: 1.86s\tremaining: 1.69s\n",
      "525:\tlearn: 266029.3152457\ttotal: 1.87s\tremaining: 1.68s\n",
      "526:\tlearn: 266029.0718223\ttotal: 1.87s\tremaining: 1.68s\n",
      "527:\tlearn: 266028.9588903\ttotal: 1.87s\tremaining: 1.67s\n",
      "528:\tlearn: 266028.7316528\ttotal: 1.87s\tremaining: 1.67s\n",
      "529:\tlearn: 266028.2942522\ttotal: 1.88s\tremaining: 1.67s\n",
      "530:\tlearn: 266028.0489381\ttotal: 1.88s\tremaining: 1.66s\n",
      "531:\tlearn: 266027.6683813\ttotal: 1.89s\tremaining: 1.66s\n",
      "532:\tlearn: 266027.3589657\ttotal: 1.89s\tremaining: 1.65s\n",
      "533:\tlearn: 266027.0850701\ttotal: 1.89s\tremaining: 1.65s\n",
      "534:\tlearn: 266026.7693320\ttotal: 1.9s\tremaining: 1.65s\n",
      "535:\tlearn: 266026.6030480\ttotal: 1.9s\tremaining: 1.64s\n",
      "536:\tlearn: 266026.5212668\ttotal: 1.9s\tremaining: 1.64s\n",
      "537:\tlearn: 266026.0926490\ttotal: 1.91s\tremaining: 1.64s\n",
      "538:\tlearn: 266025.7616416\ttotal: 1.91s\tremaining: 1.63s\n",
      "539:\tlearn: 266025.6859095\ttotal: 1.91s\tremaining: 1.63s\n",
      "540:\tlearn: 266025.5668179\ttotal: 1.92s\tremaining: 1.62s\n",
      "541:\tlearn: 266025.1954748\ttotal: 1.92s\tremaining: 1.62s\n",
      "542:\tlearn: 266025.0866009\ttotal: 1.92s\tremaining: 1.62s\n",
      "543:\tlearn: 266024.7589937\ttotal: 1.92s\tremaining: 1.61s\n",
      "544:\tlearn: 266024.6812032\ttotal: 1.93s\tremaining: 1.61s\n",
      "545:\tlearn: 266024.5740689\ttotal: 1.93s\tremaining: 1.6s\n",
      "546:\tlearn: 266024.4765346\ttotal: 1.93s\tremaining: 1.6s\n",
      "547:\tlearn: 266024.3770460\ttotal: 1.94s\tremaining: 1.6s\n",
      "548:\tlearn: 266024.0452311\ttotal: 1.94s\tremaining: 1.59s\n",
      "549:\tlearn: 266023.8068189\ttotal: 1.95s\tremaining: 1.59s\n",
      "550:\tlearn: 266023.5305146\ttotal: 1.95s\tremaining: 1.59s\n",
      "551:\tlearn: 266023.2495348\ttotal: 1.95s\tremaining: 1.58s\n",
      "552:\tlearn: 266023.0655044\ttotal: 1.96s\tremaining: 1.58s\n",
      "553:\tlearn: 266022.9760468\ttotal: 1.96s\tremaining: 1.58s\n",
      "554:\tlearn: 266022.8873437\ttotal: 1.96s\tremaining: 1.57s\n",
      "555:\tlearn: 266022.3541566\ttotal: 1.96s\tremaining: 1.57s\n",
      "556:\tlearn: 266022.2764697\ttotal: 1.97s\tremaining: 1.57s\n",
      "557:\tlearn: 266022.0148119\ttotal: 1.97s\tremaining: 1.56s\n",
      "558:\tlearn: 266021.9366340\ttotal: 1.98s\tremaining: 1.56s\n",
      "559:\tlearn: 266021.7163690\ttotal: 1.98s\tremaining: 1.56s\n",
      "560:\tlearn: 266021.6391975\ttotal: 1.99s\tremaining: 1.55s\n",
      "561:\tlearn: 266021.5663638\ttotal: 1.99s\tremaining: 1.55s\n",
      "562:\tlearn: 266021.4976072\ttotal: 1.99s\tremaining: 1.54s\n",
      "563:\tlearn: 266021.0724830\ttotal: 2s\tremaining: 1.54s\n",
      "564:\tlearn: 266020.9520965\ttotal: 2s\tremaining: 1.54s\n",
      "565:\tlearn: 266020.7912733\ttotal: 2s\tremaining: 1.53s\n",
      "566:\tlearn: 266020.6936367\ttotal: 2s\tremaining: 1.53s\n",
      "567:\tlearn: 266020.4121766\ttotal: 2.01s\tremaining: 1.53s\n",
      "568:\tlearn: 266020.2160339\ttotal: 2.01s\tremaining: 1.52s\n",
      "569:\tlearn: 266019.9341925\ttotal: 2.01s\tremaining: 1.52s\n",
      "570:\tlearn: 266019.7105459\ttotal: 2.02s\tremaining: 1.52s\n",
      "571:\tlearn: 266019.4779478\ttotal: 2.06s\tremaining: 1.54s\n",
      "572:\tlearn: 266019.1899676\ttotal: 2.07s\tremaining: 1.54s\n",
      "573:\tlearn: 266018.9891921\ttotal: 2.08s\tremaining: 1.54s\n",
      "574:\tlearn: 266018.8490157\ttotal: 2.08s\tremaining: 1.54s\n",
      "575:\tlearn: 266018.5746502\ttotal: 2.09s\tremaining: 1.54s\n",
      "576:\tlearn: 266018.3317883\ttotal: 2.09s\tremaining: 1.53s\n",
      "577:\tlearn: 266017.8892549\ttotal: 2.09s\tremaining: 1.53s\n",
      "578:\tlearn: 266017.5447722\ttotal: 2.1s\tremaining: 1.52s\n",
      "579:\tlearn: 266017.4065142\ttotal: 2.1s\tremaining: 1.52s\n",
      "580:\tlearn: 266017.1454431\ttotal: 2.1s\tremaining: 1.52s\n",
      "581:\tlearn: 266016.7730013\ttotal: 2.11s\tremaining: 1.51s\n",
      "582:\tlearn: 266016.5572583\ttotal: 2.11s\tremaining: 1.51s\n",
      "583:\tlearn: 266016.3832607\ttotal: 2.12s\tremaining: 1.51s\n",
      "584:\tlearn: 266016.1552309\ttotal: 2.12s\tremaining: 1.5s\n",
      "585:\tlearn: 266016.1202771\ttotal: 2.12s\tremaining: 1.5s\n",
      "586:\tlearn: 266015.8313204\ttotal: 2.12s\tremaining: 1.49s\n",
      "587:\tlearn: 266015.3319686\ttotal: 2.13s\tremaining: 1.49s\n",
      "588:\tlearn: 266015.2709935\ttotal: 2.13s\tremaining: 1.49s\n",
      "589:\tlearn: 266015.0465558\ttotal: 2.13s\tremaining: 1.48s\n",
      "590:\tlearn: 266014.9889994\ttotal: 2.14s\tremaining: 1.48s\n",
      "591:\tlearn: 266014.8102757\ttotal: 2.14s\tremaining: 1.47s\n",
      "592:\tlearn: 266014.6726949\ttotal: 2.14s\tremaining: 1.47s\n",
      "593:\tlearn: 266014.2475220\ttotal: 2.15s\tremaining: 1.47s\n",
      "594:\tlearn: 266014.0224271\ttotal: 2.15s\tremaining: 1.46s\n",
      "595:\tlearn: 266013.9682660\ttotal: 2.15s\tremaining: 1.46s\n",
      "596:\tlearn: 266013.9171047\ttotal: 2.15s\tremaining: 1.45s\n",
      "597:\tlearn: 266013.8067118\ttotal: 2.16s\tremaining: 1.45s\n",
      "598:\tlearn: 266013.6495176\ttotal: 2.16s\tremaining: 1.45s\n",
      "599:\tlearn: 266013.4872544\ttotal: 2.17s\tremaining: 1.44s\n",
      "600:\tlearn: 266013.4416519\ttotal: 2.17s\tremaining: 1.44s\n",
      "601:\tlearn: 266013.2382687\ttotal: 2.17s\tremaining: 1.44s\n",
      "602:\tlearn: 266012.9824983\ttotal: 2.18s\tremaining: 1.43s\n",
      "603:\tlearn: 266012.9391777\ttotal: 2.18s\tremaining: 1.43s\n",
      "604:\tlearn: 266012.7178005\ttotal: 2.18s\tremaining: 1.43s\n",
      "605:\tlearn: 266012.5998331\ttotal: 2.19s\tremaining: 1.42s\n",
      "606:\tlearn: 266012.3724377\ttotal: 2.19s\tremaining: 1.42s\n",
      "607:\tlearn: 266012.1210743\ttotal: 2.19s\tremaining: 1.41s\n",
      "608:\tlearn: 266011.9476821\ttotal: 2.19s\tremaining: 1.41s\n",
      "609:\tlearn: 266011.8398521\ttotal: 2.2s\tremaining: 1.41s\n",
      "610:\tlearn: 266011.6729481\ttotal: 2.2s\tremaining: 1.4s\n",
      "611:\tlearn: 266011.4230351\ttotal: 2.21s\tremaining: 1.4s\n",
      "612:\tlearn: 266011.3805211\ttotal: 2.21s\tremaining: 1.39s\n",
      "613:\tlearn: 266011.3403424\ttotal: 2.21s\tremaining: 1.39s\n",
      "614:\tlearn: 266011.2597065\ttotal: 2.21s\tremaining: 1.39s\n",
      "615:\tlearn: 266011.1107296\ttotal: 2.22s\tremaining: 1.38s\n",
      "616:\tlearn: 266011.0730768\ttotal: 2.22s\tremaining: 1.38s\n",
      "617:\tlearn: 266010.8977304\ttotal: 2.23s\tremaining: 1.38s\n",
      "618:\tlearn: 266010.8586547\ttotal: 2.23s\tremaining: 1.37s\n",
      "619:\tlearn: 266010.5328248\ttotal: 2.23s\tremaining: 1.37s\n",
      "620:\tlearn: 266010.3814950\ttotal: 2.24s\tremaining: 1.36s\n",
      "621:\tlearn: 266010.2191041\ttotal: 2.24s\tremaining: 1.36s\n",
      "622:\tlearn: 266009.9986197\ttotal: 2.24s\tremaining: 1.36s\n",
      "623:\tlearn: 266009.9659954\ttotal: 2.25s\tremaining: 1.35s\n",
      "624:\tlearn: 266009.8933432\ttotal: 2.25s\tremaining: 1.35s\n",
      "625:\tlearn: 266009.8593808\ttotal: 2.25s\tremaining: 1.34s\n",
      "626:\tlearn: 266009.7426200\ttotal: 2.25s\tremaining: 1.34s\n",
      "627:\tlearn: 266009.6758519\ttotal: 2.26s\tremaining: 1.34s\n",
      "628:\tlearn: 266009.3469606\ttotal: 2.26s\tremaining: 1.33s\n",
      "629:\tlearn: 266009.1627967\ttotal: 2.26s\tremaining: 1.33s\n",
      "630:\tlearn: 266009.0204217\ttotal: 2.26s\tremaining: 1.32s\n",
      "631:\tlearn: 266008.8448820\ttotal: 2.27s\tremaining: 1.32s\n",
      "632:\tlearn: 266008.7076534\ttotal: 2.27s\tremaining: 1.32s\n",
      "633:\tlearn: 266008.6463975\ttotal: 2.27s\tremaining: 1.31s\n",
      "634:\tlearn: 266008.4427611\ttotal: 2.28s\tremaining: 1.31s\n",
      "635:\tlearn: 266008.2486384\ttotal: 2.28s\tremaining: 1.3s\n",
      "636:\tlearn: 266008.0879183\ttotal: 2.28s\tremaining: 1.3s\n",
      "637:\tlearn: 266007.9050338\ttotal: 2.29s\tremaining: 1.3s\n",
      "638:\tlearn: 266007.7118424\ttotal: 2.29s\tremaining: 1.29s\n",
      "639:\tlearn: 266007.5575442\ttotal: 2.29s\tremaining: 1.29s\n",
      "640:\tlearn: 266007.4082787\ttotal: 2.29s\tremaining: 1.28s\n",
      "641:\tlearn: 266007.2915392\ttotal: 2.29s\tremaining: 1.28s\n",
      "642:\tlearn: 266007.2085147\ttotal: 2.3s\tremaining: 1.28s\n",
      "643:\tlearn: 266007.0473518\ttotal: 2.3s\tremaining: 1.27s\n",
      "644:\tlearn: 266006.8218997\ttotal: 2.31s\tremaining: 1.27s\n",
      "645:\tlearn: 266006.7326967\ttotal: 2.31s\tremaining: 1.26s\n",
      "646:\tlearn: 266006.5814524\ttotal: 2.31s\tremaining: 1.26s\n",
      "647:\tlearn: 266006.4479071\ttotal: 2.31s\tremaining: 1.26s\n",
      "648:\tlearn: 266006.2457786\ttotal: 2.32s\tremaining: 1.25s\n",
      "649:\tlearn: 266006.1014504\ttotal: 2.32s\tremaining: 1.25s\n",
      "650:\tlearn: 266005.9035891\ttotal: 2.32s\tremaining: 1.24s\n",
      "651:\tlearn: 266005.8175621\ttotal: 2.32s\tremaining: 1.24s\n",
      "652:\tlearn: 266005.7452952\ttotal: 2.33s\tremaining: 1.24s\n",
      "653:\tlearn: 266005.6949383\ttotal: 2.33s\tremaining: 1.23s\n",
      "654:\tlearn: 266005.6216748\ttotal: 2.33s\tremaining: 1.23s\n",
      "655:\tlearn: 266005.4820783\ttotal: 2.34s\tremaining: 1.23s\n",
      "656:\tlearn: 266005.3307801\ttotal: 2.34s\tremaining: 1.22s\n",
      "657:\tlearn: 266005.1345219\ttotal: 2.34s\tremaining: 1.22s\n",
      "658:\tlearn: 266005.1068421\ttotal: 2.35s\tremaining: 1.21s\n",
      "659:\tlearn: 266004.9768367\ttotal: 2.35s\tremaining: 1.21s\n",
      "660:\tlearn: 266004.8635224\ttotal: 2.35s\tremaining: 1.21s\n",
      "661:\tlearn: 266004.6420181\ttotal: 2.35s\tremaining: 1.2s\n",
      "662:\tlearn: 266004.5668081\ttotal: 2.36s\tremaining: 1.2s\n",
      "663:\tlearn: 266004.4417510\ttotal: 2.36s\tremaining: 1.2s\n",
      "664:\tlearn: 266004.2749782\ttotal: 2.36s\tremaining: 1.19s\n",
      "665:\tlearn: 266004.1270040\ttotal: 2.37s\tremaining: 1.19s\n",
      "666:\tlearn: 266003.9081236\ttotal: 2.37s\tremaining: 1.18s\n",
      "667:\tlearn: 266003.7692270\ttotal: 2.37s\tremaining: 1.18s\n",
      "668:\tlearn: 266003.7406343\ttotal: 2.38s\tremaining: 1.18s\n",
      "669:\tlearn: 266003.7063868\ttotal: 2.38s\tremaining: 1.17s\n",
      "670:\tlearn: 266003.6117609\ttotal: 2.38s\tremaining: 1.17s\n",
      "671:\tlearn: 266003.4877164\ttotal: 2.39s\tremaining: 1.16s\n",
      "672:\tlearn: 266003.4310785\ttotal: 2.39s\tremaining: 1.16s\n",
      "673:\tlearn: 266003.3957530\ttotal: 2.39s\tremaining: 1.16s\n",
      "674:\tlearn: 266003.1779018\ttotal: 2.4s\tremaining: 1.15s\n",
      "675:\tlearn: 266003.0562602\ttotal: 2.4s\tremaining: 1.15s\n",
      "676:\tlearn: 266002.8893295\ttotal: 2.4s\tremaining: 1.15s\n",
      "677:\tlearn: 266002.7450882\ttotal: 2.41s\tremaining: 1.14s\n",
      "678:\tlearn: 266002.6200909\ttotal: 2.41s\tremaining: 1.14s\n",
      "679:\tlearn: 266002.5639475\ttotal: 2.41s\tremaining: 1.14s\n",
      "680:\tlearn: 266002.4665897\ttotal: 2.42s\tremaining: 1.13s\n",
      "681:\tlearn: 266002.3599997\ttotal: 2.42s\tremaining: 1.13s\n",
      "682:\tlearn: 266002.3035798\ttotal: 2.42s\tremaining: 1.12s\n",
      "683:\tlearn: 266002.1771572\ttotal: 2.42s\tremaining: 1.12s\n",
      "684:\tlearn: 266002.0752546\ttotal: 2.43s\tremaining: 1.12s\n",
      "685:\tlearn: 266001.9112683\ttotal: 2.43s\tremaining: 1.11s\n",
      "686:\tlearn: 266001.7965202\ttotal: 2.43s\tremaining: 1.11s\n",
      "687:\tlearn: 266001.6889812\ttotal: 2.43s\tremaining: 1.1s\n",
      "688:\tlearn: 266001.6679177\ttotal: 2.44s\tremaining: 1.1s\n",
      "689:\tlearn: 266001.5105089\ttotal: 2.44s\tremaining: 1.1s\n",
      "690:\tlearn: 266001.3845119\ttotal: 2.44s\tremaining: 1.09s\n",
      "691:\tlearn: 266001.2812394\ttotal: 2.44s\tremaining: 1.09s\n",
      "692:\tlearn: 266001.1535615\ttotal: 2.45s\tremaining: 1.08s\n",
      "693:\tlearn: 266001.0567002\ttotal: 2.45s\tremaining: 1.08s\n",
      "694:\tlearn: 266000.9680644\ttotal: 2.45s\tremaining: 1.08s\n",
      "695:\tlearn: 266000.8277509\ttotal: 2.46s\tremaining: 1.07s\n",
      "696:\tlearn: 266000.8038307\ttotal: 2.46s\tremaining: 1.07s\n",
      "697:\tlearn: 266000.7734242\ttotal: 2.46s\tremaining: 1.06s\n",
      "698:\tlearn: 266000.6990589\ttotal: 2.46s\tremaining: 1.06s\n",
      "699:\tlearn: 266000.5820591\ttotal: 2.47s\tremaining: 1.06s\n",
      "700:\tlearn: 266000.5503303\ttotal: 2.47s\tremaining: 1.05s\n",
      "701:\tlearn: 266000.4077493\ttotal: 2.47s\tremaining: 1.05s\n",
      "702:\tlearn: 266000.3605384\ttotal: 2.48s\tremaining: 1.05s\n",
      "703:\tlearn: 266000.2683007\ttotal: 2.48s\tremaining: 1.04s\n",
      "704:\tlearn: 266000.2580887\ttotal: 2.48s\tremaining: 1.04s\n",
      "705:\tlearn: 266000.1400200\ttotal: 2.48s\tremaining: 1.03s\n",
      "706:\tlearn: 266000.0555166\ttotal: 2.49s\tremaining: 1.03s\n",
      "707:\tlearn: 265999.9681279\ttotal: 2.49s\tremaining: 1.03s\n",
      "708:\tlearn: 265999.8640828\ttotal: 2.49s\tremaining: 1.02s\n",
      "709:\tlearn: 265999.8502820\ttotal: 2.5s\tremaining: 1.02s\n",
      "710:\tlearn: 265999.7288867\ttotal: 2.5s\tremaining: 1.01s\n",
      "711:\tlearn: 265999.6618945\ttotal: 2.5s\tremaining: 1.01s\n",
      "712:\tlearn: 265999.6489095\ttotal: 2.5s\tremaining: 1.01s\n",
      "713:\tlearn: 265999.5462025\ttotal: 2.51s\tremaining: 1s\n",
      "714:\tlearn: 265999.5339936\ttotal: 2.51s\tremaining: 1s\n",
      "715:\tlearn: 265999.5061273\ttotal: 2.51s\tremaining: 997ms\n",
      "716:\tlearn: 265999.4022636\ttotal: 2.52s\tremaining: 994ms\n",
      "717:\tlearn: 265999.3562960\ttotal: 2.52s\tremaining: 990ms\n",
      "718:\tlearn: 265999.2484582\ttotal: 2.52s\tremaining: 987ms\n",
      "719:\tlearn: 265999.2371387\ttotal: 2.53s\tremaining: 983ms\n",
      "720:\tlearn: 265999.2264921\ttotal: 2.53s\tremaining: 979ms\n",
      "721:\tlearn: 265999.1258158\ttotal: 2.54s\tremaining: 976ms\n",
      "722:\tlearn: 265998.9926747\ttotal: 2.54s\tremaining: 972ms\n",
      "723:\tlearn: 265998.9086668\ttotal: 2.54s\tremaining: 969ms\n",
      "724:\tlearn: 265998.7909912\ttotal: 2.54s\tremaining: 965ms\n",
      "725:\tlearn: 265998.6993552\ttotal: 2.55s\tremaining: 963ms\n",
      "726:\tlearn: 265998.6129437\ttotal: 2.55s\tremaining: 959ms\n",
      "727:\tlearn: 265998.5890629\ttotal: 2.56s\tremaining: 955ms\n",
      "728:\tlearn: 265998.5163742\ttotal: 2.56s\tremaining: 951ms\n",
      "729:\tlearn: 265998.4411658\ttotal: 2.56s\tremaining: 948ms\n",
      "730:\tlearn: 265998.3563989\ttotal: 2.57s\tremaining: 945ms\n",
      "731:\tlearn: 265998.3465014\ttotal: 2.57s\tremaining: 942ms\n",
      "732:\tlearn: 265998.2207188\ttotal: 2.57s\tremaining: 938ms\n",
      "733:\tlearn: 265998.2141282\ttotal: 2.58s\tremaining: 934ms\n",
      "734:\tlearn: 265998.1374391\ttotal: 2.58s\tremaining: 931ms\n",
      "735:\tlearn: 265998.0294782\ttotal: 2.58s\tremaining: 928ms\n",
      "736:\tlearn: 265997.9812584\ttotal: 2.59s\tremaining: 924ms\n",
      "737:\tlearn: 265997.8847173\ttotal: 2.6s\tremaining: 922ms\n",
      "738:\tlearn: 265997.7818225\ttotal: 2.6s\tremaining: 919ms\n",
      "739:\tlearn: 265997.7031806\ttotal: 2.61s\tremaining: 916ms\n",
      "740:\tlearn: 265997.6481788\ttotal: 2.61s\tremaining: 913ms\n",
      "741:\tlearn: 265997.5478669\ttotal: 2.62s\tremaining: 910ms\n",
      "742:\tlearn: 265997.5133093\ttotal: 2.62s\tremaining: 906ms\n",
      "743:\tlearn: 265997.5075379\ttotal: 2.66s\tremaining: 916ms\n",
      "744:\tlearn: 265997.4862201\ttotal: 2.67s\tremaining: 914ms\n",
      "745:\tlearn: 265997.4650011\ttotal: 2.68s\tremaining: 913ms\n",
      "746:\tlearn: 265997.3769278\ttotal: 2.69s\tremaining: 911ms\n",
      "747:\tlearn: 265997.2989041\ttotal: 2.69s\tremaining: 907ms\n",
      "748:\tlearn: 265997.1957110\ttotal: 2.7s\tremaining: 904ms\n",
      "749:\tlearn: 265997.0902569\ttotal: 2.7s\tremaining: 900ms\n",
      "750:\tlearn: 265997.0222443\ttotal: 2.7s\tremaining: 897ms\n",
      "751:\tlearn: 265996.9707123\ttotal: 2.71s\tremaining: 894ms\n",
      "752:\tlearn: 265996.8775769\ttotal: 2.71s\tremaining: 890ms\n",
      "753:\tlearn: 265996.8130349\ttotal: 2.72s\tremaining: 887ms\n",
      "754:\tlearn: 265996.7336466\ttotal: 2.72s\tremaining: 883ms\n",
      "755:\tlearn: 265996.6484376\ttotal: 2.72s\tremaining: 879ms\n",
      "756:\tlearn: 265996.5696548\ttotal: 2.73s\tremaining: 875ms\n",
      "757:\tlearn: 265996.5562098\ttotal: 2.73s\tremaining: 871ms\n",
      "758:\tlearn: 265996.5118689\ttotal: 2.73s\tremaining: 867ms\n",
      "759:\tlearn: 265996.4890293\ttotal: 2.73s\tremaining: 863ms\n",
      "760:\tlearn: 265996.4402370\ttotal: 2.73s\tremaining: 859ms\n",
      "761:\tlearn: 265996.3396638\ttotal: 2.74s\tremaining: 855ms\n",
      "762:\tlearn: 265996.2626651\ttotal: 2.74s\tremaining: 851ms\n",
      "763:\tlearn: 265996.2052133\ttotal: 2.74s\tremaining: 847ms\n",
      "764:\tlearn: 265996.1312497\ttotal: 2.75s\tremaining: 843ms\n",
      "765:\tlearn: 265996.0520800\ttotal: 2.75s\tremaining: 839ms\n",
      "766:\tlearn: 265996.0397503\ttotal: 2.75s\tremaining: 836ms\n",
      "767:\tlearn: 265995.9660173\ttotal: 2.75s\tremaining: 832ms\n",
      "768:\tlearn: 265995.8979944\ttotal: 2.76s\tremaining: 828ms\n",
      "769:\tlearn: 265995.8384714\ttotal: 2.76s\tremaining: 824ms\n",
      "770:\tlearn: 265995.7996240\ttotal: 2.76s\tremaining: 821ms\n",
      "771:\tlearn: 265995.7125662\ttotal: 2.77s\tremaining: 817ms\n",
      "772:\tlearn: 265995.6376503\ttotal: 2.77s\tremaining: 813ms\n",
      "773:\tlearn: 265995.5751952\ttotal: 2.77s\tremaining: 810ms\n",
      "774:\tlearn: 265995.5623066\ttotal: 2.77s\tremaining: 806ms\n",
      "775:\tlearn: 265995.5435100\ttotal: 2.78s\tremaining: 802ms\n",
      "776:\tlearn: 265995.5170615\ttotal: 2.78s\tremaining: 798ms\n",
      "777:\tlearn: 265995.4976646\ttotal: 2.78s\tremaining: 794ms\n",
      "778:\tlearn: 265995.4183317\ttotal: 2.79s\tremaining: 790ms\n",
      "779:\tlearn: 265995.3382685\ttotal: 2.79s\tremaining: 787ms\n",
      "780:\tlearn: 265995.3123280\ttotal: 2.79s\tremaining: 783ms\n",
      "781:\tlearn: 265995.2528400\ttotal: 2.79s\tremaining: 779ms\n",
      "782:\tlearn: 265995.1964552\ttotal: 2.8s\tremaining: 775ms\n",
      "783:\tlearn: 265995.1280249\ttotal: 2.8s\tremaining: 771ms\n",
      "784:\tlearn: 265995.0474379\ttotal: 2.8s\tremaining: 768ms\n",
      "785:\tlearn: 265994.9437303\ttotal: 2.81s\tremaining: 764ms\n",
      "786:\tlearn: 265994.8729812\ttotal: 2.81s\tremaining: 760ms\n",
      "787:\tlearn: 265994.7933922\ttotal: 2.81s\tremaining: 756ms\n",
      "788:\tlearn: 265994.7200148\ttotal: 2.81s\tremaining: 752ms\n",
      "789:\tlearn: 265994.6512218\ttotal: 2.81s\tremaining: 748ms\n",
      "790:\tlearn: 265994.6425649\ttotal: 2.82s\tremaining: 745ms\n",
      "791:\tlearn: 265994.6249705\ttotal: 2.82s\tremaining: 741ms\n",
      "792:\tlearn: 265994.5612654\ttotal: 2.82s\tremaining: 737ms\n",
      "793:\tlearn: 265994.4992855\ttotal: 2.83s\tremaining: 733ms\n",
      "794:\tlearn: 265994.4183238\ttotal: 2.83s\tremaining: 729ms\n",
      "795:\tlearn: 265994.3435865\ttotal: 2.83s\tremaining: 725ms\n",
      "796:\tlearn: 265994.2397817\ttotal: 2.83s\tremaining: 722ms\n",
      "797:\tlearn: 265994.2301857\ttotal: 2.84s\tremaining: 718ms\n",
      "798:\tlearn: 265994.2162263\ttotal: 2.84s\tremaining: 714ms\n",
      "799:\tlearn: 265994.1454247\ttotal: 2.84s\tremaining: 711ms\n",
      "800:\tlearn: 265994.1239962\ttotal: 2.84s\tremaining: 707ms\n",
      "801:\tlearn: 265994.0727987\ttotal: 2.85s\tremaining: 703ms\n",
      "802:\tlearn: 265994.0635157\ttotal: 2.85s\tremaining: 699ms\n",
      "803:\tlearn: 265994.0275581\ttotal: 2.85s\tremaining: 695ms\n",
      "804:\tlearn: 265994.0188258\ttotal: 2.85s\tremaining: 692ms\n",
      "805:\tlearn: 265994.0100472\ttotal: 2.86s\tremaining: 688ms\n",
      "806:\tlearn: 265993.9299948\ttotal: 2.86s\tremaining: 684ms\n",
      "807:\tlearn: 265993.8746628\ttotal: 2.86s\tremaining: 680ms\n",
      "808:\tlearn: 265993.8045726\ttotal: 2.87s\tremaining: 677ms\n",
      "809:\tlearn: 265993.7622941\ttotal: 2.87s\tremaining: 673ms\n",
      "810:\tlearn: 265993.7004410\ttotal: 2.87s\tremaining: 669ms\n",
      "811:\tlearn: 265993.6496377\ttotal: 2.87s\tremaining: 666ms\n",
      "812:\tlearn: 265993.5549413\ttotal: 2.88s\tremaining: 662ms\n",
      "813:\tlearn: 265993.5204312\ttotal: 2.88s\tremaining: 658ms\n",
      "814:\tlearn: 265993.4616321\ttotal: 2.88s\tremaining: 654ms\n",
      "815:\tlearn: 265993.4059151\ttotal: 2.88s\tremaining: 651ms\n",
      "816:\tlearn: 265993.3793695\ttotal: 2.89s\tremaining: 647ms\n",
      "817:\tlearn: 265993.3519152\ttotal: 2.89s\tremaining: 643ms\n",
      "818:\tlearn: 265993.3433875\ttotal: 2.89s\tremaining: 639ms\n",
      "819:\tlearn: 265993.2886597\ttotal: 2.89s\tremaining: 635ms\n",
      "820:\tlearn: 265993.2292674\ttotal: 2.9s\tremaining: 632ms\n",
      "821:\tlearn: 265993.2085100\ttotal: 2.9s\tremaining: 628ms\n",
      "822:\tlearn: 265993.1545830\ttotal: 2.9s\tremaining: 624ms\n",
      "823:\tlearn: 265993.1108235\ttotal: 2.9s\tremaining: 620ms\n",
      "824:\tlearn: 265993.0721079\ttotal: 2.9s\tremaining: 616ms\n",
      "825:\tlearn: 265993.0136460\ttotal: 2.91s\tremaining: 613ms\n",
      "826:\tlearn: 265992.9376854\ttotal: 2.91s\tremaining: 609ms\n",
      "827:\tlearn: 265992.9287670\ttotal: 2.91s\tremaining: 605ms\n",
      "828:\tlearn: 265992.8437572\ttotal: 2.92s\tremaining: 601ms\n",
      "829:\tlearn: 265992.7983476\ttotal: 2.92s\tremaining: 598ms\n",
      "830:\tlearn: 265992.7854090\ttotal: 2.92s\tremaining: 594ms\n",
      "831:\tlearn: 265992.7617596\ttotal: 2.92s\tremaining: 590ms\n",
      "832:\tlearn: 265992.7235122\ttotal: 2.93s\tremaining: 587ms\n",
      "833:\tlearn: 265992.6975823\ttotal: 2.93s\tremaining: 583ms\n",
      "834:\tlearn: 265992.6911540\ttotal: 2.93s\tremaining: 579ms\n",
      "835:\tlearn: 265992.6265133\ttotal: 2.93s\tremaining: 575ms\n",
      "836:\tlearn: 265992.5890074\ttotal: 2.94s\tremaining: 572ms\n",
      "837:\tlearn: 265992.5775733\ttotal: 2.94s\tremaining: 568ms\n",
      "838:\tlearn: 265992.5352971\ttotal: 2.94s\tremaining: 565ms\n",
      "839:\tlearn: 265992.4940816\ttotal: 2.94s\tremaining: 561ms\n",
      "840:\tlearn: 265992.4293373\ttotal: 2.95s\tremaining: 557ms\n",
      "841:\tlearn: 265992.3670783\ttotal: 2.95s\tremaining: 554ms\n",
      "842:\tlearn: 265992.3508997\ttotal: 2.95s\tremaining: 550ms\n",
      "843:\tlearn: 265992.3077702\ttotal: 2.96s\tremaining: 547ms\n",
      "844:\tlearn: 265992.2738215\ttotal: 2.96s\tremaining: 543ms\n",
      "845:\tlearn: 265992.2180103\ttotal: 2.96s\tremaining: 539ms\n",
      "846:\tlearn: 265992.1815719\ttotal: 2.96s\tremaining: 536ms\n",
      "847:\tlearn: 265992.1291252\ttotal: 2.97s\tremaining: 532ms\n",
      "848:\tlearn: 265992.0952889\ttotal: 2.97s\tremaining: 528ms\n",
      "849:\tlearn: 265992.0505080\ttotal: 2.98s\tremaining: 525ms\n",
      "850:\tlearn: 265991.9810850\ttotal: 2.98s\tremaining: 521ms\n",
      "851:\tlearn: 265991.9196915\ttotal: 2.98s\tremaining: 518ms\n",
      "852:\tlearn: 265991.8813544\ttotal: 2.98s\tremaining: 514ms\n",
      "853:\tlearn: 265991.8245351\ttotal: 2.98s\tremaining: 510ms\n",
      "854:\tlearn: 265991.7780351\ttotal: 2.99s\tremaining: 507ms\n",
      "855:\tlearn: 265991.7450313\ttotal: 2.99s\tremaining: 503ms\n",
      "856:\tlearn: 265991.6983328\ttotal: 3s\tremaining: 500ms\n",
      "857:\tlearn: 265991.6712485\ttotal: 3s\tremaining: 496ms\n",
      "858:\tlearn: 265991.6227110\ttotal: 3s\tremaining: 492ms\n",
      "859:\tlearn: 265991.6004853\ttotal: 3s\tremaining: 489ms\n",
      "860:\tlearn: 265991.5551387\ttotal: 3s\tremaining: 485ms\n",
      "861:\tlearn: 265991.5089324\ttotal: 3.01s\tremaining: 481ms\n",
      "862:\tlearn: 265991.4817429\ttotal: 3.01s\tremaining: 478ms\n",
      "863:\tlearn: 265991.4508953\ttotal: 3.01s\tremaining: 474ms\n",
      "864:\tlearn: 265991.3906469\ttotal: 3.01s\tremaining: 470ms\n",
      "865:\tlearn: 265991.3657315\ttotal: 3.02s\tremaining: 467ms\n",
      "866:\tlearn: 265991.3347195\ttotal: 3.02s\tremaining: 464ms\n",
      "867:\tlearn: 265991.2944744\ttotal: 3.02s\tremaining: 460ms\n",
      "868:\tlearn: 265991.2561541\ttotal: 3.03s\tremaining: 456ms\n",
      "869:\tlearn: 265991.2221726\ttotal: 3.03s\tremaining: 453ms\n",
      "870:\tlearn: 265991.1796886\ttotal: 3.03s\tremaining: 449ms\n",
      "871:\tlearn: 265991.1490808\ttotal: 3.04s\tremaining: 446ms\n",
      "872:\tlearn: 265991.1352987\ttotal: 3.04s\tremaining: 442ms\n",
      "873:\tlearn: 265991.1037567\ttotal: 3.04s\tremaining: 438ms\n",
      "874:\tlearn: 265991.0724396\ttotal: 3.04s\tremaining: 435ms\n",
      "875:\tlearn: 265991.0132774\ttotal: 3.04s\tremaining: 431ms\n",
      "876:\tlearn: 265990.9655321\ttotal: 3.05s\tremaining: 427ms\n",
      "877:\tlearn: 265990.9069525\ttotal: 3.05s\tremaining: 424ms\n",
      "878:\tlearn: 265990.8838689\ttotal: 3.05s\tremaining: 420ms\n",
      "879:\tlearn: 265990.8409873\ttotal: 3.06s\tremaining: 417ms\n",
      "880:\tlearn: 265990.8280992\ttotal: 3.06s\tremaining: 413ms\n",
      "881:\tlearn: 265990.8086624\ttotal: 3.06s\tremaining: 409ms\n",
      "882:\tlearn: 265990.7727591\ttotal: 3.06s\tremaining: 406ms\n",
      "883:\tlearn: 265990.7448012\ttotal: 3.06s\tremaining: 402ms\n",
      "884:\tlearn: 265990.7347517\ttotal: 3.07s\tremaining: 399ms\n",
      "885:\tlearn: 265990.7052225\ttotal: 3.07s\tremaining: 395ms\n",
      "886:\tlearn: 265990.6755413\ttotal: 3.07s\tremaining: 391ms\n",
      "887:\tlearn: 265990.6640043\ttotal: 3.07s\tremaining: 388ms\n",
      "888:\tlearn: 265990.6179020\ttotal: 3.08s\tremaining: 384ms\n",
      "889:\tlearn: 265990.5891008\ttotal: 3.08s\tremaining: 381ms\n",
      "890:\tlearn: 265990.5401199\ttotal: 3.08s\tremaining: 377ms\n",
      "891:\tlearn: 265990.4903119\ttotal: 3.08s\tremaining: 373ms\n",
      "892:\tlearn: 265990.4537394\ttotal: 3.09s\tremaining: 370ms\n",
      "893:\tlearn: 265990.4268545\ttotal: 3.09s\tremaining: 366ms\n",
      "894:\tlearn: 265990.3891876\ttotal: 3.09s\tremaining: 363ms\n",
      "895:\tlearn: 265990.3549826\ttotal: 3.09s\tremaining: 359ms\n",
      "896:\tlearn: 265990.2913765\ttotal: 3.1s\tremaining: 356ms\n",
      "897:\tlearn: 265990.2538542\ttotal: 3.1s\tremaining: 352ms\n",
      "898:\tlearn: 265990.2243033\ttotal: 3.1s\tremaining: 349ms\n",
      "899:\tlearn: 265990.1711342\ttotal: 3.1s\tremaining: 345ms\n",
      "900:\tlearn: 265990.1296708\ttotal: 3.11s\tremaining: 341ms\n",
      "901:\tlearn: 265990.0979985\ttotal: 3.11s\tremaining: 338ms\n",
      "902:\tlearn: 265990.0538082\ttotal: 3.12s\tremaining: 335ms\n",
      "903:\tlearn: 265990.0192277\ttotal: 3.12s\tremaining: 331ms\n",
      "904:\tlearn: 265989.9769427\ttotal: 3.12s\tremaining: 327ms\n",
      "905:\tlearn: 265989.9698893\ttotal: 3.12s\tremaining: 324ms\n",
      "906:\tlearn: 265989.9242329\ttotal: 3.12s\tremaining: 320ms\n",
      "907:\tlearn: 265989.8923945\ttotal: 3.13s\tremaining: 317ms\n",
      "908:\tlearn: 265989.8820033\ttotal: 3.13s\tremaining: 314ms\n",
      "909:\tlearn: 265989.8755261\ttotal: 3.13s\tremaining: 310ms\n",
      "910:\tlearn: 265989.8301537\ttotal: 3.14s\tremaining: 306ms\n",
      "911:\tlearn: 265989.8077041\ttotal: 3.14s\tremaining: 303ms\n",
      "912:\tlearn: 265989.7730815\ttotal: 3.14s\tremaining: 300ms\n",
      "913:\tlearn: 265989.7579998\ttotal: 3.15s\tremaining: 296ms\n",
      "914:\tlearn: 265989.7152294\ttotal: 3.15s\tremaining: 293ms\n",
      "915:\tlearn: 265989.7091625\ttotal: 3.15s\tremaining: 289ms\n",
      "916:\tlearn: 265989.6704497\ttotal: 3.16s\tremaining: 286ms\n",
      "917:\tlearn: 265989.6596300\ttotal: 3.16s\tremaining: 282ms\n",
      "918:\tlearn: 265989.6389188\ttotal: 3.16s\tremaining: 279ms\n",
      "919:\tlearn: 265989.6333200\ttotal: 3.17s\tremaining: 275ms\n",
      "920:\tlearn: 265989.5963776\ttotal: 3.17s\tremaining: 272ms\n",
      "921:\tlearn: 265989.5629481\ttotal: 3.17s\tremaining: 268ms\n",
      "922:\tlearn: 265989.5320312\ttotal: 3.18s\tremaining: 265ms\n",
      "923:\tlearn: 265989.5133019\ttotal: 3.22s\tremaining: 265ms\n",
      "924:\tlearn: 265989.4790248\ttotal: 3.23s\tremaining: 262ms\n",
      "925:\tlearn: 265989.4394944\ttotal: 3.24s\tremaining: 259ms\n",
      "926:\tlearn: 265989.4070363\ttotal: 3.25s\tremaining: 256ms\n",
      "927:\tlearn: 265989.3663815\ttotal: 3.25s\tremaining: 252ms\n",
      "928:\tlearn: 265989.3368218\ttotal: 3.25s\tremaining: 249ms\n",
      "929:\tlearn: 265989.2997739\ttotal: 3.25s\tremaining: 245ms\n",
      "930:\tlearn: 265989.2694108\ttotal: 3.26s\tremaining: 241ms\n",
      "931:\tlearn: 265989.2444849\ttotal: 3.26s\tremaining: 238ms\n",
      "932:\tlearn: 265989.2193422\ttotal: 3.27s\tremaining: 235ms\n",
      "933:\tlearn: 265989.1748547\ttotal: 3.27s\tremaining: 231ms\n",
      "934:\tlearn: 265989.1396659\ttotal: 3.28s\tremaining: 228ms\n",
      "935:\tlearn: 265989.1318765\ttotal: 3.28s\tremaining: 224ms\n",
      "936:\tlearn: 265989.1245355\ttotal: 3.28s\tremaining: 221ms\n",
      "937:\tlearn: 265989.0969970\ttotal: 3.29s\tremaining: 217ms\n",
      "938:\tlearn: 265989.0540635\ttotal: 3.29s\tremaining: 214ms\n",
      "939:\tlearn: 265989.0284912\ttotal: 3.29s\tremaining: 210ms\n",
      "940:\tlearn: 265989.0171182\ttotal: 3.3s\tremaining: 207ms\n",
      "941:\tlearn: 265988.9762526\ttotal: 3.3s\tremaining: 203ms\n",
      "942:\tlearn: 265988.9591637\ttotal: 3.3s\tremaining: 200ms\n",
      "943:\tlearn: 265988.9549905\ttotal: 3.3s\tremaining: 196ms\n",
      "944:\tlearn: 265988.9221357\ttotal: 3.31s\tremaining: 193ms\n",
      "945:\tlearn: 265988.8877075\ttotal: 3.31s\tremaining: 189ms\n",
      "946:\tlearn: 265988.8565168\ttotal: 3.31s\tremaining: 185ms\n",
      "947:\tlearn: 265988.8183714\ttotal: 3.31s\tremaining: 182ms\n",
      "948:\tlearn: 265988.8031890\ttotal: 3.32s\tremaining: 178ms\n",
      "949:\tlearn: 265988.8000622\ttotal: 3.32s\tremaining: 175ms\n",
      "950:\tlearn: 265988.7561514\ttotal: 3.32s\tremaining: 171ms\n",
      "951:\tlearn: 265988.7180145\ttotal: 3.33s\tremaining: 168ms\n",
      "952:\tlearn: 265988.6947717\ttotal: 3.33s\tremaining: 164ms\n",
      "953:\tlearn: 265988.6694083\ttotal: 3.33s\tremaining: 161ms\n",
      "954:\tlearn: 265988.6664890\ttotal: 3.34s\tremaining: 157ms\n",
      "955:\tlearn: 265988.6460209\ttotal: 3.34s\tremaining: 154ms\n",
      "956:\tlearn: 265988.6395303\ttotal: 3.34s\tremaining: 150ms\n",
      "957:\tlearn: 265988.6249016\ttotal: 3.35s\tremaining: 147ms\n",
      "958:\tlearn: 265988.5905114\ttotal: 3.35s\tremaining: 143ms\n",
      "959:\tlearn: 265988.5660402\ttotal: 3.35s\tremaining: 140ms\n",
      "960:\tlearn: 265988.5423575\ttotal: 3.36s\tremaining: 136ms\n",
      "961:\tlearn: 265988.5200348\ttotal: 3.36s\tremaining: 133ms\n",
      "962:\tlearn: 265988.5177225\ttotal: 3.36s\tremaining: 129ms\n",
      "963:\tlearn: 265988.5155403\ttotal: 3.37s\tremaining: 126ms\n",
      "964:\tlearn: 265988.5022263\ttotal: 3.37s\tremaining: 122ms\n",
      "965:\tlearn: 265988.4730338\ttotal: 3.37s\tremaining: 119ms\n",
      "966:\tlearn: 265988.4415657\ttotal: 3.37s\tremaining: 115ms\n",
      "967:\tlearn: 265988.4093268\ttotal: 3.38s\tremaining: 112ms\n",
      "968:\tlearn: 265988.3707291\ttotal: 3.38s\tremaining: 108ms\n",
      "969:\tlearn: 265988.3686702\ttotal: 3.38s\tremaining: 105ms\n",
      "970:\tlearn: 265988.3372387\ttotal: 3.39s\tremaining: 101ms\n",
      "971:\tlearn: 265988.3347679\ttotal: 3.39s\tremaining: 97.7ms\n",
      "972:\tlearn: 265988.3062431\ttotal: 3.39s\tremaining: 94.1ms\n",
      "973:\tlearn: 265988.2848791\ttotal: 3.4s\tremaining: 90.6ms\n",
      "974:\tlearn: 265988.2749414\ttotal: 3.4s\tremaining: 87.1ms\n",
      "975:\tlearn: 265988.2415097\ttotal: 3.4s\tremaining: 83.6ms\n",
      "976:\tlearn: 265988.2155048\ttotal: 3.4s\tremaining: 80.1ms\n",
      "977:\tlearn: 265988.2049252\ttotal: 3.4s\tremaining: 76.6ms\n",
      "978:\tlearn: 265988.1825265\ttotal: 3.41s\tremaining: 73.1ms\n",
      "979:\tlearn: 265988.1712927\ttotal: 3.41s\tremaining: 69.6ms\n",
      "980:\tlearn: 265988.1563392\ttotal: 3.41s\tremaining: 66.1ms\n",
      "981:\tlearn: 265988.1458609\ttotal: 3.42s\tremaining: 62.6ms\n",
      "982:\tlearn: 265988.1261762\ttotal: 3.42s\tremaining: 59.1ms\n",
      "983:\tlearn: 265988.1146069\ttotal: 3.42s\tremaining: 55.6ms\n",
      "984:\tlearn: 265988.0863744\ttotal: 3.42s\tremaining: 52.1ms\n",
      "985:\tlearn: 265988.0782909\ttotal: 3.43s\tremaining: 48.6ms\n",
      "986:\tlearn: 265988.0541528\ttotal: 3.43s\tremaining: 45.2ms\n",
      "987:\tlearn: 265988.0340649\ttotal: 3.43s\tremaining: 41.7ms\n",
      "988:\tlearn: 265988.0138079\ttotal: 3.43s\tremaining: 38.2ms\n",
      "989:\tlearn: 265987.9854088\ttotal: 3.44s\tremaining: 34.7ms\n",
      "990:\tlearn: 265987.9784710\ttotal: 3.44s\tremaining: 31.2ms\n",
      "991:\tlearn: 265987.9664544\ttotal: 3.44s\tremaining: 27.8ms\n",
      "992:\tlearn: 265987.9362707\ttotal: 3.44s\tremaining: 24.3ms\n",
      "993:\tlearn: 265987.9309752\ttotal: 3.45s\tremaining: 20.8ms\n",
      "994:\tlearn: 265987.9097441\ttotal: 3.45s\tremaining: 17.3ms\n",
      "995:\tlearn: 265987.9032437\ttotal: 3.45s\tremaining: 13.9ms\n",
      "996:\tlearn: 265987.8889843\ttotal: 3.46s\tremaining: 10.4ms\n",
      "997:\tlearn: 265987.8679003\ttotal: 3.46s\tremaining: 6.93ms\n",
      "998:\tlearn: 265987.8506172\ttotal: 3.46s\tremaining: 3.47ms\n",
      "999:\tlearn: 265987.8237861\ttotal: 3.46s\tremaining: 0us\n",
      "Prediction for 2026 using CatBoost completed and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor  # Import CatBoostRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=1000, learning_rate=0.1)  # You can adjust hyperparameters as needed\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2026\n",
    "prediction_2026 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2026[prediction_2026 < 0] = 0\n",
    "\n",
    "# Add the predicted '2026' column to the DataFrame\n",
    "df['2026'] = prediction_2026\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv', index=False)\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(\"Prediction for 2026 using CatBoost completed and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 977531.1305819\ttotal: 4.17ms\tremaining: 4.17s\n",
      "1:\tlearn: 920267.3987735\ttotal: 7.76ms\tremaining: 3.87s\n",
      "2:\tlearn: 867948.4028658\ttotal: 10.8ms\tremaining: 3.6s\n",
      "3:\tlearn: 818624.0551227\ttotal: 13.7ms\tremaining: 3.42s\n",
      "4:\tlearn: 774786.2393482\ttotal: 16.9ms\tremaining: 3.36s\n",
      "5:\tlearn: 737186.6224079\ttotal: 20.3ms\tremaining: 3.36s\n",
      "6:\tlearn: 698832.2749958\ttotal: 25.2ms\tremaining: 3.58s\n",
      "7:\tlearn: 666252.2536125\ttotal: 30.4ms\tremaining: 3.77s\n",
      "8:\tlearn: 634692.2886584\ttotal: 33.5ms\tremaining: 3.69s\n",
      "9:\tlearn: 607508.0144389\ttotal: 36.6ms\tremaining: 3.63s\n",
      "10:\tlearn: 579606.2060850\ttotal: 42.6ms\tremaining: 3.83s\n",
      "11:\tlearn: 555323.5598402\ttotal: 45.3ms\tremaining: 3.73s\n",
      "12:\tlearn: 533972.4379649\ttotal: 48ms\tremaining: 3.65s\n",
      "13:\tlearn: 512974.2529368\ttotal: 51.3ms\tremaining: 3.62s\n",
      "14:\tlearn: 493156.0961861\ttotal: 56.9ms\tremaining: 3.74s\n",
      "15:\tlearn: 472907.5080645\ttotal: 125ms\tremaining: 7.69s\n",
      "16:\tlearn: 457927.3489051\ttotal: 128ms\tremaining: 7.41s\n",
      "17:\tlearn: 443025.2020606\ttotal: 131ms\tremaining: 7.15s\n",
      "18:\tlearn: 428740.1375070\ttotal: 134ms\tremaining: 6.9s\n",
      "19:\tlearn: 416333.2510592\ttotal: 144ms\tremaining: 7.04s\n",
      "20:\tlearn: 404273.8368255\ttotal: 151ms\tremaining: 7.02s\n",
      "21:\tlearn: 392791.5790374\ttotal: 155ms\tremaining: 6.88s\n",
      "22:\tlearn: 381134.9204050\ttotal: 161ms\tremaining: 6.85s\n",
      "23:\tlearn: 372149.2843808\ttotal: 164ms\tremaining: 6.69s\n",
      "24:\tlearn: 363750.5520156\ttotal: 169ms\tremaining: 6.6s\n",
      "25:\tlearn: 355373.0803262\ttotal: 172ms\tremaining: 6.45s\n",
      "26:\tlearn: 348325.0759660\ttotal: 176ms\tremaining: 6.34s\n",
      "27:\tlearn: 341814.2730668\ttotal: 179ms\tremaining: 6.2s\n",
      "28:\tlearn: 335895.5358750\ttotal: 181ms\tremaining: 6.07s\n",
      "29:\tlearn: 330663.6822018\ttotal: 185ms\tremaining: 5.99s\n",
      "30:\tlearn: 325789.2642374\ttotal: 188ms\tremaining: 5.87s\n",
      "31:\tlearn: 321124.2111265\ttotal: 190ms\tremaining: 5.75s\n",
      "32:\tlearn: 316504.0389204\ttotal: 193ms\tremaining: 5.64s\n",
      "33:\tlearn: 312150.9543076\ttotal: 195ms\tremaining: 5.55s\n",
      "34:\tlearn: 308662.7942527\ttotal: 198ms\tremaining: 5.46s\n",
      "35:\tlearn: 305288.9484032\ttotal: 203ms\tremaining: 5.43s\n",
      "36:\tlearn: 302385.8465054\ttotal: 207ms\tremaining: 5.38s\n",
      "37:\tlearn: 299533.2878272\ttotal: 211ms\tremaining: 5.35s\n",
      "38:\tlearn: 296593.3843526\ttotal: 215ms\tremaining: 5.29s\n",
      "39:\tlearn: 294486.0464134\ttotal: 218ms\tremaining: 5.23s\n",
      "40:\tlearn: 292610.2810925\ttotal: 221ms\tremaining: 5.17s\n",
      "41:\tlearn: 290795.0186206\ttotal: 224ms\tremaining: 5.11s\n",
      "42:\tlearn: 288836.6641387\ttotal: 227ms\tremaining: 5.06s\n",
      "43:\tlearn: 287545.3454512\ttotal: 232ms\tremaining: 5.04s\n",
      "44:\tlearn: 285805.7241583\ttotal: 235ms\tremaining: 4.98s\n",
      "45:\tlearn: 284565.5771568\ttotal: 239ms\tremaining: 4.96s\n",
      "46:\tlearn: 283306.3291994\ttotal: 243ms\tremaining: 4.92s\n",
      "47:\tlearn: 282264.3938618\ttotal: 247ms\tremaining: 4.91s\n",
      "48:\tlearn: 281518.8912079\ttotal: 251ms\tremaining: 4.88s\n",
      "49:\tlearn: 280465.1444060\ttotal: 255ms\tremaining: 4.85s\n",
      "50:\tlearn: 279560.8103611\ttotal: 258ms\tremaining: 4.8s\n",
      "51:\tlearn: 278819.0116831\ttotal: 262ms\tremaining: 4.77s\n",
      "52:\tlearn: 278058.2200315\ttotal: 265ms\tremaining: 4.74s\n",
      "53:\tlearn: 277386.2530630\ttotal: 270ms\tremaining: 4.74s\n",
      "54:\tlearn: 276891.1936697\ttotal: 273ms\tremaining: 4.7s\n",
      "55:\tlearn: 276335.8111717\ttotal: 279ms\tremaining: 4.7s\n",
      "56:\tlearn: 275791.0392350\ttotal: 282ms\tremaining: 4.67s\n",
      "57:\tlearn: 275317.5600087\ttotal: 285ms\tremaining: 4.63s\n",
      "58:\tlearn: 274830.4732171\ttotal: 288ms\tremaining: 4.6s\n",
      "59:\tlearn: 274410.7305156\ttotal: 294ms\tremaining: 4.61s\n",
      "60:\tlearn: 274009.9191542\ttotal: 298ms\tremaining: 4.58s\n",
      "61:\tlearn: 273659.9109576\ttotal: 300ms\tremaining: 4.54s\n",
      "62:\tlearn: 273418.4054351\ttotal: 302ms\tremaining: 4.5s\n",
      "63:\tlearn: 273118.8568948\ttotal: 305ms\tremaining: 4.46s\n",
      "64:\tlearn: 272872.2194934\ttotal: 309ms\tremaining: 4.45s\n",
      "65:\tlearn: 272543.3446440\ttotal: 312ms\tremaining: 4.41s\n",
      "66:\tlearn: 272338.0797976\ttotal: 314ms\tremaining: 4.37s\n",
      "67:\tlearn: 272098.5778132\ttotal: 316ms\tremaining: 4.34s\n",
      "68:\tlearn: 271953.3049560\ttotal: 319ms\tremaining: 4.3s\n",
      "69:\tlearn: 271732.3056177\ttotal: 321ms\tremaining: 4.26s\n",
      "70:\tlearn: 271586.4874478\ttotal: 324ms\tremaining: 4.24s\n",
      "71:\tlearn: 271431.4980088\ttotal: 327ms\tremaining: 4.21s\n",
      "72:\tlearn: 271292.4728775\ttotal: 329ms\tremaining: 4.18s\n",
      "73:\tlearn: 271151.3415828\ttotal: 331ms\tremaining: 4.15s\n",
      "74:\tlearn: 270951.2168027\ttotal: 334ms\tremaining: 4.11s\n",
      "75:\tlearn: 270853.2788769\ttotal: 336ms\tremaining: 4.08s\n",
      "76:\tlearn: 270732.7551201\ttotal: 340ms\tremaining: 4.08s\n",
      "77:\tlearn: 270614.8267782\ttotal: 343ms\tremaining: 4.06s\n",
      "78:\tlearn: 270544.4101508\ttotal: 346ms\tremaining: 4.03s\n",
      "79:\tlearn: 270376.4323223\ttotal: 348ms\tremaining: 4s\n",
      "80:\tlearn: 270245.6645701\ttotal: 350ms\tremaining: 3.97s\n",
      "81:\tlearn: 270124.4130608\ttotal: 352ms\tremaining: 3.94s\n",
      "82:\tlearn: 270020.6388678\ttotal: 356ms\tremaining: 3.94s\n",
      "83:\tlearn: 269941.1097896\ttotal: 359ms\tremaining: 3.91s\n",
      "84:\tlearn: 269782.9870015\ttotal: 361ms\tremaining: 3.88s\n",
      "85:\tlearn: 269729.5418707\ttotal: 363ms\tremaining: 3.86s\n",
      "86:\tlearn: 269623.5350783\ttotal: 365ms\tremaining: 3.83s\n",
      "87:\tlearn: 269534.4967524\ttotal: 367ms\tremaining: 3.81s\n",
      "88:\tlearn: 269405.0521157\ttotal: 371ms\tremaining: 3.8s\n",
      "89:\tlearn: 269283.2355092\ttotal: 374ms\tremaining: 3.78s\n",
      "90:\tlearn: 269179.1330645\ttotal: 376ms\tremaining: 3.75s\n",
      "91:\tlearn: 269083.5443767\ttotal: 378ms\tremaining: 3.73s\n",
      "92:\tlearn: 268979.5227547\ttotal: 380ms\tremaining: 3.71s\n",
      "93:\tlearn: 268918.2936265\ttotal: 382ms\tremaining: 3.69s\n",
      "94:\tlearn: 268829.6232303\ttotal: 386ms\tremaining: 3.68s\n",
      "95:\tlearn: 268753.2558394\ttotal: 389ms\tremaining: 3.66s\n",
      "96:\tlearn: 268657.1662511\ttotal: 391ms\tremaining: 3.64s\n",
      "97:\tlearn: 268601.6790974\ttotal: 393ms\tremaining: 3.62s\n",
      "98:\tlearn: 268541.5560238\ttotal: 396ms\tremaining: 3.6s\n",
      "99:\tlearn: 268488.3490220\ttotal: 398ms\tremaining: 3.58s\n",
      "100:\tlearn: 268433.7707964\ttotal: 400ms\tremaining: 3.56s\n",
      "101:\tlearn: 268374.1791986\ttotal: 404ms\tremaining: 3.56s\n",
      "102:\tlearn: 268304.4810753\ttotal: 406ms\tremaining: 3.54s\n",
      "103:\tlearn: 268241.1650055\ttotal: 409ms\tremaining: 3.52s\n",
      "104:\tlearn: 268185.4835807\ttotal: 411ms\tremaining: 3.5s\n",
      "105:\tlearn: 268131.8161702\ttotal: 414ms\tremaining: 3.49s\n",
      "106:\tlearn: 268069.6517503\ttotal: 419ms\tremaining: 3.5s\n",
      "107:\tlearn: 268026.7418214\ttotal: 422ms\tremaining: 3.48s\n",
      "108:\tlearn: 267963.1972372\ttotal: 424ms\tremaining: 3.47s\n",
      "109:\tlearn: 267899.6941996\ttotal: 427ms\tremaining: 3.46s\n",
      "110:\tlearn: 267856.6801914\ttotal: 430ms\tremaining: 3.44s\n",
      "111:\tlearn: 267812.6347615\ttotal: 435ms\tremaining: 3.45s\n",
      "112:\tlearn: 267776.0821834\ttotal: 438ms\tremaining: 3.44s\n",
      "113:\tlearn: 267724.5254792\ttotal: 441ms\tremaining: 3.43s\n",
      "114:\tlearn: 267659.2888028\ttotal: 444ms\tremaining: 3.41s\n",
      "115:\tlearn: 267616.3425323\ttotal: 446ms\tremaining: 3.4s\n",
      "116:\tlearn: 267573.0300765\ttotal: 451ms\tremaining: 3.4s\n",
      "117:\tlearn: 267536.8993648\ttotal: 454ms\tremaining: 3.39s\n",
      "118:\tlearn: 267504.0704764\ttotal: 456ms\tremaining: 3.38s\n",
      "119:\tlearn: 267463.8839889\ttotal: 459ms\tremaining: 3.37s\n",
      "120:\tlearn: 267434.8090755\ttotal: 462ms\tremaining: 3.35s\n",
      "121:\tlearn: 267400.5736111\ttotal: 466ms\tremaining: 3.35s\n",
      "122:\tlearn: 267366.0978733\ttotal: 469ms\tremaining: 3.35s\n",
      "123:\tlearn: 267345.3001207\ttotal: 472ms\tremaining: 3.33s\n",
      "124:\tlearn: 267318.4610174\ttotal: 474ms\tremaining: 3.32s\n",
      "125:\tlearn: 267288.4655105\ttotal: 477ms\tremaining: 3.31s\n",
      "126:\tlearn: 267272.9056356\ttotal: 487ms\tremaining: 3.35s\n",
      "127:\tlearn: 267258.2048484\ttotal: 490ms\tremaining: 3.34s\n",
      "128:\tlearn: 267231.7778845\ttotal: 495ms\tremaining: 3.34s\n",
      "129:\tlearn: 267202.4791154\ttotal: 499ms\tremaining: 3.34s\n",
      "130:\tlearn: 267176.7075558\ttotal: 502ms\tremaining: 3.33s\n",
      "131:\tlearn: 267154.1100650\ttotal: 504ms\tremaining: 3.31s\n",
      "132:\tlearn: 267120.6439162\ttotal: 506ms\tremaining: 3.3s\n",
      "133:\tlearn: 267098.6612757\ttotal: 509ms\tremaining: 3.29s\n",
      "134:\tlearn: 267078.0427110\ttotal: 513ms\tremaining: 3.29s\n",
      "135:\tlearn: 267065.6928336\ttotal: 515ms\tremaining: 3.27s\n",
      "136:\tlearn: 267049.2784778\ttotal: 518ms\tremaining: 3.26s\n",
      "137:\tlearn: 267037.7410292\ttotal: 520ms\tremaining: 3.25s\n",
      "138:\tlearn: 267020.6064518\ttotal: 522ms\tremaining: 3.23s\n",
      "139:\tlearn: 266995.8737393\ttotal: 525ms\tremaining: 3.22s\n",
      "140:\tlearn: 266978.7813562\ttotal: 530ms\tremaining: 3.23s\n",
      "141:\tlearn: 266962.8463836\ttotal: 533ms\tremaining: 3.22s\n",
      "142:\tlearn: 266935.1715578\ttotal: 535ms\tremaining: 3.21s\n",
      "143:\tlearn: 266913.8823002\ttotal: 537ms\tremaining: 3.19s\n",
      "144:\tlearn: 266894.8559651\ttotal: 541ms\tremaining: 3.19s\n",
      "145:\tlearn: 266885.9211457\ttotal: 546ms\tremaining: 3.19s\n",
      "146:\tlearn: 266871.1452471\ttotal: 550ms\tremaining: 3.19s\n",
      "147:\tlearn: 266862.7841524\ttotal: 553ms\tremaining: 3.19s\n",
      "148:\tlearn: 266839.1751922\ttotal: 556ms\tremaining: 3.17s\n",
      "149:\tlearn: 266823.2757791\ttotal: 561ms\tremaining: 3.18s\n",
      "150:\tlearn: 266816.7367967\ttotal: 564ms\tremaining: 3.17s\n",
      "151:\tlearn: 266801.1362338\ttotal: 567ms\tremaining: 3.16s\n",
      "152:\tlearn: 266795.1300683\ttotal: 570ms\tremaining: 3.15s\n",
      "153:\tlearn: 266783.3878552\ttotal: 574ms\tremaining: 3.15s\n",
      "154:\tlearn: 266768.5161505\ttotal: 578ms\tremaining: 3.15s\n",
      "155:\tlearn: 266761.9541362\ttotal: 581ms\tremaining: 3.15s\n",
      "156:\tlearn: 266748.6860227\ttotal: 584ms\tremaining: 3.14s\n",
      "157:\tlearn: 266743.6623528\ttotal: 588ms\tremaining: 3.13s\n",
      "158:\tlearn: 266738.9137884\ttotal: 593ms\tremaining: 3.13s\n",
      "159:\tlearn: 266726.3734526\ttotal: 596ms\tremaining: 3.13s\n",
      "160:\tlearn: 266714.0561421\ttotal: 600ms\tremaining: 3.12s\n",
      "161:\tlearn: 266709.6214516\ttotal: 605ms\tremaining: 3.13s\n",
      "162:\tlearn: 266701.5201359\ttotal: 611ms\tremaining: 3.13s\n",
      "163:\tlearn: 266693.9326295\ttotal: 614ms\tremaining: 3.13s\n",
      "164:\tlearn: 266683.8438645\ttotal: 620ms\tremaining: 3.14s\n",
      "165:\tlearn: 266676.7275678\ttotal: 623ms\tremaining: 3.13s\n",
      "166:\tlearn: 266666.3504720\ttotal: 627ms\tremaining: 3.13s\n",
      "167:\tlearn: 266662.2032993\ttotal: 631ms\tremaining: 3.13s\n",
      "168:\tlearn: 266655.5438596\ttotal: 637ms\tremaining: 3.13s\n",
      "169:\tlearn: 266649.2968741\ttotal: 643ms\tremaining: 3.14s\n",
      "170:\tlearn: 266638.8549173\ttotal: 647ms\tremaining: 3.13s\n",
      "171:\tlearn: 266631.2190972\ttotal: 652ms\tremaining: 3.14s\n",
      "172:\tlearn: 266622.0355694\ttotal: 656ms\tremaining: 3.13s\n",
      "173:\tlearn: 266614.8432789\ttotal: 666ms\tremaining: 3.16s\n",
      "174:\tlearn: 266608.4206924\ttotal: 672ms\tremaining: 3.17s\n",
      "175:\tlearn: 266599.9882163\ttotal: 678ms\tremaining: 3.17s\n",
      "176:\tlearn: 266589.3276149\ttotal: 684ms\tremaining: 3.18s\n",
      "177:\tlearn: 266586.0696780\ttotal: 688ms\tremaining: 3.18s\n",
      "178:\tlearn: 266576.2484655\ttotal: 696ms\tremaining: 3.19s\n",
      "179:\tlearn: 266568.3087230\ttotal: 701ms\tremaining: 3.19s\n",
      "180:\tlearn: 266565.1229175\ttotal: 705ms\tremaining: 3.19s\n",
      "181:\tlearn: 266557.7923729\ttotal: 710ms\tremaining: 3.19s\n",
      "182:\tlearn: 266555.0368689\ttotal: 716ms\tremaining: 3.2s\n",
      "183:\tlearn: 266548.2568078\ttotal: 719ms\tremaining: 3.19s\n",
      "184:\tlearn: 266545.5919199\ttotal: 723ms\tremaining: 3.19s\n",
      "185:\tlearn: 266533.1798168\ttotal: 729ms\tremaining: 3.19s\n",
      "186:\tlearn: 266526.9457421\ttotal: 736ms\tremaining: 3.2s\n",
      "187:\tlearn: 266521.1051020\ttotal: 738ms\tremaining: 3.19s\n",
      "188:\tlearn: 266518.7641849\ttotal: 743ms\tremaining: 3.19s\n",
      "189:\tlearn: 266516.6472307\ttotal: 750ms\tremaining: 3.2s\n",
      "190:\tlearn: 266508.1027863\ttotal: 754ms\tremaining: 3.19s\n",
      "191:\tlearn: 266499.0411255\ttotal: 760ms\tremaining: 3.2s\n",
      "192:\tlearn: 266494.0565312\ttotal: 767ms\tremaining: 3.21s\n",
      "193:\tlearn: 266492.0243192\ttotal: 771ms\tremaining: 3.21s\n",
      "194:\tlearn: 266480.4158048\ttotal: 778ms\tremaining: 3.21s\n",
      "195:\tlearn: 266475.2475613\ttotal: 780ms\tremaining: 3.2s\n",
      "196:\tlearn: 266470.4054465\ttotal: 783ms\tremaining: 3.19s\n",
      "197:\tlearn: 266468.5898639\ttotal: 786ms\tremaining: 3.18s\n",
      "198:\tlearn: 266464.0955231\ttotal: 788ms\tremaining: 3.17s\n",
      "199:\tlearn: 266462.4313132\ttotal: 794ms\tremaining: 3.17s\n",
      "200:\tlearn: 266458.2555576\ttotal: 796ms\tremaining: 3.17s\n",
      "201:\tlearn: 266454.9636407\ttotal: 799ms\tremaining: 3.15s\n",
      "202:\tlearn: 266448.6526247\ttotal: 801ms\tremaining: 3.14s\n",
      "203:\tlearn: 266442.1472378\ttotal: 804ms\tremaining: 3.14s\n",
      "204:\tlearn: 266433.2537865\ttotal: 808ms\tremaining: 3.13s\n",
      "205:\tlearn: 266425.1947826\ttotal: 811ms\tremaining: 3.13s\n",
      "206:\tlearn: 266423.8386723\ttotal: 814ms\tremaining: 3.12s\n",
      "207:\tlearn: 266418.0427115\ttotal: 817ms\tremaining: 3.11s\n",
      "208:\tlearn: 266411.2673407\ttotal: 819ms\tremaining: 3.1s\n",
      "209:\tlearn: 266405.8812952\ttotal: 823ms\tremaining: 3.1s\n",
      "210:\tlearn: 266404.6013115\ttotal: 827ms\tremaining: 3.09s\n",
      "211:\tlearn: 266399.0924795\ttotal: 830ms\tremaining: 3.08s\n",
      "212:\tlearn: 266392.9745199\ttotal: 832ms\tremaining: 3.07s\n",
      "213:\tlearn: 266386.8901524\ttotal: 838ms\tremaining: 3.08s\n",
      "214:\tlearn: 266376.7038288\ttotal: 841ms\tremaining: 3.07s\n",
      "215:\tlearn: 266372.0171677\ttotal: 845ms\tremaining: 3.06s\n",
      "216:\tlearn: 266364.7221561\ttotal: 847ms\tremaining: 3.06s\n",
      "217:\tlearn: 266363.5267883\ttotal: 855ms\tremaining: 3.07s\n",
      "218:\tlearn: 266360.6615229\ttotal: 860ms\tremaining: 3.07s\n",
      "219:\tlearn: 266359.5646835\ttotal: 864ms\tremaining: 3.06s\n",
      "220:\tlearn: 266355.3377391\ttotal: 879ms\tremaining: 3.1s\n",
      "221:\tlearn: 266348.7366846\ttotal: 908ms\tremaining: 3.18s\n",
      "222:\tlearn: 266346.6330783\ttotal: 919ms\tremaining: 3.2s\n",
      "223:\tlearn: 266340.6599418\ttotal: 930ms\tremaining: 3.22s\n",
      "224:\tlearn: 266338.7105980\ttotal: 960ms\tremaining: 3.31s\n",
      "225:\tlearn: 266332.9948113\ttotal: 972ms\tremaining: 3.33s\n",
      "226:\tlearn: 266327.7016416\ttotal: 976ms\tremaining: 3.32s\n",
      "227:\tlearn: 266322.8853084\ttotal: 983ms\tremaining: 3.33s\n",
      "228:\tlearn: 266315.0639313\ttotal: 992ms\tremaining: 3.34s\n",
      "229:\tlearn: 266309.8192206\ttotal: 1s\tremaining: 3.36s\n",
      "230:\tlearn: 266306.4500596\ttotal: 1.01s\tremaining: 3.36s\n",
      "231:\tlearn: 266304.7679041\ttotal: 1.01s\tremaining: 3.35s\n",
      "232:\tlearn: 266301.0413652\ttotal: 1.02s\tremaining: 3.35s\n",
      "233:\tlearn: 266300.0695065\ttotal: 1.02s\tremaining: 3.34s\n",
      "234:\tlearn: 266295.0652674\ttotal: 1.02s\tremaining: 3.33s\n",
      "235:\tlearn: 266293.4874924\ttotal: 1.03s\tremaining: 3.33s\n",
      "236:\tlearn: 266289.8867708\ttotal: 1.03s\tremaining: 3.33s\n",
      "237:\tlearn: 266288.4038521\ttotal: 1.04s\tremaining: 3.32s\n",
      "238:\tlearn: 266284.7583153\ttotal: 1.04s\tremaining: 3.31s\n",
      "239:\tlearn: 266279.6460750\ttotal: 1.04s\tremaining: 3.31s\n",
      "240:\tlearn: 266277.2670140\ttotal: 1.05s\tremaining: 3.3s\n",
      "241:\tlearn: 266275.9321768\ttotal: 1.05s\tremaining: 3.3s\n",
      "242:\tlearn: 266271.1158732\ttotal: 1.05s\tremaining: 3.29s\n",
      "243:\tlearn: 266267.5268008\ttotal: 1.06s\tremaining: 3.29s\n",
      "244:\tlearn: 266266.2762116\ttotal: 1.06s\tremaining: 3.28s\n",
      "245:\tlearn: 266262.1669541\ttotal: 1.07s\tremaining: 3.27s\n",
      "246:\tlearn: 266259.1390912\ttotal: 1.07s\tremaining: 3.26s\n",
      "247:\tlearn: 266257.2790221\ttotal: 1.07s\tremaining: 3.26s\n",
      "248:\tlearn: 266253.8957638\ttotal: 1.08s\tremaining: 3.25s\n",
      "249:\tlearn: 266252.7704356\ttotal: 1.08s\tremaining: 3.25s\n",
      "250:\tlearn: 266248.8370686\ttotal: 1.08s\tremaining: 3.24s\n",
      "251:\tlearn: 266245.2569089\ttotal: 1.09s\tremaining: 3.23s\n",
      "252:\tlearn: 266244.1042200\ttotal: 1.09s\tremaining: 3.23s\n",
      "253:\tlearn: 266242.9947131\ttotal: 1.1s\tremaining: 3.22s\n",
      "254:\tlearn: 266239.7860842\ttotal: 1.1s\tremaining: 3.21s\n",
      "255:\tlearn: 266234.9368098\ttotal: 1.1s\tremaining: 3.2s\n",
      "256:\tlearn: 266232.1524142\ttotal: 1.1s\tremaining: 3.19s\n",
      "257:\tlearn: 266228.9613840\ttotal: 1.11s\tremaining: 3.19s\n",
      "258:\tlearn: 266228.2553610\ttotal: 1.11s\tremaining: 3.18s\n",
      "259:\tlearn: 266225.1661221\ttotal: 1.11s\tremaining: 3.17s\n",
      "260:\tlearn: 266222.8128612\ttotal: 1.12s\tremaining: 3.16s\n",
      "261:\tlearn: 266218.4952104\ttotal: 1.12s\tremaining: 3.16s\n",
      "262:\tlearn: 266215.1429803\ttotal: 1.12s\tremaining: 3.15s\n",
      "263:\tlearn: 266213.9276317\ttotal: 1.13s\tremaining: 3.14s\n",
      "264:\tlearn: 266213.0479787\ttotal: 1.13s\tremaining: 3.13s\n",
      "265:\tlearn: 266212.4076144\ttotal: 1.13s\tremaining: 3.12s\n",
      "266:\tlearn: 266209.7344413\ttotal: 1.13s\tremaining: 3.11s\n",
      "267:\tlearn: 266206.8744381\ttotal: 1.14s\tremaining: 3.11s\n",
      "268:\tlearn: 266206.0452190\ttotal: 1.14s\tremaining: 3.1s\n",
      "269:\tlearn: 266205.3112430\ttotal: 1.14s\tremaining: 3.09s\n",
      "270:\tlearn: 266201.7779244\ttotal: 1.15s\tremaining: 3.08s\n",
      "271:\tlearn: 266198.8655418\ttotal: 1.15s\tremaining: 3.07s\n",
      "272:\tlearn: 266196.3209263\ttotal: 1.15s\tremaining: 3.07s\n",
      "273:\tlearn: 266192.2852307\ttotal: 1.16s\tremaining: 3.06s\n",
      "274:\tlearn: 266191.6824355\ttotal: 1.16s\tremaining: 3.06s\n",
      "275:\tlearn: 266188.5453840\ttotal: 1.16s\tremaining: 3.05s\n",
      "276:\tlearn: 266186.6333581\ttotal: 1.16s\tremaining: 3.04s\n",
      "277:\tlearn: 266183.7337686\ttotal: 1.17s\tremaining: 3.04s\n",
      "278:\tlearn: 266181.5566329\ttotal: 1.17s\tremaining: 3.03s\n",
      "279:\tlearn: 266179.2949813\ttotal: 1.18s\tremaining: 3.02s\n",
      "280:\tlearn: 266178.3562846\ttotal: 1.18s\tremaining: 3.02s\n",
      "281:\tlearn: 266175.3439152\ttotal: 1.18s\tremaining: 3.01s\n",
      "282:\tlearn: 266172.0523970\ttotal: 1.19s\tremaining: 3.01s\n",
      "283:\tlearn: 266170.6799858\ttotal: 1.19s\tremaining: 3s\n",
      "284:\tlearn: 266169.5996122\ttotal: 1.19s\tremaining: 2.99s\n",
      "285:\tlearn: 266168.7648004\ttotal: 1.2s\tremaining: 2.98s\n",
      "286:\tlearn: 266168.0414961\ttotal: 1.2s\tremaining: 2.98s\n",
      "287:\tlearn: 266167.1047584\ttotal: 1.2s\tremaining: 2.98s\n",
      "288:\tlearn: 266164.4703898\ttotal: 1.21s\tremaining: 2.97s\n",
      "289:\tlearn: 266164.0197736\ttotal: 1.21s\tremaining: 2.96s\n",
      "290:\tlearn: 266162.1105440\ttotal: 1.21s\tremaining: 2.96s\n",
      "291:\tlearn: 266161.6838897\ttotal: 1.22s\tremaining: 2.96s\n",
      "292:\tlearn: 266159.6335054\ttotal: 1.22s\tremaining: 2.95s\n",
      "293:\tlearn: 266157.1325286\ttotal: 1.23s\tremaining: 2.94s\n",
      "294:\tlearn: 266156.7276987\ttotal: 1.23s\tremaining: 2.94s\n",
      "295:\tlearn: 266156.1234078\ttotal: 1.23s\tremaining: 2.94s\n",
      "296:\tlearn: 266154.3365115\ttotal: 1.24s\tremaining: 2.93s\n",
      "297:\tlearn: 266153.9573686\ttotal: 1.24s\tremaining: 2.92s\n",
      "298:\tlearn: 266151.7111270\ttotal: 1.25s\tremaining: 2.92s\n",
      "299:\tlearn: 266149.4319827\ttotal: 1.25s\tremaining: 2.92s\n",
      "300:\tlearn: 266146.7299463\ttotal: 1.25s\tremaining: 2.91s\n",
      "301:\tlearn: 266144.3171895\ttotal: 1.26s\tremaining: 2.9s\n",
      "302:\tlearn: 266143.9555151\ttotal: 1.26s\tremaining: 2.9s\n",
      "303:\tlearn: 266141.7086952\ttotal: 1.27s\tremaining: 2.9s\n",
      "304:\tlearn: 266140.1334325\ttotal: 1.27s\tremaining: 2.89s\n",
      "305:\tlearn: 266138.1760963\ttotal: 1.27s\tremaining: 2.88s\n",
      "306:\tlearn: 266137.8405013\ttotal: 1.28s\tremaining: 2.88s\n",
      "307:\tlearn: 266135.5942728\ttotal: 1.28s\tremaining: 2.87s\n",
      "308:\tlearn: 266133.2806208\ttotal: 1.28s\tremaining: 2.87s\n",
      "309:\tlearn: 266131.6841390\ttotal: 1.28s\tremaining: 2.86s\n",
      "310:\tlearn: 266130.9405138\ttotal: 1.29s\tremaining: 2.85s\n",
      "311:\tlearn: 266129.5524513\ttotal: 1.29s\tremaining: 2.84s\n",
      "312:\tlearn: 266127.6475623\ttotal: 1.29s\tremaining: 2.84s\n",
      "313:\tlearn: 266126.9670010\ttotal: 1.3s\tremaining: 2.83s\n",
      "314:\tlearn: 266126.6773512\ttotal: 1.3s\tremaining: 2.82s\n",
      "315:\tlearn: 266125.0590216\ttotal: 1.3s\tremaining: 2.82s\n",
      "316:\tlearn: 266123.2301959\ttotal: 1.3s\tremaining: 2.81s\n",
      "317:\tlearn: 266121.7238443\ttotal: 1.31s\tremaining: 2.81s\n",
      "318:\tlearn: 266120.1102680\ttotal: 1.31s\tremaining: 2.8s\n",
      "319:\tlearn: 266118.6431653\ttotal: 1.31s\tremaining: 2.79s\n",
      "320:\tlearn: 266118.0610617\ttotal: 1.32s\tremaining: 2.79s\n",
      "321:\tlearn: 266116.6493334\ttotal: 1.32s\tremaining: 2.78s\n",
      "322:\tlearn: 266114.6138297\ttotal: 1.33s\tremaining: 2.78s\n",
      "323:\tlearn: 266113.2804544\ttotal: 1.33s\tremaining: 2.77s\n",
      "324:\tlearn: 266111.5440343\ttotal: 1.33s\tremaining: 2.77s\n",
      "325:\tlearn: 266110.2085164\ttotal: 1.33s\tremaining: 2.76s\n",
      "326:\tlearn: 266109.0836729\ttotal: 1.34s\tremaining: 2.75s\n",
      "327:\tlearn: 266107.8952920\ttotal: 1.34s\tremaining: 2.75s\n",
      "328:\tlearn: 266106.7569828\ttotal: 1.34s\tremaining: 2.74s\n",
      "329:\tlearn: 266106.5000563\ttotal: 1.35s\tremaining: 2.74s\n",
      "330:\tlearn: 266105.0529287\ttotal: 1.35s\tremaining: 2.73s\n",
      "331:\tlearn: 266103.7045295\ttotal: 1.35s\tremaining: 2.73s\n",
      "332:\tlearn: 266102.8667644\ttotal: 1.36s\tremaining: 2.72s\n",
      "333:\tlearn: 266101.6280719\ttotal: 1.36s\tremaining: 2.72s\n",
      "334:\tlearn: 266100.4692387\ttotal: 1.36s\tremaining: 2.71s\n",
      "335:\tlearn: 266100.2262342\ttotal: 1.37s\tremaining: 2.7s\n",
      "336:\tlearn: 266099.4941649\ttotal: 1.37s\tremaining: 2.7s\n",
      "337:\tlearn: 266098.3328507\ttotal: 1.37s\tremaining: 2.69s\n",
      "338:\tlearn: 266097.3319710\ttotal: 1.38s\tremaining: 2.69s\n",
      "339:\tlearn: 266095.8935091\ttotal: 1.38s\tremaining: 2.68s\n",
      "340:\tlearn: 266094.6221179\ttotal: 1.38s\tremaining: 2.67s\n",
      "341:\tlearn: 266093.4901174\ttotal: 1.39s\tremaining: 2.67s\n",
      "342:\tlearn: 266091.7997985\ttotal: 1.39s\tremaining: 2.66s\n",
      "343:\tlearn: 266090.4943775\ttotal: 1.39s\tremaining: 2.66s\n",
      "344:\tlearn: 266089.9275187\ttotal: 1.4s\tremaining: 2.65s\n",
      "345:\tlearn: 266089.4706756\ttotal: 1.4s\tremaining: 2.65s\n",
      "346:\tlearn: 266088.5573485\ttotal: 1.41s\tremaining: 2.64s\n",
      "347:\tlearn: 266087.8087262\ttotal: 1.41s\tremaining: 2.64s\n",
      "348:\tlearn: 266086.7633606\ttotal: 1.41s\tremaining: 2.63s\n",
      "349:\tlearn: 266086.3600019\ttotal: 1.41s\tremaining: 2.63s\n",
      "350:\tlearn: 266086.0706102\ttotal: 1.42s\tremaining: 2.62s\n",
      "351:\tlearn: 266084.8896377\ttotal: 1.42s\tremaining: 2.62s\n",
      "352:\tlearn: 266083.5100136\ttotal: 1.43s\tremaining: 2.61s\n",
      "353:\tlearn: 266083.2345193\ttotal: 1.43s\tremaining: 2.61s\n",
      "354:\tlearn: 266082.3945913\ttotal: 1.43s\tremaining: 2.6s\n",
      "355:\tlearn: 266082.0302612\ttotal: 1.44s\tremaining: 2.6s\n",
      "356:\tlearn: 266081.4221104\ttotal: 1.44s\tremaining: 2.59s\n",
      "357:\tlearn: 266081.1699948\ttotal: 1.44s\tremaining: 2.59s\n",
      "358:\tlearn: 266080.9304697\ttotal: 1.45s\tremaining: 2.58s\n",
      "359:\tlearn: 266080.2333107\ttotal: 1.45s\tremaining: 2.58s\n",
      "360:\tlearn: 266079.9034211\ttotal: 1.45s\tremaining: 2.57s\n",
      "361:\tlearn: 266079.3498365\ttotal: 1.46s\tremaining: 2.57s\n",
      "362:\tlearn: 266079.1301185\ttotal: 1.46s\tremaining: 2.56s\n",
      "363:\tlearn: 266078.8271331\ttotal: 1.46s\tremaining: 2.55s\n",
      "364:\tlearn: 266078.1309533\ttotal: 1.47s\tremaining: 2.56s\n",
      "365:\tlearn: 266077.1060574\ttotal: 1.47s\tremaining: 2.55s\n",
      "366:\tlearn: 266076.1929624\ttotal: 1.47s\tremaining: 2.54s\n",
      "367:\tlearn: 266075.1178964\ttotal: 1.48s\tremaining: 2.54s\n",
      "368:\tlearn: 266074.0954004\ttotal: 1.48s\tremaining: 2.54s\n",
      "369:\tlearn: 266073.3494109\ttotal: 1.49s\tremaining: 2.53s\n",
      "370:\tlearn: 266072.6514983\ttotal: 1.49s\tremaining: 2.52s\n",
      "371:\tlearn: 266071.7360786\ttotal: 1.49s\tremaining: 2.52s\n",
      "372:\tlearn: 266071.1166035\ttotal: 1.49s\tremaining: 2.51s\n",
      "373:\tlearn: 266070.1389219\ttotal: 1.5s\tremaining: 2.5s\n",
      "374:\tlearn: 266069.8497728\ttotal: 1.5s\tremaining: 2.5s\n",
      "375:\tlearn: 266068.9840339\ttotal: 1.5s\tremaining: 2.49s\n",
      "376:\tlearn: 266067.8878023\ttotal: 1.5s\tremaining: 2.48s\n",
      "377:\tlearn: 266067.0726809\ttotal: 1.51s\tremaining: 2.48s\n",
      "378:\tlearn: 266066.8086295\ttotal: 1.51s\tremaining: 2.47s\n",
      "379:\tlearn: 266066.0184362\ttotal: 1.51s\tremaining: 2.47s\n",
      "380:\tlearn: 266064.9847256\ttotal: 1.51s\tremaining: 2.46s\n",
      "381:\tlearn: 266063.9792440\ttotal: 1.52s\tremaining: 2.45s\n",
      "382:\tlearn: 266063.1949807\ttotal: 1.52s\tremaining: 2.45s\n",
      "383:\tlearn: 266062.6594384\ttotal: 1.52s\tremaining: 2.44s\n",
      "384:\tlearn: 266062.0411993\ttotal: 1.52s\tremaining: 2.44s\n",
      "385:\tlearn: 266061.2162498\ttotal: 1.53s\tremaining: 2.43s\n",
      "386:\tlearn: 266060.2903952\ttotal: 1.53s\tremaining: 2.42s\n",
      "387:\tlearn: 266059.5010574\ttotal: 1.53s\tremaining: 2.42s\n",
      "388:\tlearn: 266058.8857785\ttotal: 1.54s\tremaining: 2.41s\n",
      "389:\tlearn: 266058.6597005\ttotal: 1.54s\tremaining: 2.41s\n",
      "390:\tlearn: 266058.1796736\ttotal: 1.54s\tremaining: 2.4s\n",
      "391:\tlearn: 266057.4523376\ttotal: 1.54s\tremaining: 2.4s\n",
      "392:\tlearn: 266057.2425443\ttotal: 1.55s\tremaining: 2.39s\n",
      "393:\tlearn: 266057.0852621\ttotal: 1.55s\tremaining: 2.38s\n",
      "394:\tlearn: 266056.9363394\ttotal: 1.55s\tremaining: 2.38s\n",
      "395:\tlearn: 266056.2793924\ttotal: 1.55s\tremaining: 2.37s\n",
      "396:\tlearn: 266056.1376890\ttotal: 1.56s\tremaining: 2.37s\n",
      "397:\tlearn: 266055.4912810\ttotal: 1.56s\tremaining: 2.36s\n",
      "398:\tlearn: 266055.2982618\ttotal: 1.56s\tremaining: 2.36s\n",
      "399:\tlearn: 266055.1619533\ttotal: 1.57s\tremaining: 2.35s\n",
      "400:\tlearn: 266054.5692399\ttotal: 1.57s\tremaining: 2.34s\n",
      "401:\tlearn: 266054.4030329\ttotal: 1.57s\tremaining: 2.34s\n",
      "402:\tlearn: 266054.2788288\ttotal: 1.58s\tremaining: 2.34s\n",
      "403:\tlearn: 266053.7932723\ttotal: 1.58s\tremaining: 2.33s\n",
      "404:\tlearn: 266052.9386608\ttotal: 1.58s\tremaining: 2.33s\n",
      "405:\tlearn: 266052.1246694\ttotal: 1.58s\tremaining: 2.32s\n",
      "406:\tlearn: 266051.7242841\ttotal: 1.59s\tremaining: 2.31s\n",
      "407:\tlearn: 266051.1661441\ttotal: 1.59s\tremaining: 2.31s\n",
      "408:\tlearn: 266051.0087965\ttotal: 1.6s\tremaining: 2.31s\n",
      "409:\tlearn: 266050.3574125\ttotal: 1.6s\tremaining: 2.3s\n",
      "410:\tlearn: 266049.7286135\ttotal: 1.6s\tremaining: 2.3s\n",
      "411:\tlearn: 266049.2117918\ttotal: 1.61s\tremaining: 2.29s\n",
      "412:\tlearn: 266048.8596287\ttotal: 1.61s\tremaining: 2.29s\n",
      "413:\tlearn: 266048.7255515\ttotal: 1.61s\tremaining: 2.29s\n",
      "414:\tlearn: 266048.1808654\ttotal: 1.62s\tremaining: 2.28s\n",
      "415:\tlearn: 266048.0678183\ttotal: 1.62s\tremaining: 2.27s\n",
      "416:\tlearn: 266047.6704091\ttotal: 1.63s\tremaining: 2.27s\n",
      "417:\tlearn: 266047.1334924\ttotal: 1.63s\tremaining: 2.27s\n",
      "418:\tlearn: 266046.6876113\ttotal: 1.63s\tremaining: 2.26s\n",
      "419:\tlearn: 266045.9898299\ttotal: 1.64s\tremaining: 2.26s\n",
      "420:\tlearn: 266045.3884436\ttotal: 1.64s\tremaining: 2.25s\n",
      "421:\tlearn: 266044.6826612\ttotal: 1.64s\tremaining: 2.25s\n",
      "422:\tlearn: 266044.0759360\ttotal: 1.65s\tremaining: 2.24s\n",
      "423:\tlearn: 266043.6506463\ttotal: 1.65s\tremaining: 2.24s\n",
      "424:\tlearn: 266043.5113756\ttotal: 1.65s\tremaining: 2.24s\n",
      "425:\tlearn: 266043.1254546\ttotal: 1.66s\tremaining: 2.23s\n",
      "426:\tlearn: 266042.5461137\ttotal: 1.66s\tremaining: 2.23s\n",
      "427:\tlearn: 266041.9390588\ttotal: 1.66s\tremaining: 2.22s\n",
      "428:\tlearn: 266041.5235042\ttotal: 1.67s\tremaining: 2.22s\n",
      "429:\tlearn: 266041.1521632\ttotal: 1.67s\tremaining: 2.21s\n",
      "430:\tlearn: 266040.6679488\ttotal: 1.67s\tremaining: 2.21s\n",
      "431:\tlearn: 266040.2868340\ttotal: 1.68s\tremaining: 2.2s\n",
      "432:\tlearn: 266039.7649783\ttotal: 1.68s\tremaining: 2.2s\n",
      "433:\tlearn: 266039.4243805\ttotal: 1.68s\tremaining: 2.19s\n",
      "434:\tlearn: 266038.7751747\ttotal: 1.69s\tremaining: 2.19s\n",
      "435:\tlearn: 266038.6457942\ttotal: 1.69s\tremaining: 2.18s\n",
      "436:\tlearn: 266038.2626028\ttotal: 1.69s\tremaining: 2.18s\n",
      "437:\tlearn: 266037.8407717\ttotal: 1.69s\tremaining: 2.17s\n",
      "438:\tlearn: 266037.3400887\ttotal: 1.7s\tremaining: 2.17s\n",
      "439:\tlearn: 266036.8961342\ttotal: 1.7s\tremaining: 2.16s\n",
      "440:\tlearn: 266036.4094998\ttotal: 1.7s\tremaining: 2.16s\n",
      "441:\tlearn: 266036.2264242\ttotal: 1.7s\tremaining: 2.15s\n",
      "442:\tlearn: 266035.9209938\ttotal: 1.71s\tremaining: 2.15s\n",
      "443:\tlearn: 266035.3873390\ttotal: 1.71s\tremaining: 2.14s\n",
      "444:\tlearn: 266034.9495288\ttotal: 1.71s\tremaining: 2.13s\n",
      "445:\tlearn: 266034.8482134\ttotal: 1.71s\tremaining: 2.13s\n",
      "446:\tlearn: 266034.4597316\ttotal: 1.72s\tremaining: 2.12s\n",
      "447:\tlearn: 266034.0322415\ttotal: 1.72s\tremaining: 2.12s\n",
      "448:\tlearn: 266033.2544887\ttotal: 1.72s\tremaining: 2.11s\n",
      "449:\tlearn: 266033.1551938\ttotal: 1.72s\tremaining: 2.11s\n",
      "450:\tlearn: 266033.0634739\ttotal: 1.73s\tremaining: 2.1s\n",
      "451:\tlearn: 266032.6435172\ttotal: 1.73s\tremaining: 2.1s\n",
      "452:\tlearn: 266032.1748601\ttotal: 1.73s\tremaining: 2.09s\n",
      "453:\tlearn: 266031.6142986\ttotal: 1.74s\tremaining: 2.09s\n",
      "454:\tlearn: 266031.4138967\ttotal: 1.74s\tremaining: 2.08s\n",
      "455:\tlearn: 266031.3274320\ttotal: 1.74s\tremaining: 2.08s\n",
      "456:\tlearn: 266031.2457425\ttotal: 1.74s\tremaining: 2.07s\n",
      "457:\tlearn: 266031.1685476\ttotal: 1.75s\tremaining: 2.07s\n",
      "458:\tlearn: 266031.0842112\ttotal: 1.75s\tremaining: 2.06s\n",
      "459:\tlearn: 266031.0145017\ttotal: 1.75s\tremaining: 2.06s\n",
      "460:\tlearn: 266030.6881770\ttotal: 1.75s\tremaining: 2.05s\n",
      "461:\tlearn: 266030.0710200\ttotal: 1.75s\tremaining: 2.04s\n",
      "462:\tlearn: 266029.7907411\ttotal: 1.76s\tremaining: 2.04s\n",
      "463:\tlearn: 266029.6294768\ttotal: 1.76s\tremaining: 2.04s\n",
      "464:\tlearn: 266029.1991045\ttotal: 1.76s\tremaining: 2.03s\n",
      "465:\tlearn: 266028.7251707\ttotal: 1.77s\tremaining: 2.02s\n",
      "466:\tlearn: 266028.3023944\ttotal: 1.77s\tremaining: 2.02s\n",
      "467:\tlearn: 266028.0251974\ttotal: 1.77s\tremaining: 2.01s\n",
      "468:\tlearn: 266027.8807146\ttotal: 1.77s\tremaining: 2.01s\n",
      "469:\tlearn: 266027.3443304\ttotal: 1.78s\tremaining: 2s\n",
      "470:\tlearn: 266027.2006261\ttotal: 1.78s\tremaining: 2s\n",
      "471:\tlearn: 266026.8326181\ttotal: 1.78s\tremaining: 1.99s\n",
      "472:\tlearn: 266026.4978564\ttotal: 1.78s\tremaining: 1.99s\n",
      "473:\tlearn: 266026.2546676\ttotal: 1.79s\tremaining: 1.98s\n",
      "474:\tlearn: 266026.0503757\ttotal: 1.79s\tremaining: 1.98s\n",
      "475:\tlearn: 266025.8036026\ttotal: 1.79s\tremaining: 1.97s\n",
      "476:\tlearn: 266025.5305108\ttotal: 1.8s\tremaining: 1.97s\n",
      "477:\tlearn: 266025.0899245\ttotal: 1.8s\tremaining: 1.97s\n",
      "478:\tlearn: 266024.7560403\ttotal: 1.8s\tremaining: 1.96s\n",
      "479:\tlearn: 266024.2086031\ttotal: 1.8s\tremaining: 1.96s\n",
      "480:\tlearn: 266023.8948824\ttotal: 1.81s\tremaining: 1.95s\n",
      "481:\tlearn: 266023.5851617\ttotal: 1.81s\tremaining: 1.95s\n",
      "482:\tlearn: 266023.4127753\ttotal: 1.81s\tremaining: 1.94s\n",
      "483:\tlearn: 266023.3512566\ttotal: 1.82s\tremaining: 1.94s\n",
      "484:\tlearn: 266023.2239177\ttotal: 1.82s\tremaining: 1.94s\n",
      "485:\tlearn: 266023.1729333\ttotal: 1.83s\tremaining: 1.94s\n",
      "486:\tlearn: 266023.0606890\ttotal: 1.83s\tremaining: 1.93s\n",
      "487:\tlearn: 266022.8957456\ttotal: 1.83s\tremaining: 1.93s\n",
      "488:\tlearn: 266022.5187054\ttotal: 1.84s\tremaining: 1.92s\n",
      "489:\tlearn: 266022.0249902\ttotal: 1.84s\tremaining: 1.92s\n",
      "490:\tlearn: 266021.6945303\ttotal: 1.85s\tremaining: 1.91s\n",
      "491:\tlearn: 266021.4566851\ttotal: 1.85s\tremaining: 1.91s\n",
      "492:\tlearn: 266021.2854086\ttotal: 1.85s\tremaining: 1.9s\n",
      "493:\tlearn: 266020.9992650\ttotal: 1.86s\tremaining: 1.9s\n",
      "494:\tlearn: 266020.8941273\ttotal: 1.86s\tremaining: 1.9s\n",
      "495:\tlearn: 266020.7948706\ttotal: 1.86s\tremaining: 1.89s\n",
      "496:\tlearn: 266020.5808401\ttotal: 1.86s\tremaining: 1.89s\n",
      "497:\tlearn: 266020.1830822\ttotal: 1.87s\tremaining: 1.88s\n",
      "498:\tlearn: 266019.8257760\ttotal: 1.87s\tremaining: 1.88s\n",
      "499:\tlearn: 266019.5718591\ttotal: 1.88s\tremaining: 1.88s\n",
      "500:\tlearn: 266019.4463911\ttotal: 1.88s\tremaining: 1.87s\n",
      "501:\tlearn: 266019.1948440\ttotal: 1.88s\tremaining: 1.87s\n",
      "502:\tlearn: 266019.0027169\ttotal: 1.89s\tremaining: 1.86s\n",
      "503:\tlearn: 266018.9550454\ttotal: 1.89s\tremaining: 1.86s\n",
      "504:\tlearn: 266018.9158196\ttotal: 1.89s\tremaining: 1.85s\n",
      "505:\tlearn: 266018.7578223\ttotal: 1.89s\tremaining: 1.85s\n",
      "506:\tlearn: 266018.7150304\ttotal: 1.9s\tremaining: 1.84s\n",
      "507:\tlearn: 266018.3522536\ttotal: 1.9s\tremaining: 1.84s\n",
      "508:\tlearn: 266018.3168981\ttotal: 1.9s\tremaining: 1.83s\n",
      "509:\tlearn: 266018.0562273\ttotal: 1.91s\tremaining: 1.83s\n",
      "510:\tlearn: 266017.8826749\ttotal: 1.91s\tremaining: 1.82s\n",
      "511:\tlearn: 266017.6744684\ttotal: 1.91s\tremaining: 1.82s\n",
      "512:\tlearn: 266017.4071312\ttotal: 1.91s\tremaining: 1.81s\n",
      "513:\tlearn: 266017.3285761\ttotal: 1.91s\tremaining: 1.81s\n",
      "514:\tlearn: 266017.2544388\ttotal: 1.92s\tremaining: 1.81s\n",
      "515:\tlearn: 266017.0891792\ttotal: 1.92s\tremaining: 1.8s\n",
      "516:\tlearn: 266017.0588559\ttotal: 1.92s\tremaining: 1.8s\n",
      "517:\tlearn: 266017.0301594\ttotal: 1.93s\tremaining: 1.79s\n",
      "518:\tlearn: 266016.7782580\ttotal: 1.93s\tremaining: 1.79s\n",
      "519:\tlearn: 266016.7510610\ttotal: 1.93s\tremaining: 1.78s\n",
      "520:\tlearn: 266016.7208984\ttotal: 1.93s\tremaining: 1.78s\n",
      "521:\tlearn: 266016.5350283\ttotal: 1.94s\tremaining: 1.77s\n",
      "522:\tlearn: 266016.2559778\ttotal: 1.94s\tremaining: 1.77s\n",
      "523:\tlearn: 266016.2276074\ttotal: 1.94s\tremaining: 1.76s\n",
      "524:\tlearn: 266016.2007887\ttotal: 1.94s\tremaining: 1.76s\n",
      "525:\tlearn: 266016.1754326\ttotal: 1.95s\tremaining: 1.75s\n",
      "526:\tlearn: 266015.8271913\ttotal: 1.95s\tremaining: 1.75s\n",
      "527:\tlearn: 266015.6742775\ttotal: 1.95s\tremaining: 1.74s\n",
      "528:\tlearn: 266015.4502950\ttotal: 1.95s\tremaining: 1.74s\n",
      "529:\tlearn: 266015.4263716\ttotal: 1.96s\tremaining: 1.73s\n",
      "530:\tlearn: 266015.2836133\ttotal: 1.96s\tremaining: 1.73s\n",
      "531:\tlearn: 266015.1284621\ttotal: 1.96s\tremaining: 1.73s\n",
      "532:\tlearn: 266014.7906468\ttotal: 1.97s\tremaining: 1.72s\n",
      "533:\tlearn: 266014.4407646\ttotal: 1.97s\tremaining: 1.72s\n",
      "534:\tlearn: 266014.2068799\ttotal: 1.97s\tremaining: 1.71s\n",
      "535:\tlearn: 266014.0151476\ttotal: 1.97s\tremaining: 1.71s\n",
      "536:\tlearn: 266013.7917153\ttotal: 1.97s\tremaining: 1.7s\n",
      "537:\tlearn: 266013.6998582\ttotal: 1.98s\tremaining: 1.7s\n",
      "538:\tlearn: 266013.5471036\ttotal: 1.98s\tremaining: 1.69s\n",
      "539:\tlearn: 266013.2259061\ttotal: 1.98s\tremaining: 1.69s\n",
      "540:\tlearn: 266013.0857454\ttotal: 1.99s\tremaining: 1.69s\n",
      "541:\tlearn: 266012.8825660\ttotal: 1.99s\tremaining: 1.68s\n",
      "542:\tlearn: 266012.6219120\ttotal: 1.99s\tremaining: 1.68s\n",
      "543:\tlearn: 266012.5360093\ttotal: 1.99s\tremaining: 1.67s\n",
      "544:\tlearn: 266012.3327540\ttotal: 2s\tremaining: 1.67s\n",
      "545:\tlearn: 266012.2185380\ttotal: 2s\tremaining: 1.66s\n",
      "546:\tlearn: 266012.0531388\ttotal: 2s\tremaining: 1.66s\n",
      "547:\tlearn: 266011.7870644\ttotal: 2s\tremaining: 1.65s\n",
      "548:\tlearn: 266011.5829133\ttotal: 2.01s\tremaining: 1.65s\n",
      "549:\tlearn: 266011.5024235\ttotal: 2.01s\tremaining: 1.65s\n",
      "550:\tlearn: 266011.3495577\ttotal: 2.02s\tremaining: 1.64s\n",
      "551:\tlearn: 266011.1840663\ttotal: 2.02s\tremaining: 1.64s\n",
      "552:\tlearn: 266011.1571494\ttotal: 2.02s\tremaining: 1.63s\n",
      "553:\tlearn: 266011.0009395\ttotal: 2.02s\tremaining: 1.63s\n",
      "554:\tlearn: 266010.8508777\ttotal: 2.03s\tremaining: 1.62s\n",
      "555:\tlearn: 266010.6908956\ttotal: 2.03s\tremaining: 1.62s\n",
      "556:\tlearn: 266010.5706518\ttotal: 2.03s\tremaining: 1.62s\n",
      "557:\tlearn: 266010.4959079\ttotal: 2.04s\tremaining: 1.61s\n",
      "558:\tlearn: 266010.2928848\ttotal: 2.04s\tremaining: 1.61s\n",
      "559:\tlearn: 266010.0415963\ttotal: 2.04s\tremaining: 1.6s\n",
      "560:\tlearn: 266010.0229878\ttotal: 2.04s\tremaining: 1.6s\n",
      "561:\tlearn: 266009.8691847\ttotal: 2.05s\tremaining: 1.6s\n",
      "562:\tlearn: 266009.7323719\ttotal: 2.05s\tremaining: 1.59s\n",
      "563:\tlearn: 266009.5500080\ttotal: 2.05s\tremaining: 1.59s\n",
      "564:\tlearn: 266009.5322515\ttotal: 2.06s\tremaining: 1.58s\n",
      "565:\tlearn: 266009.3641547\ttotal: 2.06s\tremaining: 1.58s\n",
      "566:\tlearn: 266009.2676859\ttotal: 2.06s\tremaining: 1.57s\n",
      "567:\tlearn: 266009.2456023\ttotal: 2.06s\tremaining: 1.57s\n",
      "568:\tlearn: 266009.2296007\ttotal: 2.07s\tremaining: 1.57s\n",
      "569:\tlearn: 266009.2080612\ttotal: 2.07s\tremaining: 1.56s\n",
      "570:\tlearn: 266009.0229666\ttotal: 2.07s\tremaining: 1.56s\n",
      "571:\tlearn: 266008.9083702\ttotal: 2.08s\tremaining: 1.55s\n",
      "572:\tlearn: 266008.6278230\ttotal: 2.08s\tremaining: 1.55s\n",
      "573:\tlearn: 266008.3924019\ttotal: 2.08s\tremaining: 1.54s\n",
      "574:\tlearn: 266008.2207929\ttotal: 2.08s\tremaining: 1.54s\n",
      "575:\tlearn: 266008.1090606\ttotal: 2.09s\tremaining: 1.53s\n",
      "576:\tlearn: 266008.0618623\ttotal: 2.09s\tremaining: 1.53s\n",
      "577:\tlearn: 266007.9589818\ttotal: 2.09s\tremaining: 1.53s\n",
      "578:\tlearn: 266007.7383271\ttotal: 2.1s\tremaining: 1.52s\n",
      "579:\tlearn: 266007.5807749\ttotal: 2.1s\tremaining: 1.52s\n",
      "580:\tlearn: 266007.3647285\ttotal: 2.1s\tremaining: 1.51s\n",
      "581:\tlearn: 266007.2116262\ttotal: 2.1s\tremaining: 1.51s\n",
      "582:\tlearn: 266007.0872532\ttotal: 2.11s\tremaining: 1.51s\n",
      "583:\tlearn: 266006.9742736\ttotal: 2.11s\tremaining: 1.5s\n",
      "584:\tlearn: 266006.8043306\ttotal: 2.11s\tremaining: 1.5s\n",
      "585:\tlearn: 266006.7845528\ttotal: 2.11s\tremaining: 1.49s\n",
      "586:\tlearn: 266006.6945774\ttotal: 2.12s\tremaining: 1.49s\n",
      "587:\tlearn: 266006.5597850\ttotal: 2.12s\tremaining: 1.48s\n",
      "588:\tlearn: 266006.3538408\ttotal: 2.12s\tremaining: 1.48s\n",
      "589:\tlearn: 266006.2136946\ttotal: 2.12s\tremaining: 1.48s\n",
      "590:\tlearn: 266005.9932619\ttotal: 2.13s\tremaining: 1.47s\n",
      "591:\tlearn: 266005.8216956\ttotal: 2.13s\tremaining: 1.47s\n",
      "592:\tlearn: 266005.7125178\ttotal: 2.13s\tremaining: 1.46s\n",
      "593:\tlearn: 266005.6940078\ttotal: 2.13s\tremaining: 1.46s\n",
      "594:\tlearn: 266005.4717477\ttotal: 2.14s\tremaining: 1.45s\n",
      "595:\tlearn: 266005.3184532\ttotal: 2.14s\tremaining: 1.45s\n",
      "596:\tlearn: 266005.1673578\ttotal: 2.14s\tremaining: 1.45s\n",
      "597:\tlearn: 266004.9988596\ttotal: 2.15s\tremaining: 1.44s\n",
      "598:\tlearn: 266004.8122584\ttotal: 2.15s\tremaining: 1.44s\n",
      "599:\tlearn: 266004.6147925\ttotal: 2.15s\tremaining: 1.43s\n",
      "600:\tlearn: 266004.4186036\ttotal: 2.15s\tremaining: 1.43s\n",
      "601:\tlearn: 266004.2337981\ttotal: 2.16s\tremaining: 1.43s\n",
      "602:\tlearn: 266004.2157357\ttotal: 2.16s\tremaining: 1.42s\n",
      "603:\tlearn: 266004.1983696\ttotal: 2.16s\tremaining: 1.42s\n",
      "604:\tlearn: 266004.0163803\ttotal: 2.16s\tremaining: 1.41s\n",
      "605:\tlearn: 266003.9247196\ttotal: 2.17s\tremaining: 1.41s\n",
      "606:\tlearn: 266003.9098078\ttotal: 2.17s\tremaining: 1.4s\n",
      "607:\tlearn: 266003.7729769\ttotal: 2.17s\tremaining: 1.4s\n",
      "608:\tlearn: 266003.6561891\ttotal: 2.17s\tremaining: 1.4s\n",
      "609:\tlearn: 266003.5515851\ttotal: 2.18s\tremaining: 1.39s\n",
      "610:\tlearn: 266003.4441408\ttotal: 2.18s\tremaining: 1.39s\n",
      "611:\tlearn: 266003.3212947\ttotal: 2.18s\tremaining: 1.38s\n",
      "612:\tlearn: 266003.2284909\ttotal: 2.19s\tremaining: 1.38s\n",
      "613:\tlearn: 266003.0372265\ttotal: 2.19s\tremaining: 1.38s\n",
      "614:\tlearn: 266002.9070119\ttotal: 2.19s\tremaining: 1.37s\n",
      "615:\tlearn: 266002.7453951\ttotal: 2.19s\tremaining: 1.37s\n",
      "616:\tlearn: 266002.6589609\ttotal: 2.19s\tremaining: 1.36s\n",
      "617:\tlearn: 266002.6141034\ttotal: 2.2s\tremaining: 1.36s\n",
      "618:\tlearn: 266002.4986415\ttotal: 2.2s\tremaining: 1.35s\n",
      "619:\tlearn: 266002.4506851\ttotal: 2.2s\tremaining: 1.35s\n",
      "620:\tlearn: 266002.3429330\ttotal: 2.21s\tremaining: 1.35s\n",
      "621:\tlearn: 266002.2016817\ttotal: 2.21s\tremaining: 1.34s\n",
      "622:\tlearn: 266002.0496623\ttotal: 2.21s\tremaining: 1.34s\n",
      "623:\tlearn: 266001.9595587\ttotal: 2.22s\tremaining: 1.33s\n",
      "624:\tlearn: 266001.8129006\ttotal: 2.22s\tremaining: 1.33s\n",
      "625:\tlearn: 266001.6941471\ttotal: 2.22s\tremaining: 1.33s\n",
      "626:\tlearn: 266001.6442530\ttotal: 2.22s\tremaining: 1.32s\n",
      "627:\tlearn: 266001.4591578\ttotal: 2.23s\tremaining: 1.32s\n",
      "628:\tlearn: 266001.3880709\ttotal: 2.23s\tremaining: 1.32s\n",
      "629:\tlearn: 266001.3247083\ttotal: 2.23s\tremaining: 1.31s\n",
      "630:\tlearn: 266001.2147441\ttotal: 2.24s\tremaining: 1.31s\n",
      "631:\tlearn: 266001.0972715\ttotal: 2.24s\tremaining: 1.3s\n",
      "632:\tlearn: 266000.9847871\ttotal: 2.24s\tremaining: 1.3s\n",
      "633:\tlearn: 266000.8766153\ttotal: 2.25s\tremaining: 1.3s\n",
      "634:\tlearn: 266000.7683319\ttotal: 2.25s\tremaining: 1.29s\n",
      "635:\tlearn: 266000.6507218\ttotal: 2.25s\tremaining: 1.29s\n",
      "636:\tlearn: 266000.5555072\ttotal: 2.25s\tremaining: 1.28s\n",
      "637:\tlearn: 266000.4758647\ttotal: 2.26s\tremaining: 1.28s\n",
      "638:\tlearn: 266000.4388404\ttotal: 2.26s\tremaining: 1.28s\n",
      "639:\tlearn: 266000.4025224\ttotal: 2.27s\tremaining: 1.27s\n",
      "640:\tlearn: 266000.3634613\ttotal: 2.27s\tremaining: 1.27s\n",
      "641:\tlearn: 266000.3272443\ttotal: 2.27s\tremaining: 1.27s\n",
      "642:\tlearn: 266000.1892500\ttotal: 2.27s\tremaining: 1.26s\n",
      "643:\tlearn: 266000.0803388\ttotal: 2.28s\tremaining: 1.26s\n",
      "644:\tlearn: 265999.9966759\ttotal: 2.28s\tremaining: 1.25s\n",
      "645:\tlearn: 265999.9533728\ttotal: 2.28s\tremaining: 1.25s\n",
      "646:\tlearn: 265999.8505308\ttotal: 2.29s\tremaining: 1.25s\n",
      "647:\tlearn: 265999.7289051\ttotal: 2.29s\tremaining: 1.24s\n",
      "648:\tlearn: 265999.6703855\ttotal: 2.29s\tremaining: 1.24s\n",
      "649:\tlearn: 265999.6130710\ttotal: 2.29s\tremaining: 1.24s\n",
      "650:\tlearn: 265999.5041806\ttotal: 2.3s\tremaining: 1.23s\n",
      "651:\tlearn: 265999.4645162\ttotal: 2.3s\tremaining: 1.23s\n",
      "652:\tlearn: 265999.3623509\ttotal: 2.3s\tremaining: 1.22s\n",
      "653:\tlearn: 265999.2654928\ttotal: 2.3s\tremaining: 1.22s\n",
      "654:\tlearn: 265999.1874427\ttotal: 2.31s\tremaining: 1.21s\n",
      "655:\tlearn: 265999.1309563\ttotal: 2.31s\tremaining: 1.21s\n",
      "656:\tlearn: 265999.0725961\ttotal: 2.31s\tremaining: 1.21s\n",
      "657:\tlearn: 265998.9347008\ttotal: 2.31s\tremaining: 1.2s\n",
      "658:\tlearn: 265998.8278557\ttotal: 2.32s\tremaining: 1.2s\n",
      "659:\tlearn: 265998.7881933\ttotal: 2.32s\tremaining: 1.19s\n",
      "660:\tlearn: 265998.6984165\ttotal: 2.32s\tremaining: 1.19s\n",
      "661:\tlearn: 265998.6319827\ttotal: 2.33s\tremaining: 1.19s\n",
      "662:\tlearn: 265998.5513399\ttotal: 2.33s\tremaining: 1.18s\n",
      "663:\tlearn: 265998.5225433\ttotal: 2.33s\tremaining: 1.18s\n",
      "664:\tlearn: 265998.4259470\ttotal: 2.33s\tremaining: 1.18s\n",
      "665:\tlearn: 265998.3545065\ttotal: 2.33s\tremaining: 1.17s\n",
      "666:\tlearn: 265998.2866834\ttotal: 2.34s\tremaining: 1.17s\n",
      "667:\tlearn: 265998.2617323\ttotal: 2.34s\tremaining: 1.16s\n",
      "668:\tlearn: 265998.1351885\ttotal: 2.34s\tremaining: 1.16s\n",
      "669:\tlearn: 265998.1114075\ttotal: 2.35s\tremaining: 1.16s\n",
      "670:\tlearn: 265997.9970737\ttotal: 2.35s\tremaining: 1.15s\n",
      "671:\tlearn: 265997.8778673\ttotal: 2.35s\tremaining: 1.15s\n",
      "672:\tlearn: 265997.7979235\ttotal: 2.35s\tremaining: 1.14s\n",
      "673:\tlearn: 265997.7214598\ttotal: 2.36s\tremaining: 1.14s\n",
      "674:\tlearn: 265997.6970719\ttotal: 2.36s\tremaining: 1.14s\n",
      "675:\tlearn: 265997.5940240\ttotal: 2.36s\tremaining: 1.13s\n",
      "676:\tlearn: 265997.5235902\ttotal: 2.36s\tremaining: 1.13s\n",
      "677:\tlearn: 265997.5042628\ttotal: 2.37s\tremaining: 1.12s\n",
      "678:\tlearn: 265997.4098309\ttotal: 2.37s\tremaining: 1.12s\n",
      "679:\tlearn: 265997.3053674\ttotal: 2.37s\tremaining: 1.12s\n",
      "680:\tlearn: 265997.2348053\ttotal: 2.38s\tremaining: 1.11s\n",
      "681:\tlearn: 265997.1363308\ttotal: 2.38s\tremaining: 1.11s\n",
      "682:\tlearn: 265997.0672021\ttotal: 2.38s\tremaining: 1.1s\n",
      "683:\tlearn: 265997.0468087\ttotal: 2.38s\tremaining: 1.1s\n",
      "684:\tlearn: 265996.9884831\ttotal: 2.39s\tremaining: 1.1s\n",
      "685:\tlearn: 265996.9682526\ttotal: 2.39s\tremaining: 1.09s\n",
      "686:\tlearn: 265996.8787567\ttotal: 2.39s\tremaining: 1.09s\n",
      "687:\tlearn: 265996.8084843\ttotal: 2.4s\tremaining: 1.09s\n",
      "688:\tlearn: 265996.6792100\ttotal: 2.4s\tremaining: 1.08s\n",
      "689:\tlearn: 265996.6714303\ttotal: 2.4s\tremaining: 1.08s\n",
      "690:\tlearn: 265996.6189667\ttotal: 2.4s\tremaining: 1.07s\n",
      "691:\tlearn: 265996.5461152\ttotal: 2.41s\tremaining: 1.07s\n",
      "692:\tlearn: 265996.4859924\ttotal: 2.41s\tremaining: 1.07s\n",
      "693:\tlearn: 265996.4199273\ttotal: 2.41s\tremaining: 1.06s\n",
      "694:\tlearn: 265996.3704222\ttotal: 2.42s\tremaining: 1.06s\n",
      "695:\tlearn: 265996.3362207\ttotal: 2.42s\tremaining: 1.06s\n",
      "696:\tlearn: 265996.2379692\ttotal: 2.42s\tremaining: 1.05s\n",
      "697:\tlearn: 265996.1768829\ttotal: 2.42s\tremaining: 1.05s\n",
      "698:\tlearn: 265996.1683898\ttotal: 2.43s\tremaining: 1.04s\n",
      "699:\tlearn: 265996.1603658\ttotal: 2.43s\tremaining: 1.04s\n",
      "700:\tlearn: 265996.0915778\ttotal: 2.44s\tremaining: 1.04s\n",
      "701:\tlearn: 265996.0384897\ttotal: 2.44s\tremaining: 1.03s\n",
      "702:\tlearn: 265995.9335272\ttotal: 2.44s\tremaining: 1.03s\n",
      "703:\tlearn: 265995.8769587\ttotal: 2.44s\tremaining: 1.03s\n",
      "704:\tlearn: 265995.8144289\ttotal: 2.45s\tremaining: 1.02s\n",
      "705:\tlearn: 265995.7760270\ttotal: 2.45s\tremaining: 1.02s\n",
      "706:\tlearn: 265995.6944971\ttotal: 2.45s\tremaining: 1.02s\n",
      "707:\tlearn: 265995.6379717\ttotal: 2.46s\tremaining: 1.01s\n",
      "708:\tlearn: 265995.5590131\ttotal: 2.46s\tremaining: 1.01s\n",
      "709:\tlearn: 265995.5018375\ttotal: 2.47s\tremaining: 1.01s\n",
      "710:\tlearn: 265995.4208846\ttotal: 2.47s\tremaining: 1s\n",
      "711:\tlearn: 265995.3440956\ttotal: 2.47s\tremaining: 1s\n",
      "712:\tlearn: 265995.2714247\ttotal: 2.48s\tremaining: 998ms\n",
      "713:\tlearn: 265995.2637811\ttotal: 2.48s\tremaining: 995ms\n",
      "714:\tlearn: 265995.1911448\ttotal: 2.49s\tremaining: 991ms\n",
      "715:\tlearn: 265995.1711399\ttotal: 2.49s\tremaining: 988ms\n",
      "716:\tlearn: 265995.0958575\ttotal: 2.5s\tremaining: 985ms\n",
      "717:\tlearn: 265995.0887391\ttotal: 2.5s\tremaining: 982ms\n",
      "718:\tlearn: 265995.0515418\ttotal: 2.5s\tremaining: 979ms\n",
      "719:\tlearn: 265994.9897712\ttotal: 2.51s\tremaining: 975ms\n",
      "720:\tlearn: 265994.9023411\ttotal: 2.51s\tremaining: 972ms\n",
      "721:\tlearn: 265994.8543135\ttotal: 2.52s\tremaining: 968ms\n",
      "722:\tlearn: 265994.8352973\ttotal: 2.52s\tremaining: 965ms\n",
      "723:\tlearn: 265994.7780422\ttotal: 2.52s\tremaining: 961ms\n",
      "724:\tlearn: 265994.6902647\ttotal: 2.53s\tremaining: 960ms\n",
      "725:\tlearn: 265994.5872942\ttotal: 2.53s\tremaining: 956ms\n",
      "726:\tlearn: 265994.5250223\ttotal: 2.54s\tremaining: 953ms\n",
      "727:\tlearn: 265994.4374691\ttotal: 2.54s\tremaining: 951ms\n",
      "728:\tlearn: 265994.3843552\ttotal: 2.55s\tremaining: 947ms\n",
      "729:\tlearn: 265994.3014015\ttotal: 2.55s\tremaining: 944ms\n",
      "730:\tlearn: 265994.2191009\ttotal: 2.56s\tremaining: 940ms\n",
      "731:\tlearn: 265994.1023665\ttotal: 2.56s\tremaining: 937ms\n",
      "732:\tlearn: 265994.0478284\ttotal: 2.56s\tremaining: 934ms\n",
      "733:\tlearn: 265993.9985437\ttotal: 2.57s\tremaining: 930ms\n",
      "734:\tlearn: 265993.9089305\ttotal: 2.57s\tremaining: 927ms\n",
      "735:\tlearn: 265993.8553580\ttotal: 2.57s\tremaining: 924ms\n",
      "736:\tlearn: 265993.8013742\ttotal: 2.58s\tremaining: 920ms\n",
      "737:\tlearn: 265993.7292079\ttotal: 2.58s\tremaining: 917ms\n",
      "738:\tlearn: 265993.6900855\ttotal: 2.58s\tremaining: 913ms\n",
      "739:\tlearn: 265993.6555056\ttotal: 2.59s\tremaining: 910ms\n",
      "740:\tlearn: 265993.6306304\ttotal: 2.59s\tremaining: 906ms\n",
      "741:\tlearn: 265993.5941408\ttotal: 2.6s\tremaining: 902ms\n",
      "742:\tlearn: 265993.5489081\ttotal: 2.6s\tremaining: 899ms\n",
      "743:\tlearn: 265993.5160727\ttotal: 2.6s\tremaining: 896ms\n",
      "744:\tlearn: 265993.4713229\ttotal: 2.61s\tremaining: 892ms\n",
      "745:\tlearn: 265993.4329282\ttotal: 2.61s\tremaining: 889ms\n",
      "746:\tlearn: 265993.3963522\ttotal: 2.61s\tremaining: 885ms\n",
      "747:\tlearn: 265993.3715047\ttotal: 2.62s\tremaining: 883ms\n",
      "748:\tlearn: 265993.3396229\ttotal: 2.62s\tremaining: 879ms\n",
      "749:\tlearn: 265993.2930633\ttotal: 2.63s\tremaining: 876ms\n",
      "750:\tlearn: 265993.2133708\ttotal: 2.63s\tremaining: 872ms\n",
      "751:\tlearn: 265993.1903150\ttotal: 2.64s\tremaining: 870ms\n",
      "752:\tlearn: 265993.1162543\ttotal: 2.64s\tremaining: 866ms\n",
      "753:\tlearn: 265993.0664616\ttotal: 2.64s\tremaining: 863ms\n",
      "754:\tlearn: 265993.0238847\ttotal: 2.65s\tremaining: 859ms\n",
      "755:\tlearn: 265992.9485346\ttotal: 2.65s\tremaining: 856ms\n",
      "756:\tlearn: 265992.9161006\ttotal: 2.66s\tremaining: 853ms\n",
      "757:\tlearn: 265992.8579037\ttotal: 2.66s\tremaining: 849ms\n",
      "758:\tlearn: 265992.8382321\ttotal: 2.66s\tremaining: 845ms\n",
      "759:\tlearn: 265992.8088415\ttotal: 2.67s\tremaining: 842ms\n",
      "760:\tlearn: 265992.7765994\ttotal: 2.67s\tremaining: 838ms\n",
      "761:\tlearn: 265992.7275455\ttotal: 2.67s\tremaining: 835ms\n",
      "762:\tlearn: 265992.6760861\ttotal: 2.68s\tremaining: 831ms\n",
      "763:\tlearn: 265992.6244484\ttotal: 2.68s\tremaining: 828ms\n",
      "764:\tlearn: 265992.5520625\ttotal: 2.68s\tremaining: 824ms\n",
      "765:\tlearn: 265992.5034877\ttotal: 2.69s\tremaining: 821ms\n",
      "766:\tlearn: 265992.4633800\ttotal: 2.69s\tremaining: 817ms\n",
      "767:\tlearn: 265992.4576641\ttotal: 2.69s\tremaining: 813ms\n",
      "768:\tlearn: 265992.3966325\ttotal: 2.7s\tremaining: 810ms\n",
      "769:\tlearn: 265992.3904392\ttotal: 2.7s\tremaining: 807ms\n",
      "770:\tlearn: 265992.3571457\ttotal: 2.7s\tremaining: 803ms\n",
      "771:\tlearn: 265992.3190119\ttotal: 2.71s\tremaining: 799ms\n",
      "772:\tlearn: 265992.3047095\ttotal: 2.71s\tremaining: 796ms\n",
      "773:\tlearn: 265992.2899459\ttotal: 2.71s\tremaining: 793ms\n",
      "774:\tlearn: 265992.2414608\ttotal: 2.72s\tremaining: 789ms\n",
      "775:\tlearn: 265992.1763165\ttotal: 2.72s\tremaining: 786ms\n",
      "776:\tlearn: 265992.1319346\ttotal: 2.73s\tremaining: 783ms\n",
      "777:\tlearn: 265992.0752433\ttotal: 2.73s\tremaining: 779ms\n",
      "778:\tlearn: 265992.0375466\ttotal: 2.73s\tremaining: 776ms\n",
      "779:\tlearn: 265991.9902942\ttotal: 2.74s\tremaining: 772ms\n",
      "780:\tlearn: 265991.9496616\ttotal: 2.74s\tremaining: 769ms\n",
      "781:\tlearn: 265991.9090631\ttotal: 2.75s\tremaining: 766ms\n",
      "782:\tlearn: 265991.8658798\ttotal: 2.75s\tremaining: 763ms\n",
      "783:\tlearn: 265991.8516717\ttotal: 2.75s\tremaining: 759ms\n",
      "784:\tlearn: 265991.8403756\ttotal: 2.76s\tremaining: 756ms\n",
      "785:\tlearn: 265991.8111195\ttotal: 2.76s\tremaining: 752ms\n",
      "786:\tlearn: 265991.7779217\ttotal: 2.77s\tremaining: 749ms\n",
      "787:\tlearn: 265991.7634251\ttotal: 2.77s\tremaining: 745ms\n",
      "788:\tlearn: 265991.7305571\ttotal: 2.77s\tremaining: 742ms\n",
      "789:\tlearn: 265991.6935396\ttotal: 2.78s\tremaining: 738ms\n",
      "790:\tlearn: 265991.6583223\ttotal: 2.78s\tremaining: 735ms\n",
      "791:\tlearn: 265991.5946618\ttotal: 2.79s\tremaining: 731ms\n",
      "792:\tlearn: 265991.5689634\ttotal: 2.79s\tremaining: 728ms\n",
      "793:\tlearn: 265991.5234451\ttotal: 2.79s\tremaining: 725ms\n",
      "794:\tlearn: 265991.4552473\ttotal: 2.8s\tremaining: 721ms\n",
      "795:\tlearn: 265991.4035730\ttotal: 2.8s\tremaining: 718ms\n",
      "796:\tlearn: 265991.3600683\ttotal: 2.81s\tremaining: 715ms\n",
      "797:\tlearn: 265991.3403834\ttotal: 2.81s\tremaining: 711ms\n",
      "798:\tlearn: 265991.2949369\ttotal: 2.81s\tremaining: 708ms\n",
      "799:\tlearn: 265991.2463237\ttotal: 2.82s\tremaining: 705ms\n",
      "800:\tlearn: 265991.2226798\ttotal: 2.82s\tremaining: 702ms\n",
      "801:\tlearn: 265991.1765284\ttotal: 2.83s\tremaining: 698ms\n",
      "802:\tlearn: 265991.1378616\ttotal: 2.83s\tremaining: 695ms\n",
      "803:\tlearn: 265991.0986521\ttotal: 2.84s\tremaining: 692ms\n",
      "804:\tlearn: 265991.0757891\ttotal: 2.84s\tremaining: 688ms\n",
      "805:\tlearn: 265991.0647502\ttotal: 2.84s\tremaining: 684ms\n",
      "806:\tlearn: 265991.0106774\ttotal: 2.85s\tremaining: 681ms\n",
      "807:\tlearn: 265990.9670552\ttotal: 2.85s\tremaining: 678ms\n",
      "808:\tlearn: 265990.9527622\ttotal: 2.85s\tremaining: 674ms\n",
      "809:\tlearn: 265990.9004376\ttotal: 2.86s\tremaining: 670ms\n",
      "810:\tlearn: 265990.8536025\ttotal: 2.86s\tremaining: 667ms\n",
      "811:\tlearn: 265990.8337885\ttotal: 2.86s\tremaining: 663ms\n",
      "812:\tlearn: 265990.7866875\ttotal: 2.87s\tremaining: 659ms\n",
      "813:\tlearn: 265990.7604379\ttotal: 2.87s\tremaining: 656ms\n",
      "814:\tlearn: 265990.7491507\ttotal: 2.87s\tremaining: 652ms\n",
      "815:\tlearn: 265990.7211156\ttotal: 2.88s\tremaining: 648ms\n",
      "816:\tlearn: 265990.7104575\ttotal: 2.88s\tremaining: 645ms\n",
      "817:\tlearn: 265990.6454802\ttotal: 2.88s\tremaining: 642ms\n",
      "818:\tlearn: 265990.5984373\ttotal: 2.89s\tremaining: 638ms\n",
      "819:\tlearn: 265990.5631181\ttotal: 2.89s\tremaining: 634ms\n",
      "820:\tlearn: 265990.5368964\ttotal: 2.89s\tremaining: 631ms\n",
      "821:\tlearn: 265990.4999977\ttotal: 2.9s\tremaining: 627ms\n",
      "822:\tlearn: 265990.4585166\ttotal: 2.9s\tremaining: 624ms\n",
      "823:\tlearn: 265990.4344632\ttotal: 2.9s\tremaining: 620ms\n",
      "824:\tlearn: 265990.3989616\ttotal: 2.9s\tremaining: 616ms\n",
      "825:\tlearn: 265990.3602567\ttotal: 2.91s\tremaining: 613ms\n",
      "826:\tlearn: 265990.3256012\ttotal: 2.91s\tremaining: 609ms\n",
      "827:\tlearn: 265990.3162862\ttotal: 2.92s\tremaining: 606ms\n",
      "828:\tlearn: 265990.2884108\ttotal: 2.92s\tremaining: 602ms\n",
      "829:\tlearn: 265990.2519592\ttotal: 2.92s\tremaining: 598ms\n",
      "830:\tlearn: 265990.2469187\ttotal: 2.93s\tremaining: 595ms\n",
      "831:\tlearn: 265990.2266282\ttotal: 2.93s\tremaining: 591ms\n",
      "832:\tlearn: 265990.1993557\ttotal: 2.93s\tremaining: 588ms\n",
      "833:\tlearn: 265990.1904008\ttotal: 2.93s\tremaining: 584ms\n",
      "834:\tlearn: 265990.1645428\ttotal: 2.94s\tremaining: 580ms\n",
      "835:\tlearn: 265990.1259183\ttotal: 2.94s\tremaining: 577ms\n",
      "836:\tlearn: 265990.1060383\ttotal: 2.94s\tremaining: 574ms\n",
      "837:\tlearn: 265990.0959526\ttotal: 2.95s\tremaining: 570ms\n",
      "838:\tlearn: 265990.0589716\ttotal: 2.95s\tremaining: 566ms\n",
      "839:\tlearn: 265990.0356319\ttotal: 2.95s\tremaining: 563ms\n",
      "840:\tlearn: 265990.0265637\ttotal: 2.96s\tremaining: 559ms\n",
      "841:\tlearn: 265989.9947160\ttotal: 2.96s\tremaining: 556ms\n",
      "842:\tlearn: 265989.9371850\ttotal: 2.96s\tremaining: 552ms\n",
      "843:\tlearn: 265989.8979323\ttotal: 2.97s\tremaining: 549ms\n",
      "844:\tlearn: 265989.8685486\ttotal: 2.97s\tremaining: 545ms\n",
      "845:\tlearn: 265989.8277647\ttotal: 2.98s\tremaining: 542ms\n",
      "846:\tlearn: 265989.8057026\ttotal: 2.98s\tremaining: 538ms\n",
      "847:\tlearn: 265989.7803211\ttotal: 2.98s\tremaining: 535ms\n",
      "848:\tlearn: 265989.7443557\ttotal: 2.99s\tremaining: 532ms\n",
      "849:\tlearn: 265989.7234980\ttotal: 2.99s\tremaining: 528ms\n",
      "850:\tlearn: 265989.7013914\ttotal: 3s\tremaining: 524ms\n",
      "851:\tlearn: 265989.6886392\ttotal: 3s\tremaining: 521ms\n",
      "852:\tlearn: 265989.6441348\ttotal: 3s\tremaining: 518ms\n",
      "853:\tlearn: 265989.6180730\ttotal: 3.01s\tremaining: 514ms\n",
      "854:\tlearn: 265989.5920657\ttotal: 3.01s\tremaining: 511ms\n",
      "855:\tlearn: 265989.5677928\ttotal: 3.01s\tremaining: 507ms\n",
      "856:\tlearn: 265989.5297742\ttotal: 3.02s\tremaining: 504ms\n",
      "857:\tlearn: 265989.4804649\ttotal: 3.02s\tremaining: 500ms\n",
      "858:\tlearn: 265989.4641044\ttotal: 3.03s\tremaining: 497ms\n",
      "859:\tlearn: 265989.4385321\ttotal: 3.03s\tremaining: 493ms\n",
      "860:\tlearn: 265989.4203059\ttotal: 3.03s\tremaining: 490ms\n",
      "861:\tlearn: 265989.3860038\ttotal: 3.04s\tremaining: 486ms\n",
      "862:\tlearn: 265989.3675671\ttotal: 3.04s\tremaining: 483ms\n",
      "863:\tlearn: 265989.3604329\ttotal: 3.05s\tremaining: 480ms\n",
      "864:\tlearn: 265989.3332454\ttotal: 3.05s\tremaining: 476ms\n",
      "865:\tlearn: 265989.3077523\ttotal: 3.05s\tremaining: 472ms\n",
      "866:\tlearn: 265989.2873957\ttotal: 3.06s\tremaining: 469ms\n",
      "867:\tlearn: 265989.2479645\ttotal: 3.06s\tremaining: 465ms\n",
      "868:\tlearn: 265989.2296373\ttotal: 3.06s\tremaining: 461ms\n",
      "869:\tlearn: 265989.1770738\ttotal: 3.06s\tremaining: 458ms\n",
      "870:\tlearn: 265989.1638569\ttotal: 3.07s\tremaining: 454ms\n",
      "871:\tlearn: 265989.1424981\ttotal: 3.07s\tremaining: 451ms\n",
      "872:\tlearn: 265989.1361993\ttotal: 3.07s\tremaining: 447ms\n",
      "873:\tlearn: 265989.1282235\ttotal: 3.07s\tremaining: 443ms\n",
      "874:\tlearn: 265989.1216298\ttotal: 3.08s\tremaining: 440ms\n",
      "875:\tlearn: 265989.0795759\ttotal: 3.08s\tremaining: 436ms\n",
      "876:\tlearn: 265989.0741668\ttotal: 3.08s\tremaining: 433ms\n",
      "877:\tlearn: 265989.0492268\ttotal: 3.09s\tremaining: 429ms\n",
      "878:\tlearn: 265989.0306512\ttotal: 3.09s\tremaining: 425ms\n",
      "879:\tlearn: 265989.0026594\ttotal: 3.09s\tremaining: 422ms\n",
      "880:\tlearn: 265988.9967685\ttotal: 3.1s\tremaining: 418ms\n",
      "881:\tlearn: 265988.9925813\ttotal: 3.1s\tremaining: 415ms\n",
      "882:\tlearn: 265988.9886456\ttotal: 3.1s\tremaining: 411ms\n",
      "883:\tlearn: 265988.9632575\ttotal: 3.1s\tremaining: 407ms\n",
      "884:\tlearn: 265988.9595595\ttotal: 3.11s\tremaining: 404ms\n",
      "885:\tlearn: 265988.9283568\ttotal: 3.11s\tremaining: 400ms\n",
      "886:\tlearn: 265988.9034488\ttotal: 3.11s\tremaining: 397ms\n",
      "887:\tlearn: 265988.8785730\ttotal: 3.12s\tremaining: 393ms\n",
      "888:\tlearn: 265988.8750984\ttotal: 3.12s\tremaining: 389ms\n",
      "889:\tlearn: 265988.8326763\ttotal: 3.12s\tremaining: 386ms\n",
      "890:\tlearn: 265988.8293703\ttotal: 3.12s\tremaining: 382ms\n",
      "891:\tlearn: 265988.7884424\ttotal: 3.13s\tremaining: 379ms\n",
      "892:\tlearn: 265988.7596591\ttotal: 3.13s\tremaining: 375ms\n",
      "893:\tlearn: 265988.7447312\ttotal: 3.13s\tremaining: 372ms\n",
      "894:\tlearn: 265988.7416219\ttotal: 3.14s\tremaining: 368ms\n",
      "895:\tlearn: 265988.7387049\ttotal: 3.14s\tremaining: 364ms\n",
      "896:\tlearn: 265988.7208250\ttotal: 3.14s\tremaining: 361ms\n",
      "897:\tlearn: 265988.7118166\ttotal: 3.15s\tremaining: 357ms\n",
      "898:\tlearn: 265988.6977417\ttotal: 3.15s\tremaining: 354ms\n",
      "899:\tlearn: 265988.6607956\ttotal: 3.15s\tremaining: 350ms\n",
      "900:\tlearn: 265988.6579373\ttotal: 3.15s\tremaining: 346ms\n",
      "901:\tlearn: 265988.6526230\ttotal: 3.15s\tremaining: 343ms\n",
      "902:\tlearn: 265988.6370394\ttotal: 3.16s\tremaining: 339ms\n",
      "903:\tlearn: 265988.6078986\ttotal: 3.16s\tremaining: 336ms\n",
      "904:\tlearn: 265988.5769395\ttotal: 3.16s\tremaining: 332ms\n",
      "905:\tlearn: 265988.5736429\ttotal: 3.17s\tremaining: 329ms\n",
      "906:\tlearn: 265988.5525193\ttotal: 3.17s\tremaining: 325ms\n",
      "907:\tlearn: 265988.5166584\ttotal: 3.17s\tremaining: 322ms\n",
      "908:\tlearn: 265988.4840769\ttotal: 3.18s\tremaining: 318ms\n",
      "909:\tlearn: 265988.4450008\ttotal: 3.18s\tremaining: 314ms\n",
      "910:\tlearn: 265988.4299291\ttotal: 3.18s\tremaining: 311ms\n",
      "911:\tlearn: 265988.4147017\ttotal: 3.18s\tremaining: 307ms\n",
      "912:\tlearn: 265988.4116399\ttotal: 3.19s\tremaining: 304ms\n",
      "913:\tlearn: 265988.3900792\ttotal: 3.19s\tremaining: 300ms\n",
      "914:\tlearn: 265988.3593793\ttotal: 3.19s\tremaining: 297ms\n",
      "915:\tlearn: 265988.3329368\ttotal: 3.2s\tremaining: 293ms\n",
      "916:\tlearn: 265988.3180150\ttotal: 3.2s\tremaining: 290ms\n",
      "917:\tlearn: 265988.2878961\ttotal: 3.21s\tremaining: 286ms\n",
      "918:\tlearn: 265988.2790067\ttotal: 3.21s\tremaining: 283ms\n",
      "919:\tlearn: 265988.2543500\ttotal: 3.21s\tremaining: 279ms\n",
      "920:\tlearn: 265988.2296213\ttotal: 3.22s\tremaining: 276ms\n",
      "921:\tlearn: 265988.2116384\ttotal: 3.22s\tremaining: 273ms\n",
      "922:\tlearn: 265988.1989884\ttotal: 3.22s\tremaining: 269ms\n",
      "923:\tlearn: 265988.1769241\ttotal: 3.23s\tremaining: 265ms\n",
      "924:\tlearn: 265988.1721670\ttotal: 3.23s\tremaining: 262ms\n",
      "925:\tlearn: 265988.1619479\ttotal: 3.23s\tremaining: 258ms\n",
      "926:\tlearn: 265988.1409268\ttotal: 3.28s\tremaining: 259ms\n",
      "927:\tlearn: 265988.1326568\ttotal: 3.3s\tremaining: 256ms\n",
      "928:\tlearn: 265988.1170573\ttotal: 3.31s\tremaining: 253ms\n",
      "929:\tlearn: 265988.0896421\ttotal: 3.31s\tremaining: 249ms\n",
      "930:\tlearn: 265988.0738215\ttotal: 3.31s\tremaining: 246ms\n",
      "931:\tlearn: 265988.0462138\ttotal: 3.32s\tremaining: 243ms\n",
      "932:\tlearn: 265988.0192181\ttotal: 3.33s\tremaining: 239ms\n",
      "933:\tlearn: 265988.0095560\ttotal: 3.34s\tremaining: 236ms\n",
      "934:\tlearn: 265987.9880404\ttotal: 3.34s\tremaining: 232ms\n",
      "935:\tlearn: 265987.9750405\ttotal: 3.34s\tremaining: 229ms\n",
      "936:\tlearn: 265987.9464682\ttotal: 3.34s\tremaining: 225ms\n",
      "937:\tlearn: 265987.9204915\ttotal: 3.35s\tremaining: 221ms\n",
      "938:\tlearn: 265987.9082561\ttotal: 3.35s\tremaining: 218ms\n",
      "939:\tlearn: 265987.8927221\ttotal: 3.35s\tremaining: 214ms\n",
      "940:\tlearn: 265987.8629873\ttotal: 3.36s\tremaining: 211ms\n",
      "941:\tlearn: 265987.8472972\ttotal: 3.36s\tremaining: 207ms\n",
      "942:\tlearn: 265987.8178462\ttotal: 3.36s\tremaining: 203ms\n",
      "943:\tlearn: 265987.7938044\ttotal: 3.37s\tremaining: 200ms\n",
      "944:\tlearn: 265987.7807083\ttotal: 3.37s\tremaining: 196ms\n",
      "945:\tlearn: 265987.7690557\ttotal: 3.37s\tremaining: 193ms\n",
      "946:\tlearn: 265987.7567660\ttotal: 3.38s\tremaining: 189ms\n",
      "947:\tlearn: 265987.7369555\ttotal: 3.38s\tremaining: 185ms\n",
      "948:\tlearn: 265987.7187887\ttotal: 3.38s\tremaining: 182ms\n",
      "949:\tlearn: 265987.7044576\ttotal: 3.39s\tremaining: 178ms\n",
      "950:\tlearn: 265987.6877597\ttotal: 3.39s\tremaining: 175ms\n",
      "951:\tlearn: 265987.6696467\ttotal: 3.39s\tremaining: 171ms\n",
      "952:\tlearn: 265987.6495323\ttotal: 3.39s\tremaining: 167ms\n",
      "953:\tlearn: 265987.6289523\ttotal: 3.4s\tremaining: 164ms\n",
      "954:\tlearn: 265987.6220042\ttotal: 3.4s\tremaining: 160ms\n",
      "955:\tlearn: 265987.5960500\ttotal: 3.4s\tremaining: 157ms\n",
      "956:\tlearn: 265987.5915539\ttotal: 3.41s\tremaining: 153ms\n",
      "957:\tlearn: 265987.5813290\ttotal: 3.41s\tremaining: 150ms\n",
      "958:\tlearn: 265987.5682819\ttotal: 3.42s\tremaining: 146ms\n",
      "959:\tlearn: 265987.5555635\ttotal: 3.42s\tremaining: 143ms\n",
      "960:\tlearn: 265987.5360408\ttotal: 3.42s\tremaining: 139ms\n",
      "961:\tlearn: 265987.5157171\ttotal: 3.43s\tremaining: 135ms\n",
      "962:\tlearn: 265987.5046183\ttotal: 3.43s\tremaining: 132ms\n",
      "963:\tlearn: 265987.5003901\ttotal: 3.44s\tremaining: 128ms\n",
      "964:\tlearn: 265987.4791624\ttotal: 3.44s\tremaining: 125ms\n",
      "965:\tlearn: 265987.4595800\ttotal: 3.44s\tremaining: 121ms\n",
      "966:\tlearn: 265987.4510129\ttotal: 3.45s\tremaining: 118ms\n",
      "967:\tlearn: 265987.4376457\ttotal: 3.45s\tremaining: 114ms\n",
      "968:\tlearn: 265987.4324279\ttotal: 3.45s\tremaining: 111ms\n",
      "969:\tlearn: 265987.4022186\ttotal: 3.46s\tremaining: 107ms\n",
      "970:\tlearn: 265987.3985194\ttotal: 3.46s\tremaining: 103ms\n",
      "971:\tlearn: 265987.3801711\ttotal: 3.46s\tremaining: 99.8ms\n",
      "972:\tlearn: 265987.3759888\ttotal: 3.47s\tremaining: 96.2ms\n",
      "973:\tlearn: 265987.3724956\ttotal: 3.47s\tremaining: 92.7ms\n",
      "974:\tlearn: 265987.3548850\ttotal: 3.48s\tremaining: 89.1ms\n",
      "975:\tlearn: 265987.3399078\ttotal: 3.48s\tremaining: 85.6ms\n",
      "976:\tlearn: 265987.3346091\ttotal: 3.48s\tremaining: 82ms\n",
      "977:\tlearn: 265987.3143837\ttotal: 3.48s\tremaining: 78.4ms\n",
      "978:\tlearn: 265987.3006986\ttotal: 3.49s\tremaining: 74.8ms\n",
      "979:\tlearn: 265987.2838733\ttotal: 3.49s\tremaining: 71.3ms\n",
      "980:\tlearn: 265987.2692822\ttotal: 3.5s\tremaining: 67.7ms\n",
      "981:\tlearn: 265987.2430555\ttotal: 3.5s\tremaining: 64.1ms\n",
      "982:\tlearn: 265987.2222555\ttotal: 3.5s\tremaining: 60.6ms\n",
      "983:\tlearn: 265987.2164773\ttotal: 3.51s\tremaining: 57ms\n",
      "984:\tlearn: 265987.1905627\ttotal: 3.51s\tremaining: 53.5ms\n",
      "985:\tlearn: 265987.1869961\ttotal: 3.51s\tremaining: 49.9ms\n",
      "986:\tlearn: 265987.1640726\ttotal: 3.52s\tremaining: 46.3ms\n",
      "987:\tlearn: 265987.1476959\ttotal: 3.52s\tremaining: 42.8ms\n",
      "988:\tlearn: 265987.1413806\ttotal: 3.52s\tremaining: 39.2ms\n",
      "989:\tlearn: 265987.1376420\ttotal: 3.53s\tremaining: 35.6ms\n",
      "990:\tlearn: 265987.1303896\ttotal: 3.53s\tremaining: 32.1ms\n",
      "991:\tlearn: 265987.1265805\ttotal: 3.53s\tremaining: 28.5ms\n",
      "992:\tlearn: 265987.1229508\ttotal: 3.54s\tremaining: 24.9ms\n",
      "993:\tlearn: 265987.1103022\ttotal: 3.54s\tremaining: 21.4ms\n",
      "994:\tlearn: 265987.0914734\ttotal: 3.54s\tremaining: 17.8ms\n",
      "995:\tlearn: 265987.0756669\ttotal: 3.55s\tremaining: 14.2ms\n",
      "996:\tlearn: 265987.0506224\ttotal: 3.55s\tremaining: 10.7ms\n",
      "997:\tlearn: 265987.0271272\ttotal: 3.56s\tremaining: 7.13ms\n",
      "998:\tlearn: 265987.0069348\ttotal: 3.56s\tremaining: 3.56ms\n",
      "999:\tlearn: 265986.9915201\ttotal: 3.56s\tremaining: 0us\n",
      "Prediction for 2027 using CatBoost completed and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor  # Import CatBoostRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=1000, learning_rate=0.1)  # You can adjust hyperparameters as needed\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2027\n",
    "prediction_2027 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2027[prediction_2027 < 0] = 0\n",
    "\n",
    "# Add the predicted '2027' column to the DataFrame\n",
    "df['2027'] = prediction_2027\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv', index=False)\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(\"Prediction for 2027 using CatBoost completed and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 979179.8920277\ttotal: 7.35ms\tremaining: 7.34s\n",
      "1:\tlearn: 921591.5985084\ttotal: 10.3ms\tremaining: 5.14s\n",
      "2:\tlearn: 871873.9750293\ttotal: 13.1ms\tremaining: 4.37s\n",
      "3:\tlearn: 826987.5344509\ttotal: 16.3ms\tremaining: 4.05s\n",
      "4:\tlearn: 783420.9207121\ttotal: 20.6ms\tremaining: 4.09s\n",
      "5:\tlearn: 744278.8261384\ttotal: 23.6ms\tremaining: 3.91s\n",
      "6:\tlearn: 704278.0530842\ttotal: 30.1ms\tremaining: 4.27s\n",
      "7:\tlearn: 672382.9431120\ttotal: 35.9ms\tremaining: 4.45s\n",
      "8:\tlearn: 640134.0734349\ttotal: 39.6ms\tremaining: 4.36s\n",
      "9:\tlearn: 607782.2317375\ttotal: 60.2ms\tremaining: 5.96s\n",
      "10:\tlearn: 581870.9007924\ttotal: 72.7ms\tremaining: 6.54s\n",
      "11:\tlearn: 556718.2754024\ttotal: 82.8ms\tremaining: 6.82s\n",
      "12:\tlearn: 533971.4677114\ttotal: 92.8ms\tremaining: 7.04s\n",
      "13:\tlearn: 513123.0912206\ttotal: 107ms\tremaining: 7.55s\n",
      "14:\tlearn: 491806.8823206\ttotal: 110ms\tremaining: 7.25s\n",
      "15:\tlearn: 473535.1243897\ttotal: 119ms\tremaining: 7.3s\n",
      "16:\tlearn: 457298.3208269\ttotal: 121ms\tremaining: 7.01s\n",
      "17:\tlearn: 442285.7633968\ttotal: 124ms\tremaining: 6.76s\n",
      "18:\tlearn: 428851.8055571\ttotal: 127ms\tremaining: 6.54s\n",
      "19:\tlearn: 415949.0736616\ttotal: 132ms\tremaining: 6.49s\n",
      "20:\tlearn: 404738.5107253\ttotal: 137ms\tremaining: 6.39s\n",
      "21:\tlearn: 393335.3616949\ttotal: 143ms\tremaining: 6.37s\n",
      "22:\tlearn: 383026.0098760\ttotal: 147ms\tremaining: 6.25s\n",
      "23:\tlearn: 373872.5913929\ttotal: 151ms\tremaining: 6.14s\n",
      "24:\tlearn: 365165.5328144\ttotal: 154ms\tremaining: 6.02s\n",
      "25:\tlearn: 357552.2996492\ttotal: 157ms\tremaining: 5.87s\n",
      "26:\tlearn: 349747.7401626\ttotal: 160ms\tremaining: 5.76s\n",
      "27:\tlearn: 343051.2771388\ttotal: 164ms\tremaining: 5.68s\n",
      "28:\tlearn: 336817.8224925\ttotal: 166ms\tremaining: 5.56s\n",
      "29:\tlearn: 330734.3737856\ttotal: 169ms\tremaining: 5.46s\n",
      "30:\tlearn: 325618.6238608\ttotal: 171ms\tremaining: 5.36s\n",
      "31:\tlearn: 320992.9650089\ttotal: 174ms\tremaining: 5.25s\n",
      "32:\tlearn: 317040.0762668\ttotal: 177ms\tremaining: 5.17s\n",
      "33:\tlearn: 313181.6163004\ttotal: 180ms\tremaining: 5.12s\n",
      "34:\tlearn: 309220.5227349\ttotal: 183ms\tremaining: 5.04s\n",
      "35:\tlearn: 306091.9999137\ttotal: 185ms\tremaining: 4.95s\n",
      "36:\tlearn: 302718.8220238\ttotal: 187ms\tremaining: 4.87s\n",
      "37:\tlearn: 299803.2637459\ttotal: 190ms\tremaining: 4.8s\n",
      "38:\tlearn: 297454.7502609\ttotal: 192ms\tremaining: 4.74s\n",
      "39:\tlearn: 294704.7482936\ttotal: 195ms\tremaining: 4.69s\n",
      "40:\tlearn: 292608.6175285\ttotal: 200ms\tremaining: 4.67s\n",
      "41:\tlearn: 290873.5167104\ttotal: 202ms\tremaining: 4.61s\n",
      "42:\tlearn: 288955.1961696\ttotal: 204ms\tremaining: 4.55s\n",
      "43:\tlearn: 287566.8681704\ttotal: 207ms\tremaining: 4.49s\n",
      "44:\tlearn: 286383.6716369\ttotal: 211ms\tremaining: 4.49s\n",
      "45:\tlearn: 284924.0675215\ttotal: 215ms\tremaining: 4.46s\n",
      "46:\tlearn: 283702.6431186\ttotal: 217ms\tremaining: 4.41s\n",
      "47:\tlearn: 282758.0997124\ttotal: 220ms\tremaining: 4.36s\n",
      "48:\tlearn: 281510.7979746\ttotal: 222ms\tremaining: 4.3s\n",
      "49:\tlearn: 280579.0285719\ttotal: 226ms\tremaining: 4.29s\n",
      "50:\tlearn: 279675.7819018\ttotal: 230ms\tremaining: 4.27s\n",
      "51:\tlearn: 278849.1018393\ttotal: 233ms\tremaining: 4.24s\n",
      "52:\tlearn: 278042.9412373\ttotal: 235ms\tremaining: 4.21s\n",
      "53:\tlearn: 277376.1090633\ttotal: 239ms\tremaining: 4.19s\n",
      "54:\tlearn: 276789.4110645\ttotal: 243ms\tremaining: 4.18s\n",
      "55:\tlearn: 276207.1246811\ttotal: 247ms\tremaining: 4.16s\n",
      "56:\tlearn: 275790.8178015\ttotal: 252ms\tremaining: 4.16s\n",
      "57:\tlearn: 275261.5873104\ttotal: 256ms\tremaining: 4.15s\n",
      "58:\tlearn: 274781.7486800\ttotal: 260ms\tremaining: 4.14s\n",
      "59:\tlearn: 274373.3867132\ttotal: 263ms\tremaining: 4.12s\n",
      "60:\tlearn: 274032.1796981\ttotal: 266ms\tremaining: 4.09s\n",
      "61:\tlearn: 273693.3069259\ttotal: 269ms\tremaining: 4.07s\n",
      "62:\tlearn: 273405.1144592\ttotal: 274ms\tremaining: 4.08s\n",
      "63:\tlearn: 273064.7211588\ttotal: 278ms\tremaining: 4.06s\n",
      "64:\tlearn: 272818.6281346\ttotal: 280ms\tremaining: 4.03s\n",
      "65:\tlearn: 272471.5207205\ttotal: 283ms\tremaining: 4s\n",
      "66:\tlearn: 272237.9439144\ttotal: 288ms\tremaining: 4.01s\n",
      "67:\tlearn: 272009.6862545\ttotal: 292ms\tremaining: 4s\n",
      "68:\tlearn: 271795.5152660\ttotal: 295ms\tremaining: 3.98s\n",
      "69:\tlearn: 271667.6369771\ttotal: 298ms\tremaining: 3.96s\n",
      "70:\tlearn: 271554.1993751\ttotal: 300ms\tremaining: 3.93s\n",
      "71:\tlearn: 271455.0256051\ttotal: 304ms\tremaining: 3.92s\n",
      "72:\tlearn: 271278.6493627\ttotal: 307ms\tremaining: 3.9s\n",
      "73:\tlearn: 271022.3205174\ttotal: 309ms\tremaining: 3.87s\n",
      "74:\tlearn: 270850.6957066\ttotal: 311ms\tremaining: 3.84s\n",
      "75:\tlearn: 270763.1740064\ttotal: 313ms\tremaining: 3.81s\n",
      "76:\tlearn: 270556.7330696\ttotal: 319ms\tremaining: 3.82s\n",
      "77:\tlearn: 270345.3827093\ttotal: 321ms\tremaining: 3.79s\n",
      "78:\tlearn: 270243.2258855\ttotal: 323ms\tremaining: 3.77s\n",
      "79:\tlearn: 270081.2089895\ttotal: 325ms\tremaining: 3.74s\n",
      "80:\tlearn: 269953.1693637\ttotal: 328ms\tremaining: 3.71s\n",
      "81:\tlearn: 269817.0113895\ttotal: 330ms\tremaining: 3.69s\n",
      "82:\tlearn: 269663.7687159\ttotal: 333ms\tremaining: 3.67s\n",
      "83:\tlearn: 269538.9352312\ttotal: 336ms\tremaining: 3.66s\n",
      "84:\tlearn: 269420.2891451\ttotal: 338ms\tremaining: 3.64s\n",
      "85:\tlearn: 269300.4605773\ttotal: 340ms\tremaining: 3.62s\n",
      "86:\tlearn: 269150.1051557\ttotal: 342ms\tremaining: 3.59s\n",
      "87:\tlearn: 269026.3325807\ttotal: 345ms\tremaining: 3.58s\n",
      "88:\tlearn: 268942.9988244\ttotal: 347ms\tremaining: 3.55s\n",
      "89:\tlearn: 268836.6923492\ttotal: 352ms\tremaining: 3.56s\n",
      "90:\tlearn: 268769.4902537\ttotal: 354ms\tremaining: 3.54s\n",
      "91:\tlearn: 268692.8303575\ttotal: 357ms\tremaining: 3.52s\n",
      "92:\tlearn: 268660.3938791\ttotal: 359ms\tremaining: 3.5s\n",
      "93:\tlearn: 268578.1784545\ttotal: 361ms\tremaining: 3.48s\n",
      "94:\tlearn: 268492.0457159\ttotal: 365ms\tremaining: 3.48s\n",
      "95:\tlearn: 268404.8620252\ttotal: 368ms\tremaining: 3.46s\n",
      "96:\tlearn: 268347.7233210\ttotal: 370ms\tremaining: 3.44s\n",
      "97:\tlearn: 268285.8495199\ttotal: 372ms\tremaining: 3.42s\n",
      "98:\tlearn: 268222.0746107\ttotal: 375ms\tremaining: 3.41s\n",
      "99:\tlearn: 268150.5642304\ttotal: 377ms\tremaining: 3.39s\n",
      "100:\tlearn: 268104.3208822\ttotal: 379ms\tremaining: 3.37s\n",
      "101:\tlearn: 268044.6582355\ttotal: 382ms\tremaining: 3.37s\n",
      "102:\tlearn: 268013.1932657\ttotal: 385ms\tremaining: 3.35s\n",
      "103:\tlearn: 267943.4716843\ttotal: 387ms\tremaining: 3.33s\n",
      "104:\tlearn: 267883.7447395\ttotal: 389ms\tremaining: 3.32s\n",
      "105:\tlearn: 267836.9043218\ttotal: 391ms\tremaining: 3.3s\n",
      "106:\tlearn: 267769.4382370\ttotal: 394ms\tremaining: 3.28s\n",
      "107:\tlearn: 267730.6944987\ttotal: 398ms\tremaining: 3.28s\n",
      "108:\tlearn: 267688.2003818\ttotal: 400ms\tremaining: 3.27s\n",
      "109:\tlearn: 267635.5126847\ttotal: 403ms\tremaining: 3.26s\n",
      "110:\tlearn: 267592.1477155\ttotal: 406ms\tremaining: 3.25s\n",
      "111:\tlearn: 267549.3837924\ttotal: 412ms\tremaining: 3.27s\n",
      "112:\tlearn: 267507.7294258\ttotal: 415ms\tremaining: 3.26s\n",
      "113:\tlearn: 267463.4179352\ttotal: 419ms\tremaining: 3.26s\n",
      "114:\tlearn: 267425.3286206\ttotal: 422ms\tremaining: 3.25s\n",
      "115:\tlearn: 267381.3453465\ttotal: 425ms\tremaining: 3.24s\n",
      "116:\tlearn: 267346.6439549\ttotal: 429ms\tremaining: 3.24s\n",
      "117:\tlearn: 267316.5586886\ttotal: 433ms\tremaining: 3.24s\n",
      "118:\tlearn: 267290.1892590\ttotal: 436ms\tremaining: 3.22s\n",
      "119:\tlearn: 267268.7535346\ttotal: 438ms\tremaining: 3.21s\n",
      "120:\tlearn: 267236.7662134\ttotal: 441ms\tremaining: 3.2s\n",
      "121:\tlearn: 267213.3158430\ttotal: 446ms\tremaining: 3.21s\n",
      "122:\tlearn: 267185.0165342\ttotal: 449ms\tremaining: 3.2s\n",
      "123:\tlearn: 267158.3654503\ttotal: 452ms\tremaining: 3.19s\n",
      "124:\tlearn: 267136.4565513\ttotal: 454ms\tremaining: 3.18s\n",
      "125:\tlearn: 267110.5013523\ttotal: 458ms\tremaining: 3.17s\n",
      "126:\tlearn: 267088.4547250\ttotal: 462ms\tremaining: 3.17s\n",
      "127:\tlearn: 267068.9508012\ttotal: 465ms\tremaining: 3.17s\n",
      "128:\tlearn: 267044.6453466\ttotal: 467ms\tremaining: 3.15s\n",
      "129:\tlearn: 267021.6472702\ttotal: 470ms\tremaining: 3.15s\n",
      "130:\tlearn: 266999.8820424\ttotal: 473ms\tremaining: 3.14s\n",
      "131:\tlearn: 266982.9564431\ttotal: 478ms\tremaining: 3.14s\n",
      "132:\tlearn: 266960.5841967\ttotal: 482ms\tremaining: 3.14s\n",
      "133:\tlearn: 266946.1889745\ttotal: 486ms\tremaining: 3.14s\n",
      "134:\tlearn: 266929.8717523\ttotal: 490ms\tremaining: 3.14s\n",
      "135:\tlearn: 266917.0852438\ttotal: 493ms\tremaining: 3.13s\n",
      "136:\tlearn: 266898.5417362\ttotal: 527ms\tremaining: 3.32s\n",
      "137:\tlearn: 266878.2833578\ttotal: 537ms\tremaining: 3.35s\n",
      "138:\tlearn: 266860.6556550\ttotal: 559ms\tremaining: 3.46s\n",
      "139:\tlearn: 266844.6952904\ttotal: 562ms\tremaining: 3.45s\n",
      "140:\tlearn: 266829.9226998\ttotal: 564ms\tremaining: 3.44s\n",
      "141:\tlearn: 266811.7195142\ttotal: 567ms\tremaining: 3.42s\n",
      "142:\tlearn: 266795.6212509\ttotal: 571ms\tremaining: 3.42s\n",
      "143:\tlearn: 266780.3867963\ttotal: 576ms\tremaining: 3.42s\n",
      "144:\tlearn: 266768.6515265\ttotal: 581ms\tremaining: 3.43s\n",
      "145:\tlearn: 266759.5816184\ttotal: 585ms\tremaining: 3.42s\n",
      "146:\tlearn: 266746.4232872\ttotal: 589ms\tremaining: 3.42s\n",
      "147:\tlearn: 266735.9558767\ttotal: 592ms\tremaining: 3.41s\n",
      "148:\tlearn: 266726.0932455\ttotal: 595ms\tremaining: 3.4s\n",
      "149:\tlearn: 266718.4112002\ttotal: 597ms\tremaining: 3.38s\n",
      "150:\tlearn: 266710.3488533\ttotal: 599ms\tremaining: 3.37s\n",
      "151:\tlearn: 266701.8860010\ttotal: 604ms\tremaining: 3.37s\n",
      "152:\tlearn: 266695.3305715\ttotal: 606ms\tremaining: 3.36s\n",
      "153:\tlearn: 266681.5722152\ttotal: 609ms\tremaining: 3.35s\n",
      "154:\tlearn: 266669.8474088\ttotal: 613ms\tremaining: 3.34s\n",
      "155:\tlearn: 266664.2533194\ttotal: 615ms\tremaining: 3.33s\n",
      "156:\tlearn: 266659.2528640\ttotal: 617ms\tremaining: 3.31s\n",
      "157:\tlearn: 266653.4949982\ttotal: 620ms\tremaining: 3.31s\n",
      "158:\tlearn: 266642.0590221\ttotal: 625ms\tremaining: 3.3s\n",
      "159:\tlearn: 266637.2711830\ttotal: 627ms\tremaining: 3.29s\n",
      "160:\tlearn: 266632.5513190\ttotal: 629ms\tremaining: 3.28s\n",
      "161:\tlearn: 266621.9379586\ttotal: 633ms\tremaining: 3.27s\n",
      "162:\tlearn: 266617.4676052\ttotal: 637ms\tremaining: 3.27s\n",
      "163:\tlearn: 266604.0494691\ttotal: 639ms\tremaining: 3.26s\n",
      "164:\tlearn: 266600.1891758\ttotal: 640ms\tremaining: 3.24s\n",
      "165:\tlearn: 266595.3806947\ttotal: 643ms\tremaining: 3.23s\n",
      "166:\tlearn: 266588.5476036\ttotal: 645ms\tremaining: 3.22s\n",
      "167:\tlearn: 266584.0062055\ttotal: 650ms\tremaining: 3.22s\n",
      "168:\tlearn: 266573.6141726\ttotal: 653ms\tremaining: 3.21s\n",
      "169:\tlearn: 266570.2993680\ttotal: 655ms\tremaining: 3.19s\n",
      "170:\tlearn: 266566.1623586\ttotal: 657ms\tremaining: 3.18s\n",
      "171:\tlearn: 266559.7395684\ttotal: 659ms\tremaining: 3.17s\n",
      "172:\tlearn: 266553.3245288\ttotal: 662ms\tremaining: 3.16s\n",
      "173:\tlearn: 266547.2739922\ttotal: 667ms\tremaining: 3.17s\n",
      "174:\tlearn: 266543.4215365\ttotal: 670ms\tremaining: 3.16s\n",
      "175:\tlearn: 266535.1984192\ttotal: 673ms\tremaining: 3.15s\n",
      "176:\tlearn: 266529.0392186\ttotal: 676ms\tremaining: 3.14s\n",
      "177:\tlearn: 266520.2816471\ttotal: 678ms\tremaining: 3.13s\n",
      "178:\tlearn: 266516.8161146\ttotal: 683ms\tremaining: 3.13s\n",
      "179:\tlearn: 266513.5324838\ttotal: 685ms\tremaining: 3.12s\n",
      "180:\tlearn: 266507.9219548\ttotal: 687ms\tremaining: 3.11s\n",
      "181:\tlearn: 266498.9728396\ttotal: 690ms\tremaining: 3.1s\n",
      "182:\tlearn: 266489.6966630\ttotal: 692ms\tremaining: 3.09s\n",
      "183:\tlearn: 266485.6571738\ttotal: 694ms\tremaining: 3.08s\n",
      "184:\tlearn: 266481.8871902\ttotal: 698ms\tremaining: 3.08s\n",
      "185:\tlearn: 266479.6787369\ttotal: 700ms\tremaining: 3.06s\n",
      "186:\tlearn: 266472.8031175\ttotal: 702ms\tremaining: 3.05s\n",
      "187:\tlearn: 266466.8020783\ttotal: 704ms\tremaining: 3.04s\n",
      "188:\tlearn: 266458.7188834\ttotal: 706ms\tremaining: 3.03s\n",
      "189:\tlearn: 266454.9970539\ttotal: 708ms\tremaining: 3.02s\n",
      "190:\tlearn: 266448.0712834\ttotal: 713ms\tremaining: 3.02s\n",
      "191:\tlearn: 266446.1132954\ttotal: 715ms\tremaining: 3.01s\n",
      "192:\tlearn: 266438.7449675\ttotal: 717ms\tremaining: 3s\n",
      "193:\tlearn: 266436.6508892\ttotal: 719ms\tremaining: 2.99s\n",
      "194:\tlearn: 266430.1313523\ttotal: 722ms\tremaining: 2.98s\n",
      "195:\tlearn: 266428.1542082\ttotal: 724ms\tremaining: 2.97s\n",
      "196:\tlearn: 266426.2767739\ttotal: 728ms\tremaining: 2.97s\n",
      "197:\tlearn: 266421.1246482\ttotal: 731ms\tremaining: 2.96s\n",
      "198:\tlearn: 266416.3877759\ttotal: 734ms\tremaining: 2.95s\n",
      "199:\tlearn: 266414.6081769\ttotal: 736ms\tremaining: 2.94s\n",
      "200:\tlearn: 266408.3167103\ttotal: 738ms\tremaining: 2.93s\n",
      "201:\tlearn: 266400.0325963\ttotal: 740ms\tremaining: 2.92s\n",
      "202:\tlearn: 266398.4138453\ttotal: 745ms\tremaining: 2.92s\n",
      "203:\tlearn: 266392.2180507\ttotal: 748ms\tremaining: 2.92s\n",
      "204:\tlearn: 266390.6806425\ttotal: 750ms\tremaining: 2.91s\n",
      "205:\tlearn: 266386.9145213\ttotal: 752ms\tremaining: 2.9s\n",
      "206:\tlearn: 266385.5709919\ttotal: 754ms\tremaining: 2.89s\n",
      "207:\tlearn: 266381.6431105\ttotal: 757ms\tremaining: 2.88s\n",
      "208:\tlearn: 266374.7449340\ttotal: 762ms\tremaining: 2.88s\n",
      "209:\tlearn: 266369.2187724\ttotal: 764ms\tremaining: 2.87s\n",
      "210:\tlearn: 266365.8149637\ttotal: 766ms\tremaining: 2.87s\n",
      "211:\tlearn: 266364.7127554\ttotal: 767ms\tremaining: 2.85s\n",
      "212:\tlearn: 266357.4985675\ttotal: 770ms\tremaining: 2.84s\n",
      "213:\tlearn: 266354.3348639\ttotal: 772ms\tremaining: 2.83s\n",
      "214:\tlearn: 266351.3325397\ttotal: 776ms\tremaining: 2.83s\n",
      "215:\tlearn: 266345.3901920\ttotal: 779ms\tremaining: 2.83s\n",
      "216:\tlearn: 266342.5385494\ttotal: 781ms\tremaining: 2.82s\n",
      "217:\tlearn: 266336.6460899\ttotal: 783ms\tremaining: 2.81s\n",
      "218:\tlearn: 266332.1184947\ttotal: 786ms\tremaining: 2.8s\n",
      "219:\tlearn: 266326.2638309\ttotal: 788ms\tremaining: 2.79s\n",
      "220:\tlearn: 266319.6874394\ttotal: 793ms\tremaining: 2.79s\n",
      "221:\tlearn: 266315.5023120\ttotal: 795ms\tremaining: 2.79s\n",
      "222:\tlearn: 266310.9886471\ttotal: 797ms\tremaining: 2.78s\n",
      "223:\tlearn: 266306.2232762\ttotal: 801ms\tremaining: 2.77s\n",
      "224:\tlearn: 266301.3874718\ttotal: 804ms\tremaining: 2.77s\n",
      "225:\tlearn: 266296.9852516\ttotal: 807ms\tremaining: 2.77s\n",
      "226:\tlearn: 266296.0155922\ttotal: 812ms\tremaining: 2.77s\n",
      "227:\tlearn: 266291.9451081\ttotal: 815ms\tremaining: 2.76s\n",
      "228:\tlearn: 266291.0251323\ttotal: 818ms\tremaining: 2.75s\n",
      "229:\tlearn: 266290.1521827\ttotal: 823ms\tremaining: 2.76s\n",
      "230:\tlearn: 266284.9237081\ttotal: 827ms\tremaining: 2.75s\n",
      "231:\tlearn: 266284.1175024\ttotal: 830ms\tremaining: 2.75s\n",
      "232:\tlearn: 266280.3176052\ttotal: 834ms\tremaining: 2.74s\n",
      "233:\tlearn: 266279.5528582\ttotal: 838ms\tremaining: 2.74s\n",
      "234:\tlearn: 266274.7989515\ttotal: 841ms\tremaining: 2.74s\n",
      "235:\tlearn: 266271.4639494\ttotal: 844ms\tremaining: 2.73s\n",
      "236:\tlearn: 266268.1309351\ttotal: 847ms\tremaining: 2.73s\n",
      "237:\tlearn: 266264.6996103\ttotal: 849ms\tremaining: 2.72s\n",
      "238:\tlearn: 266260.8088276\ttotal: 854ms\tremaining: 2.72s\n",
      "239:\tlearn: 266257.3946506\ttotal: 858ms\tremaining: 2.72s\n",
      "240:\tlearn: 266254.0978592\ttotal: 861ms\tremaining: 2.71s\n",
      "241:\tlearn: 266250.6991862\ttotal: 864ms\tremaining: 2.7s\n",
      "242:\tlearn: 266249.8151555\ttotal: 867ms\tremaining: 2.7s\n",
      "243:\tlearn: 266249.1266378\ttotal: 870ms\tremaining: 2.7s\n",
      "244:\tlearn: 266248.4734362\ttotal: 874ms\tremaining: 2.69s\n",
      "245:\tlearn: 266247.8536781\ttotal: 876ms\tremaining: 2.69s\n",
      "246:\tlearn: 266244.4567463\ttotal: 878ms\tremaining: 2.68s\n",
      "247:\tlearn: 266243.8705435\ttotal: 880ms\tremaining: 2.67s\n",
      "248:\tlearn: 266243.3141887\ttotal: 885ms\tremaining: 2.67s\n",
      "249:\tlearn: 266239.1070732\ttotal: 888ms\tremaining: 2.66s\n",
      "250:\tlearn: 266236.1278851\ttotal: 890ms\tremaining: 2.66s\n",
      "251:\tlearn: 266235.5978662\ttotal: 892ms\tremaining: 2.65s\n",
      "252:\tlearn: 266233.5154646\ttotal: 895ms\tremaining: 2.64s\n",
      "253:\tlearn: 266231.5504753\ttotal: 897ms\tremaining: 2.63s\n",
      "254:\tlearn: 266228.6485995\ttotal: 902ms\tremaining: 2.63s\n",
      "255:\tlearn: 266225.4985797\ttotal: 904ms\tremaining: 2.63s\n",
      "256:\tlearn: 266222.0818689\ttotal: 906ms\tremaining: 2.62s\n",
      "257:\tlearn: 266218.7255368\ttotal: 909ms\tremaining: 2.61s\n",
      "258:\tlearn: 266215.5984616\ttotal: 911ms\tremaining: 2.61s\n",
      "259:\tlearn: 266212.6509277\ttotal: 916ms\tremaining: 2.61s\n",
      "260:\tlearn: 266210.4038247\ttotal: 919ms\tremaining: 2.6s\n",
      "261:\tlearn: 266207.7867228\ttotal: 921ms\tremaining: 2.6s\n",
      "262:\tlearn: 266205.2737404\ttotal: 923ms\tremaining: 2.59s\n",
      "263:\tlearn: 266203.8274945\ttotal: 926ms\tremaining: 2.58s\n",
      "264:\tlearn: 266201.0904229\ttotal: 928ms\tremaining: 2.57s\n",
      "265:\tlearn: 266199.3668834\ttotal: 933ms\tremaining: 2.57s\n",
      "266:\tlearn: 266196.8384038\ttotal: 935ms\tremaining: 2.57s\n",
      "267:\tlearn: 266193.6621505\ttotal: 937ms\tremaining: 2.56s\n",
      "268:\tlearn: 266190.5563714\ttotal: 940ms\tremaining: 2.55s\n",
      "269:\tlearn: 266187.9155367\ttotal: 942ms\tremaining: 2.55s\n",
      "270:\tlearn: 266185.4279930\ttotal: 946ms\tremaining: 2.54s\n",
      "271:\tlearn: 266183.8281991\ttotal: 949ms\tremaining: 2.54s\n",
      "272:\tlearn: 266181.6306613\ttotal: 952ms\tremaining: 2.53s\n",
      "273:\tlearn: 266181.2080318\ttotal: 954ms\tremaining: 2.53s\n",
      "274:\tlearn: 266180.7296329\ttotal: 956ms\tremaining: 2.52s\n",
      "275:\tlearn: 266177.8919068\ttotal: 959ms\tremaining: 2.52s\n",
      "276:\tlearn: 266177.5109979\ttotal: 964ms\tremaining: 2.52s\n",
      "277:\tlearn: 266176.1076205\ttotal: 967ms\tremaining: 2.51s\n",
      "278:\tlearn: 266173.7960886\ttotal: 969ms\tremaining: 2.5s\n",
      "279:\tlearn: 266171.7879505\ttotal: 971ms\tremaining: 2.5s\n",
      "280:\tlearn: 266169.2202368\ttotal: 973ms\tremaining: 2.49s\n",
      "281:\tlearn: 266168.0366068\ttotal: 976ms\tremaining: 2.48s\n",
      "282:\tlearn: 266166.1637882\ttotal: 980ms\tremaining: 2.48s\n",
      "283:\tlearn: 266164.6341254\ttotal: 983ms\tremaining: 2.48s\n",
      "284:\tlearn: 266162.4019184\ttotal: 985ms\tremaining: 2.47s\n",
      "285:\tlearn: 266160.3428884\ttotal: 988ms\tremaining: 2.47s\n",
      "286:\tlearn: 266157.9248416\ttotal: 991ms\tremaining: 2.46s\n",
      "287:\tlearn: 266156.8860827\ttotal: 995ms\tremaining: 2.46s\n",
      "288:\tlearn: 266154.6251192\ttotal: 998ms\tremaining: 2.45s\n",
      "289:\tlearn: 266152.9451424\ttotal: 1s\tremaining: 2.45s\n",
      "290:\tlearn: 266151.1248094\ttotal: 1s\tremaining: 2.44s\n",
      "291:\tlearn: 266148.4646833\ttotal: 1s\tremaining: 2.44s\n",
      "292:\tlearn: 266146.4925356\ttotal: 1.01s\tremaining: 2.44s\n",
      "293:\tlearn: 266146.1867075\ttotal: 1.01s\tremaining: 2.43s\n",
      "294:\tlearn: 266145.8969479\ttotal: 1.02s\tremaining: 2.43s\n",
      "295:\tlearn: 266145.6223691\ttotal: 1.02s\tremaining: 2.43s\n",
      "296:\tlearn: 266144.4216895\ttotal: 1.03s\tremaining: 2.43s\n",
      "297:\tlearn: 266144.1620146\ttotal: 1.03s\tremaining: 2.43s\n",
      "298:\tlearn: 266142.4423726\ttotal: 1.03s\tremaining: 2.42s\n",
      "299:\tlearn: 266140.5524931\ttotal: 1.03s\tremaining: 2.42s\n",
      "300:\tlearn: 266139.4257090\ttotal: 1.04s\tremaining: 2.41s\n",
      "301:\tlearn: 266139.1799481\ttotal: 1.04s\tremaining: 2.41s\n",
      "302:\tlearn: 266138.3056487\ttotal: 1.04s\tremaining: 2.4s\n",
      "303:\tlearn: 266137.5451113\ttotal: 1.05s\tremaining: 2.4s\n",
      "304:\tlearn: 266135.4239069\ttotal: 1.05s\tremaining: 2.39s\n",
      "305:\tlearn: 266133.2383958\ttotal: 1.05s\tremaining: 2.39s\n",
      "306:\tlearn: 266132.2420965\ttotal: 1.06s\tremaining: 2.39s\n",
      "307:\tlearn: 266130.8952931\ttotal: 1.1s\tremaining: 2.48s\n",
      "308:\tlearn: 266129.1670898\ttotal: 1.11s\tremaining: 2.49s\n",
      "309:\tlearn: 266127.9151202\ttotal: 1.13s\tremaining: 2.51s\n",
      "310:\tlearn: 266126.1481859\ttotal: 1.13s\tremaining: 2.51s\n",
      "311:\tlearn: 266124.6788118\ttotal: 1.14s\tremaining: 2.5s\n",
      "312:\tlearn: 266122.9959978\ttotal: 1.14s\tremaining: 2.5s\n",
      "313:\tlearn: 266122.2912640\ttotal: 1.14s\tremaining: 2.5s\n",
      "314:\tlearn: 266120.5074122\ttotal: 1.15s\tremaining: 2.5s\n",
      "315:\tlearn: 266118.3428665\ttotal: 1.16s\tremaining: 2.5s\n",
      "316:\tlearn: 266116.7763871\ttotal: 1.16s\tremaining: 2.5s\n",
      "317:\tlearn: 266115.5289277\ttotal: 1.16s\tremaining: 2.5s\n",
      "318:\tlearn: 266115.3246837\ttotal: 1.17s\tremaining: 2.49s\n",
      "319:\tlearn: 266115.1309415\ttotal: 1.17s\tremaining: 2.49s\n",
      "320:\tlearn: 266113.8033970\ttotal: 1.18s\tremaining: 2.49s\n",
      "321:\tlearn: 266113.6197741\ttotal: 1.18s\tremaining: 2.48s\n",
      "322:\tlearn: 266112.2873952\ttotal: 1.18s\tremaining: 2.47s\n",
      "323:\tlearn: 266111.4996319\ttotal: 1.19s\tremaining: 2.47s\n",
      "324:\tlearn: 266110.2884708\ttotal: 1.19s\tremaining: 2.47s\n",
      "325:\tlearn: 266108.1442981\ttotal: 1.19s\tremaining: 2.46s\n",
      "326:\tlearn: 266107.1598577\ttotal: 1.19s\tremaining: 2.46s\n",
      "327:\tlearn: 266106.3206199\ttotal: 1.2s\tremaining: 2.45s\n",
      "328:\tlearn: 266105.7148491\ttotal: 1.2s\tremaining: 2.45s\n",
      "329:\tlearn: 266104.6150930\ttotal: 1.21s\tremaining: 2.45s\n",
      "330:\tlearn: 266104.0458344\ttotal: 1.21s\tremaining: 2.44s\n",
      "331:\tlearn: 266102.7759355\ttotal: 1.21s\tremaining: 2.44s\n",
      "332:\tlearn: 266101.4894492\ttotal: 1.21s\tremaining: 2.43s\n",
      "333:\tlearn: 266101.2309044\ttotal: 1.22s\tremaining: 2.43s\n",
      "334:\tlearn: 266100.2834173\ttotal: 1.22s\tremaining: 2.43s\n",
      "335:\tlearn: 266099.7522620\ttotal: 1.23s\tremaining: 2.42s\n",
      "336:\tlearn: 266099.2498391\ttotal: 1.23s\tremaining: 2.42s\n",
      "337:\tlearn: 266098.2633984\ttotal: 1.23s\tremaining: 2.42s\n",
      "338:\tlearn: 266096.9404701\ttotal: 1.24s\tremaining: 2.41s\n",
      "339:\tlearn: 266095.7097450\ttotal: 1.24s\tremaining: 2.41s\n",
      "340:\tlearn: 266094.5348914\ttotal: 1.24s\tremaining: 2.4s\n",
      "341:\tlearn: 266093.3449162\ttotal: 1.25s\tremaining: 2.4s\n",
      "342:\tlearn: 266092.3518850\ttotal: 1.25s\tremaining: 2.4s\n",
      "343:\tlearn: 266091.8975565\ttotal: 1.26s\tremaining: 2.4s\n",
      "344:\tlearn: 266091.0403339\ttotal: 1.26s\tremaining: 2.39s\n",
      "345:\tlearn: 266089.7729343\ttotal: 1.26s\tremaining: 2.39s\n",
      "346:\tlearn: 266089.2998340\ttotal: 1.27s\tremaining: 2.39s\n",
      "347:\tlearn: 266088.7668943\ttotal: 1.27s\tremaining: 2.38s\n",
      "348:\tlearn: 266087.5375000\ttotal: 1.27s\tremaining: 2.37s\n",
      "349:\tlearn: 266086.7078827\ttotal: 1.27s\tremaining: 2.37s\n",
      "350:\tlearn: 266085.8154650\ttotal: 1.28s\tremaining: 2.37s\n",
      "351:\tlearn: 266085.3882457\ttotal: 1.28s\tremaining: 2.36s\n",
      "352:\tlearn: 266084.9859508\ttotal: 1.28s\tremaining: 2.35s\n",
      "353:\tlearn: 266084.6069719\ttotal: 1.29s\tremaining: 2.35s\n",
      "354:\tlearn: 266083.5002252\ttotal: 1.29s\tremaining: 2.34s\n",
      "355:\tlearn: 266081.9976038\ttotal: 1.29s\tremaining: 2.34s\n",
      "356:\tlearn: 266081.0796606\ttotal: 1.3s\tremaining: 2.34s\n",
      "357:\tlearn: 266080.6975760\ttotal: 1.3s\tremaining: 2.33s\n",
      "358:\tlearn: 266079.6612736\ttotal: 1.3s\tremaining: 2.33s\n",
      "359:\tlearn: 266078.7356790\ttotal: 1.3s\tremaining: 2.32s\n",
      "360:\tlearn: 266077.5602922\ttotal: 1.31s\tremaining: 2.31s\n",
      "361:\tlearn: 266076.4270353\ttotal: 1.31s\tremaining: 2.31s\n",
      "362:\tlearn: 266076.0642562\ttotal: 1.31s\tremaining: 2.31s\n",
      "363:\tlearn: 266075.2264327\ttotal: 1.32s\tremaining: 2.3s\n",
      "364:\tlearn: 266074.7540472\ttotal: 1.32s\tremaining: 2.29s\n",
      "365:\tlearn: 266074.2525412\ttotal: 1.32s\tremaining: 2.29s\n",
      "366:\tlearn: 266073.9465216\ttotal: 1.33s\tremaining: 2.29s\n",
      "367:\tlearn: 266073.1555651\ttotal: 1.33s\tremaining: 2.28s\n",
      "368:\tlearn: 266072.2431659\ttotal: 1.33s\tremaining: 2.28s\n",
      "369:\tlearn: 266071.3613023\ttotal: 1.33s\tremaining: 2.27s\n",
      "370:\tlearn: 266071.0104855\ttotal: 1.34s\tremaining: 2.27s\n",
      "371:\tlearn: 266069.9251057\ttotal: 1.34s\tremaining: 2.26s\n",
      "372:\tlearn: 266069.5940956\ttotal: 1.34s\tremaining: 2.26s\n",
      "373:\tlearn: 266068.7845836\ttotal: 1.35s\tremaining: 2.25s\n",
      "374:\tlearn: 266068.4671202\ttotal: 1.35s\tremaining: 2.25s\n",
      "375:\tlearn: 266067.8549126\ttotal: 1.35s\tremaining: 2.24s\n",
      "376:\tlearn: 266067.2126446\ttotal: 1.35s\tremaining: 2.23s\n",
      "377:\tlearn: 266066.4143735\ttotal: 1.36s\tremaining: 2.23s\n",
      "378:\tlearn: 266065.9994923\ttotal: 1.36s\tremaining: 2.23s\n",
      "379:\tlearn: 266065.8879282\ttotal: 1.36s\tremaining: 2.22s\n",
      "380:\tlearn: 266065.1462927\ttotal: 1.37s\tremaining: 2.22s\n",
      "381:\tlearn: 266065.0403396\ttotal: 1.37s\tremaining: 2.21s\n",
      "382:\tlearn: 266064.7536103\ttotal: 1.37s\tremaining: 2.21s\n",
      "383:\tlearn: 266064.6532394\ttotal: 1.38s\tremaining: 2.21s\n",
      "384:\tlearn: 266063.9188584\ttotal: 1.38s\tremaining: 2.2s\n",
      "385:\tlearn: 266063.5430983\ttotal: 1.38s\tremaining: 2.2s\n",
      "386:\tlearn: 266063.4460717\ttotal: 1.38s\tremaining: 2.19s\n",
      "387:\tlearn: 266062.5964453\ttotal: 1.39s\tremaining: 2.19s\n",
      "388:\tlearn: 266061.6705576\ttotal: 1.39s\tremaining: 2.19s\n",
      "389:\tlearn: 266060.9761221\ttotal: 1.39s\tremaining: 2.18s\n",
      "390:\tlearn: 266060.8966952\ttotal: 1.4s\tremaining: 2.17s\n",
      "391:\tlearn: 266059.9835802\ttotal: 1.4s\tremaining: 2.17s\n",
      "392:\tlearn: 266059.3666568\ttotal: 1.4s\tremaining: 2.17s\n",
      "393:\tlearn: 266059.2912665\ttotal: 1.41s\tremaining: 2.16s\n",
      "394:\tlearn: 266058.3279965\ttotal: 1.41s\tremaining: 2.16s\n",
      "395:\tlearn: 266057.9298270\ttotal: 1.41s\tremaining: 2.15s\n",
      "396:\tlearn: 266057.4823333\ttotal: 1.42s\tremaining: 2.15s\n",
      "397:\tlearn: 266057.3985454\ttotal: 1.42s\tremaining: 2.15s\n",
      "398:\tlearn: 266056.5074517\ttotal: 1.43s\tremaining: 2.15s\n",
      "399:\tlearn: 266056.4395750\ttotal: 1.43s\tremaining: 2.14s\n",
      "400:\tlearn: 266055.8648391\ttotal: 1.43s\tremaining: 2.14s\n",
      "401:\tlearn: 266055.5661780\ttotal: 1.44s\tremaining: 2.14s\n",
      "402:\tlearn: 266054.8906897\ttotal: 1.44s\tremaining: 2.13s\n",
      "403:\tlearn: 266054.3859974\ttotal: 1.44s\tremaining: 2.13s\n",
      "404:\tlearn: 266053.9260380\ttotal: 1.45s\tremaining: 2.13s\n",
      "405:\tlearn: 266053.4489958\ttotal: 1.45s\tremaining: 2.13s\n",
      "406:\tlearn: 266052.9551305\ttotal: 1.46s\tremaining: 2.12s\n",
      "407:\tlearn: 266052.2284892\ttotal: 1.46s\tremaining: 2.12s\n",
      "408:\tlearn: 266051.7423266\ttotal: 1.46s\tremaining: 2.12s\n",
      "409:\tlearn: 266050.9626998\ttotal: 1.47s\tremaining: 2.11s\n",
      "410:\tlearn: 266050.5228733\ttotal: 1.47s\tremaining: 2.11s\n",
      "411:\tlearn: 266050.4583471\ttotal: 1.47s\tremaining: 2.1s\n",
      "412:\tlearn: 266050.0765864\ttotal: 1.48s\tremaining: 2.1s\n",
      "413:\tlearn: 266050.0153821\ttotal: 1.48s\tremaining: 2.09s\n",
      "414:\tlearn: 266049.9451027\ttotal: 1.48s\tremaining: 2.09s\n",
      "415:\tlearn: 266049.3214087\ttotal: 1.48s\tremaining: 2.08s\n",
      "416:\tlearn: 266048.6579655\ttotal: 1.49s\tremaining: 2.08s\n",
      "417:\tlearn: 266048.2569535\ttotal: 1.49s\tremaining: 2.07s\n",
      "418:\tlearn: 266048.0446995\ttotal: 1.49s\tremaining: 2.07s\n",
      "419:\tlearn: 266047.8014299\ttotal: 1.5s\tremaining: 2.07s\n",
      "420:\tlearn: 266047.2720365\ttotal: 1.5s\tremaining: 2.06s\n",
      "421:\tlearn: 266046.5052761\ttotal: 1.5s\tremaining: 2.06s\n",
      "422:\tlearn: 266046.1257663\ttotal: 1.5s\tremaining: 2.05s\n",
      "423:\tlearn: 266045.7613473\ttotal: 1.51s\tremaining: 2.05s\n",
      "424:\tlearn: 266045.1391956\ttotal: 1.51s\tremaining: 2.04s\n",
      "425:\tlearn: 266044.3859526\ttotal: 1.51s\tremaining: 2.04s\n",
      "426:\tlearn: 266043.9489221\ttotal: 1.52s\tremaining: 2.03s\n",
      "427:\tlearn: 266043.7558992\ttotal: 1.52s\tremaining: 2.03s\n",
      "428:\tlearn: 266043.5052682\ttotal: 1.52s\tremaining: 2.02s\n",
      "429:\tlearn: 266043.3235930\ttotal: 1.52s\tremaining: 2.02s\n",
      "430:\tlearn: 266042.9177206\ttotal: 1.53s\tremaining: 2.02s\n",
      "431:\tlearn: 266042.2871293\ttotal: 1.53s\tremaining: 2.01s\n",
      "432:\tlearn: 266042.0731067\ttotal: 1.53s\tremaining: 2.01s\n",
      "433:\tlearn: 266041.7652238\ttotal: 1.53s\tremaining: 2s\n",
      "434:\tlearn: 266041.7182509\ttotal: 1.54s\tremaining: 2s\n",
      "435:\tlearn: 266041.3331055\ttotal: 1.54s\tremaining: 1.99s\n",
      "436:\tlearn: 266041.1737024\ttotal: 1.54s\tremaining: 1.99s\n",
      "437:\tlearn: 266040.7213828\ttotal: 1.55s\tremaining: 1.99s\n",
      "438:\tlearn: 266040.2477009\ttotal: 1.55s\tremaining: 1.98s\n",
      "439:\tlearn: 266039.9354194\ttotal: 1.55s\tremaining: 1.98s\n",
      "440:\tlearn: 266039.7890004\ttotal: 1.56s\tremaining: 1.97s\n",
      "441:\tlearn: 266039.3237270\ttotal: 1.56s\tremaining: 1.97s\n",
      "442:\tlearn: 266038.9649545\ttotal: 1.56s\tremaining: 1.96s\n",
      "443:\tlearn: 266038.3014628\ttotal: 1.56s\tremaining: 1.96s\n",
      "444:\tlearn: 266038.1655727\ttotal: 1.57s\tremaining: 1.95s\n",
      "445:\tlearn: 266037.6194401\ttotal: 1.57s\tremaining: 1.95s\n",
      "446:\tlearn: 266037.0531750\ttotal: 1.57s\tremaining: 1.95s\n",
      "447:\tlearn: 266036.9245649\ttotal: 1.58s\tremaining: 1.94s\n",
      "448:\tlearn: 266036.5449611\ttotal: 1.58s\tremaining: 1.94s\n",
      "449:\tlearn: 266036.3797698\ttotal: 1.58s\tremaining: 1.93s\n",
      "450:\tlearn: 266036.0453547\ttotal: 1.58s\tremaining: 1.93s\n",
      "451:\tlearn: 266035.7360184\ttotal: 1.59s\tremaining: 1.93s\n",
      "452:\tlearn: 266035.1919367\ttotal: 1.59s\tremaining: 1.92s\n",
      "453:\tlearn: 266035.0695920\ttotal: 1.59s\tremaining: 1.92s\n",
      "454:\tlearn: 266034.9526604\ttotal: 1.6s\tremaining: 1.91s\n",
      "455:\tlearn: 266034.5052230\ttotal: 1.6s\tremaining: 1.91s\n",
      "456:\tlearn: 266034.3589688\ttotal: 1.6s\tremaining: 1.91s\n",
      "457:\tlearn: 266033.9791470\ttotal: 1.61s\tremaining: 1.9s\n",
      "458:\tlearn: 266033.5898347\ttotal: 1.61s\tremaining: 1.9s\n",
      "459:\tlearn: 266033.1693603\ttotal: 1.61s\tremaining: 1.89s\n",
      "460:\tlearn: 266032.7427194\ttotal: 1.62s\tremaining: 1.89s\n",
      "461:\tlearn: 266032.2606038\ttotal: 1.62s\tremaining: 1.89s\n",
      "462:\tlearn: 266031.8066469\ttotal: 1.62s\tremaining: 1.88s\n",
      "463:\tlearn: 266031.2986900\ttotal: 1.63s\tremaining: 1.88s\n",
      "464:\tlearn: 266030.8423565\ttotal: 1.63s\tremaining: 1.87s\n",
      "465:\tlearn: 266030.7357814\ttotal: 1.63s\tremaining: 1.87s\n",
      "466:\tlearn: 266030.2999673\ttotal: 1.64s\tremaining: 1.87s\n",
      "467:\tlearn: 266029.9358471\ttotal: 1.64s\tremaining: 1.87s\n",
      "468:\tlearn: 266029.6122070\ttotal: 1.65s\tremaining: 1.86s\n",
      "469:\tlearn: 266029.2190992\ttotal: 1.65s\tremaining: 1.86s\n",
      "470:\tlearn: 266028.8153189\ttotal: 1.65s\tremaining: 1.86s\n",
      "471:\tlearn: 266028.5960429\ttotal: 1.66s\tremaining: 1.85s\n",
      "472:\tlearn: 266028.4984199\ttotal: 1.66s\tremaining: 1.85s\n",
      "473:\tlearn: 266028.2285044\ttotal: 1.66s\tremaining: 1.84s\n",
      "474:\tlearn: 266027.8841177\ttotal: 1.66s\tremaining: 1.84s\n",
      "475:\tlearn: 266027.7894889\ttotal: 1.67s\tremaining: 1.83s\n",
      "476:\tlearn: 266027.4846116\ttotal: 1.67s\tremaining: 1.83s\n",
      "477:\tlearn: 266027.2681391\ttotal: 1.67s\tremaining: 1.83s\n",
      "478:\tlearn: 266026.8265957\ttotal: 1.68s\tremaining: 1.82s\n",
      "479:\tlearn: 266026.5916696\ttotal: 1.68s\tremaining: 1.82s\n",
      "480:\tlearn: 266026.2931555\ttotal: 1.68s\tremaining: 1.81s\n",
      "481:\tlearn: 266026.0148806\ttotal: 1.68s\tremaining: 1.81s\n",
      "482:\tlearn: 266025.9013660\ttotal: 1.69s\tremaining: 1.8s\n",
      "483:\tlearn: 266025.8187226\ttotal: 1.69s\tremaining: 1.8s\n",
      "484:\tlearn: 266025.5882887\ttotal: 1.69s\tremaining: 1.8s\n",
      "485:\tlearn: 266025.2587401\ttotal: 1.7s\tremaining: 1.79s\n",
      "486:\tlearn: 266024.7563779\ttotal: 1.7s\tremaining: 1.79s\n",
      "487:\tlearn: 266024.4095314\ttotal: 1.7s\tremaining: 1.78s\n",
      "488:\tlearn: 266024.2503494\ttotal: 1.7s\tremaining: 1.78s\n",
      "489:\tlearn: 266023.8399388\ttotal: 1.7s\tremaining: 1.77s\n",
      "490:\tlearn: 266023.5549914\ttotal: 1.71s\tremaining: 1.77s\n",
      "491:\tlearn: 266023.2443889\ttotal: 1.73s\tremaining: 1.78s\n",
      "492:\tlearn: 266022.8883268\ttotal: 1.73s\tremaining: 1.78s\n",
      "493:\tlearn: 266022.5443085\ttotal: 1.73s\tremaining: 1.78s\n",
      "494:\tlearn: 266022.4272020\ttotal: 1.74s\tremaining: 1.77s\n",
      "495:\tlearn: 266022.1872048\ttotal: 1.74s\tremaining: 1.77s\n",
      "496:\tlearn: 266021.9033196\ttotal: 1.75s\tremaining: 1.77s\n",
      "497:\tlearn: 266021.4601520\ttotal: 1.75s\tremaining: 1.77s\n",
      "498:\tlearn: 266021.2564541\ttotal: 1.76s\tremaining: 1.76s\n",
      "499:\tlearn: 266020.7946942\ttotal: 1.76s\tremaining: 1.76s\n",
      "500:\tlearn: 266020.6572499\ttotal: 1.76s\tremaining: 1.76s\n",
      "501:\tlearn: 266020.5818708\ttotal: 1.77s\tremaining: 1.75s\n",
      "502:\tlearn: 266020.4894649\ttotal: 1.77s\tremaining: 1.75s\n",
      "503:\tlearn: 266020.1972706\ttotal: 1.78s\tremaining: 1.75s\n",
      "504:\tlearn: 266019.8809352\ttotal: 1.78s\tremaining: 1.75s\n",
      "505:\tlearn: 266019.6235079\ttotal: 1.78s\tremaining: 1.74s\n",
      "506:\tlearn: 266019.3511323\ttotal: 1.85s\tremaining: 1.8s\n",
      "507:\tlearn: 266019.0533895\ttotal: 1.86s\tremaining: 1.8s\n",
      "508:\tlearn: 266018.8354229\ttotal: 1.86s\tremaining: 1.8s\n",
      "509:\tlearn: 266018.6409294\ttotal: 1.87s\tremaining: 1.79s\n",
      "510:\tlearn: 266018.4138279\ttotal: 1.87s\tremaining: 1.79s\n",
      "511:\tlearn: 266018.1694335\ttotal: 1.88s\tremaining: 1.79s\n",
      "512:\tlearn: 266017.9199513\ttotal: 1.88s\tremaining: 1.79s\n",
      "513:\tlearn: 266017.6369143\ttotal: 1.89s\tremaining: 1.78s\n",
      "514:\tlearn: 266017.4222099\ttotal: 1.89s\tremaining: 1.78s\n",
      "515:\tlearn: 266017.2650013\ttotal: 1.89s\tremaining: 1.77s\n",
      "516:\tlearn: 266017.1015253\ttotal: 1.89s\tremaining: 1.77s\n",
      "517:\tlearn: 266016.8382056\ttotal: 1.9s\tremaining: 1.76s\n",
      "518:\tlearn: 266016.5280012\ttotal: 1.9s\tremaining: 1.76s\n",
      "519:\tlearn: 266016.3748973\ttotal: 1.9s\tremaining: 1.76s\n",
      "520:\tlearn: 266016.1759232\ttotal: 1.91s\tremaining: 1.75s\n",
      "521:\tlearn: 266016.1076674\ttotal: 1.91s\tremaining: 1.75s\n",
      "522:\tlearn: 266015.8735605\ttotal: 1.91s\tremaining: 1.74s\n",
      "523:\tlearn: 266015.8113109\ttotal: 1.91s\tremaining: 1.74s\n",
      "524:\tlearn: 266015.7303392\ttotal: 1.91s\tremaining: 1.73s\n",
      "525:\tlearn: 266015.6251108\ttotal: 1.92s\tremaining: 1.73s\n",
      "526:\tlearn: 266015.3885801\ttotal: 1.92s\tremaining: 1.72s\n",
      "527:\tlearn: 266015.1396471\ttotal: 1.92s\tremaining: 1.72s\n",
      "528:\tlearn: 266014.8926873\ttotal: 1.93s\tremaining: 1.71s\n",
      "529:\tlearn: 266014.6317208\ttotal: 1.93s\tremaining: 1.71s\n",
      "530:\tlearn: 266014.4836687\ttotal: 1.93s\tremaining: 1.7s\n",
      "531:\tlearn: 266014.4291937\ttotal: 1.93s\tremaining: 1.7s\n",
      "532:\tlearn: 266014.1469080\ttotal: 1.94s\tremaining: 1.7s\n",
      "533:\tlearn: 266014.0050620\ttotal: 1.94s\tremaining: 1.69s\n",
      "534:\tlearn: 266013.9357224\ttotal: 1.94s\tremaining: 1.69s\n",
      "535:\tlearn: 266013.9162504\ttotal: 1.94s\tremaining: 1.68s\n",
      "536:\tlearn: 266013.7424802\ttotal: 1.94s\tremaining: 1.68s\n",
      "537:\tlearn: 266013.6635377\ttotal: 1.95s\tremaining: 1.67s\n",
      "538:\tlearn: 266013.5155979\ttotal: 1.95s\tremaining: 1.67s\n",
      "539:\tlearn: 266013.3399736\ttotal: 1.95s\tremaining: 1.66s\n",
      "540:\tlearn: 266013.0540169\ttotal: 1.96s\tremaining: 1.66s\n",
      "541:\tlearn: 266012.8606078\ttotal: 1.96s\tremaining: 1.65s\n",
      "542:\tlearn: 266012.5884550\ttotal: 1.96s\tremaining: 1.65s\n",
      "543:\tlearn: 266012.4532853\ttotal: 1.96s\tremaining: 1.64s\n",
      "544:\tlearn: 266012.2487634\ttotal: 1.97s\tremaining: 1.64s\n",
      "545:\tlearn: 266012.0364331\ttotal: 1.97s\tremaining: 1.64s\n",
      "546:\tlearn: 266011.9701966\ttotal: 1.97s\tremaining: 1.63s\n",
      "547:\tlearn: 266011.8149968\ttotal: 1.97s\tremaining: 1.63s\n",
      "548:\tlearn: 266011.5807430\ttotal: 1.98s\tremaining: 1.62s\n",
      "549:\tlearn: 266011.4424718\ttotal: 1.98s\tremaining: 1.62s\n",
      "550:\tlearn: 266011.3968397\ttotal: 1.98s\tremaining: 1.62s\n",
      "551:\tlearn: 266011.3539654\ttotal: 1.99s\tremaining: 1.61s\n",
      "552:\tlearn: 266011.1082225\ttotal: 1.99s\tremaining: 1.61s\n",
      "553:\tlearn: 266010.9506926\ttotal: 1.99s\tremaining: 1.6s\n",
      "554:\tlearn: 266010.7672867\ttotal: 1.99s\tremaining: 1.6s\n",
      "555:\tlearn: 266010.7469241\ttotal: 2s\tremaining: 1.59s\n",
      "556:\tlearn: 266010.6105253\ttotal: 2s\tremaining: 1.59s\n",
      "557:\tlearn: 266010.3866271\ttotal: 2.01s\tremaining: 1.59s\n",
      "558:\tlearn: 266010.1608908\ttotal: 2.01s\tremaining: 1.58s\n",
      "559:\tlearn: 266010.0816704\ttotal: 2.01s\tremaining: 1.58s\n",
      "560:\tlearn: 266009.9068276\ttotal: 2.02s\tremaining: 1.58s\n",
      "561:\tlearn: 266009.7934588\ttotal: 2.02s\tremaining: 1.57s\n",
      "562:\tlearn: 266009.6262513\ttotal: 2.02s\tremaining: 1.57s\n",
      "563:\tlearn: 266009.3179625\ttotal: 2.02s\tremaining: 1.56s\n",
      "564:\tlearn: 266009.1452608\ttotal: 2.03s\tremaining: 1.56s\n",
      "565:\tlearn: 266008.9768403\ttotal: 2.03s\tremaining: 1.56s\n",
      "566:\tlearn: 266008.8217921\ttotal: 2.03s\tremaining: 1.55s\n",
      "567:\tlearn: 266008.7150069\ttotal: 2.04s\tremaining: 1.55s\n",
      "568:\tlearn: 266008.6572789\ttotal: 2.04s\tremaining: 1.54s\n",
      "569:\tlearn: 266008.4977872\ttotal: 2.04s\tremaining: 1.54s\n",
      "570:\tlearn: 266008.4431658\ttotal: 2.05s\tremaining: 1.54s\n",
      "571:\tlearn: 266008.3069477\ttotal: 2.05s\tremaining: 1.53s\n",
      "572:\tlearn: 266008.2657389\ttotal: 2.05s\tremaining: 1.53s\n",
      "573:\tlearn: 266008.0827363\ttotal: 2.06s\tremaining: 1.52s\n",
      "574:\tlearn: 266007.8571686\ttotal: 2.06s\tremaining: 1.52s\n",
      "575:\tlearn: 266007.7473238\ttotal: 2.06s\tremaining: 1.52s\n",
      "576:\tlearn: 266007.5674128\ttotal: 2.06s\tremaining: 1.51s\n",
      "577:\tlearn: 266007.4702911\ttotal: 2.07s\tremaining: 1.51s\n",
      "578:\tlearn: 266007.4339862\ttotal: 2.07s\tremaining: 1.5s\n",
      "579:\tlearn: 266007.3475904\ttotal: 2.08s\tremaining: 1.5s\n",
      "580:\tlearn: 266007.1868448\ttotal: 2.08s\tremaining: 1.5s\n",
      "581:\tlearn: 266007.0429985\ttotal: 2.08s\tremaining: 1.49s\n",
      "582:\tlearn: 266007.0089726\ttotal: 2.08s\tremaining: 1.49s\n",
      "583:\tlearn: 266006.8792943\ttotal: 2.08s\tremaining: 1.49s\n",
      "584:\tlearn: 266006.7123239\ttotal: 2.09s\tremaining: 1.48s\n",
      "585:\tlearn: 266006.6803933\ttotal: 2.09s\tremaining: 1.48s\n",
      "586:\tlearn: 266006.5355137\ttotal: 2.09s\tremaining: 1.47s\n",
      "587:\tlearn: 266006.3764501\ttotal: 2.1s\tremaining: 1.47s\n",
      "588:\tlearn: 266006.3584283\ttotal: 2.1s\tremaining: 1.46s\n",
      "589:\tlearn: 266006.2232821\ttotal: 2.1s\tremaining: 1.46s\n",
      "590:\tlearn: 266006.0974250\ttotal: 2.1s\tremaining: 1.46s\n",
      "591:\tlearn: 266006.0679218\ttotal: 2.11s\tremaining: 1.45s\n",
      "592:\tlearn: 266005.9376438\ttotal: 2.11s\tremaining: 1.45s\n",
      "593:\tlearn: 266005.7704940\ttotal: 2.11s\tremaining: 1.44s\n",
      "594:\tlearn: 266005.6486691\ttotal: 2.11s\tremaining: 1.44s\n",
      "595:\tlearn: 266005.5027290\ttotal: 2.12s\tremaining: 1.43s\n",
      "596:\tlearn: 266005.3312728\ttotal: 2.12s\tremaining: 1.43s\n",
      "597:\tlearn: 266005.1547804\ttotal: 2.12s\tremaining: 1.43s\n",
      "598:\tlearn: 266004.9645698\ttotal: 2.13s\tremaining: 1.42s\n",
      "599:\tlearn: 266004.8611561\ttotal: 2.13s\tremaining: 1.42s\n",
      "600:\tlearn: 266004.8024103\ttotal: 2.13s\tremaining: 1.41s\n",
      "601:\tlearn: 266004.7509452\ttotal: 2.13s\tremaining: 1.41s\n",
      "602:\tlearn: 266004.5947051\ttotal: 2.13s\tremaining: 1.4s\n",
      "603:\tlearn: 266004.4995533\ttotal: 2.14s\tremaining: 1.4s\n",
      "604:\tlearn: 266004.4368814\ttotal: 2.14s\tremaining: 1.4s\n",
      "605:\tlearn: 266004.3159385\ttotal: 2.14s\tremaining: 1.39s\n",
      "606:\tlearn: 266004.3004619\ttotal: 2.14s\tremaining: 1.39s\n",
      "607:\tlearn: 266004.2078998\ttotal: 2.15s\tremaining: 1.38s\n",
      "608:\tlearn: 266004.0745028\ttotal: 2.15s\tremaining: 1.38s\n",
      "609:\tlearn: 266003.9184166\ttotal: 2.15s\tremaining: 1.38s\n",
      "610:\tlearn: 266003.9040118\ttotal: 2.15s\tremaining: 1.37s\n",
      "611:\tlearn: 266003.8768212\ttotal: 2.16s\tremaining: 1.37s\n",
      "612:\tlearn: 266003.8039825\ttotal: 2.16s\tremaining: 1.36s\n",
      "613:\tlearn: 266003.6724774\ttotal: 2.16s\tremaining: 1.36s\n",
      "614:\tlearn: 266003.5570171\ttotal: 2.16s\tremaining: 1.35s\n",
      "615:\tlearn: 266003.3697686\ttotal: 2.17s\tremaining: 1.35s\n",
      "616:\tlearn: 266003.2508991\ttotal: 2.17s\tremaining: 1.35s\n",
      "617:\tlearn: 266003.1001001\ttotal: 2.17s\tremaining: 1.34s\n",
      "618:\tlearn: 266003.0262487\ttotal: 2.17s\tremaining: 1.34s\n",
      "619:\tlearn: 266002.9572312\ttotal: 2.18s\tremaining: 1.33s\n",
      "620:\tlearn: 266002.8996919\ttotal: 2.18s\tremaining: 1.33s\n",
      "621:\tlearn: 266002.7593612\ttotal: 2.18s\tremaining: 1.33s\n",
      "622:\tlearn: 266002.5508700\ttotal: 2.19s\tremaining: 1.32s\n",
      "623:\tlearn: 266002.4423602\ttotal: 2.19s\tremaining: 1.32s\n",
      "624:\tlearn: 266002.3347827\ttotal: 2.19s\tremaining: 1.32s\n",
      "625:\tlearn: 266002.2169427\ttotal: 2.2s\tremaining: 1.31s\n",
      "626:\tlearn: 266002.0524889\ttotal: 2.2s\tremaining: 1.31s\n",
      "627:\tlearn: 266002.0100035\ttotal: 2.2s\tremaining: 1.31s\n",
      "628:\tlearn: 266001.9448771\ttotal: 2.21s\tremaining: 1.3s\n",
      "629:\tlearn: 266001.8730205\ttotal: 2.21s\tremaining: 1.3s\n",
      "630:\tlearn: 266001.7044182\ttotal: 2.22s\tremaining: 1.29s\n",
      "631:\tlearn: 266001.5763487\ttotal: 2.22s\tremaining: 1.29s\n",
      "632:\tlearn: 266001.4719693\ttotal: 2.22s\tremaining: 1.29s\n",
      "633:\tlearn: 266001.4116891\ttotal: 2.22s\tremaining: 1.28s\n",
      "634:\tlearn: 266001.2948508\ttotal: 2.23s\tremaining: 1.28s\n",
      "635:\tlearn: 266001.2241244\ttotal: 2.23s\tremaining: 1.28s\n",
      "636:\tlearn: 266001.1710706\ttotal: 2.23s\tremaining: 1.27s\n",
      "637:\tlearn: 266001.0823233\ttotal: 2.24s\tremaining: 1.27s\n",
      "638:\tlearn: 266000.9915638\ttotal: 2.24s\tremaining: 1.26s\n",
      "639:\tlearn: 266000.8861472\ttotal: 2.24s\tremaining: 1.26s\n",
      "640:\tlearn: 266000.8560101\ttotal: 2.25s\tremaining: 1.26s\n",
      "641:\tlearn: 266000.8275559\ttotal: 2.25s\tremaining: 1.25s\n",
      "642:\tlearn: 266000.6733766\ttotal: 2.25s\tremaining: 1.25s\n",
      "643:\tlearn: 266000.5511459\ttotal: 2.25s\tremaining: 1.25s\n",
      "644:\tlearn: 266000.4553956\ttotal: 2.26s\tremaining: 1.24s\n",
      "645:\tlearn: 266000.4284803\ttotal: 2.26s\tremaining: 1.24s\n",
      "646:\tlearn: 266000.3539939\ttotal: 2.26s\tremaining: 1.23s\n",
      "647:\tlearn: 266000.2853051\ttotal: 2.26s\tremaining: 1.23s\n",
      "648:\tlearn: 266000.2598931\ttotal: 2.27s\tremaining: 1.23s\n",
      "649:\tlearn: 266000.2055936\ttotal: 2.27s\tremaining: 1.22s\n",
      "650:\tlearn: 266000.1772418\ttotal: 2.27s\tremaining: 1.22s\n",
      "651:\tlearn: 266000.1028356\ttotal: 2.27s\tremaining: 1.21s\n",
      "652:\tlearn: 266000.0404489\ttotal: 2.27s\tremaining: 1.21s\n",
      "653:\tlearn: 265999.9399910\ttotal: 2.28s\tremaining: 1.21s\n",
      "654:\tlearn: 265999.8332025\ttotal: 2.28s\tremaining: 1.2s\n",
      "655:\tlearn: 265999.6985043\ttotal: 2.28s\tremaining: 1.2s\n",
      "656:\tlearn: 265999.5857658\ttotal: 2.29s\tremaining: 1.19s\n",
      "657:\tlearn: 265999.4660986\ttotal: 2.29s\tremaining: 1.19s\n",
      "658:\tlearn: 265999.3912072\ttotal: 2.29s\tremaining: 1.19s\n",
      "659:\tlearn: 265999.3140708\ttotal: 2.29s\tremaining: 1.18s\n",
      "660:\tlearn: 265999.2176764\ttotal: 2.3s\tremaining: 1.18s\n",
      "661:\tlearn: 265999.1102272\ttotal: 2.3s\tremaining: 1.17s\n",
      "662:\tlearn: 265999.0201800\ttotal: 2.3s\tremaining: 1.17s\n",
      "663:\tlearn: 265998.8812492\ttotal: 2.3s\tremaining: 1.17s\n",
      "664:\tlearn: 265998.8652307\ttotal: 2.31s\tremaining: 1.16s\n",
      "665:\tlearn: 265998.7875976\ttotal: 2.31s\tremaining: 1.16s\n",
      "666:\tlearn: 265998.7700032\ttotal: 2.31s\tremaining: 1.16s\n",
      "667:\tlearn: 265998.6911544\ttotal: 2.32s\tremaining: 1.15s\n",
      "668:\tlearn: 265998.6712063\ttotal: 2.32s\tremaining: 1.15s\n",
      "669:\tlearn: 265998.5967038\ttotal: 2.32s\tremaining: 1.14s\n",
      "670:\tlearn: 265998.5172405\ttotal: 2.32s\tremaining: 1.14s\n",
      "671:\tlearn: 265998.4857344\ttotal: 2.33s\tremaining: 1.14s\n",
      "672:\tlearn: 265998.4112845\ttotal: 2.33s\tremaining: 1.13s\n",
      "673:\tlearn: 265998.3221832\ttotal: 2.33s\tremaining: 1.13s\n",
      "674:\tlearn: 265998.1989304\ttotal: 2.33s\tremaining: 1.12s\n",
      "675:\tlearn: 265998.0920303\ttotal: 2.33s\tremaining: 1.12s\n",
      "676:\tlearn: 265998.0405490\ttotal: 2.34s\tremaining: 1.11s\n",
      "677:\tlearn: 265997.9733201\ttotal: 2.34s\tremaining: 1.11s\n",
      "678:\tlearn: 265997.8827704\ttotal: 2.34s\tremaining: 1.11s\n",
      "679:\tlearn: 265997.8021939\ttotal: 2.35s\tremaining: 1.1s\n",
      "680:\tlearn: 265997.7133616\ttotal: 2.35s\tremaining: 1.1s\n",
      "681:\tlearn: 265997.6467566\ttotal: 2.35s\tremaining: 1.1s\n",
      "682:\tlearn: 265997.6318709\ttotal: 2.35s\tremaining: 1.09s\n",
      "683:\tlearn: 265997.5597180\ttotal: 2.36s\tremaining: 1.09s\n",
      "684:\tlearn: 265997.5434085\ttotal: 2.36s\tremaining: 1.08s\n",
      "685:\tlearn: 265997.4638905\ttotal: 2.36s\tremaining: 1.08s\n",
      "686:\tlearn: 265997.4000283\ttotal: 2.36s\tremaining: 1.08s\n",
      "687:\tlearn: 265997.3074312\ttotal: 2.37s\tremaining: 1.07s\n",
      "688:\tlearn: 265997.2125015\ttotal: 2.37s\tremaining: 1.07s\n",
      "689:\tlearn: 265997.1227050\ttotal: 2.37s\tremaining: 1.07s\n",
      "690:\tlearn: 265997.0604901\ttotal: 2.38s\tremaining: 1.06s\n",
      "691:\tlearn: 265997.0472377\ttotal: 2.38s\tremaining: 1.06s\n",
      "692:\tlearn: 265996.9579530\ttotal: 2.38s\tremaining: 1.05s\n",
      "693:\tlearn: 265996.8982620\ttotal: 2.38s\tremaining: 1.05s\n",
      "694:\tlearn: 265996.7840472\ttotal: 2.39s\tremaining: 1.05s\n",
      "695:\tlearn: 265996.7696555\ttotal: 2.39s\tremaining: 1.04s\n",
      "696:\tlearn: 265996.7077810\ttotal: 2.39s\tremaining: 1.04s\n",
      "697:\tlearn: 265996.6176580\ttotal: 2.4s\tremaining: 1.04s\n",
      "698:\tlearn: 265996.6049167\ttotal: 2.4s\tremaining: 1.03s\n",
      "699:\tlearn: 265996.5230485\ttotal: 2.4s\tremaining: 1.03s\n",
      "700:\tlearn: 265996.4197029\ttotal: 2.41s\tremaining: 1.03s\n",
      "701:\tlearn: 265996.3415735\ttotal: 2.41s\tremaining: 1.02s\n",
      "702:\tlearn: 265996.3183588\ttotal: 2.41s\tremaining: 1.02s\n",
      "703:\tlearn: 265996.2601560\ttotal: 2.42s\tremaining: 1.01s\n",
      "704:\tlearn: 265996.1780594\ttotal: 2.46s\tremaining: 1.03s\n",
      "705:\tlearn: 265996.1523083\ttotal: 2.47s\tremaining: 1.03s\n",
      "706:\tlearn: 265996.1039202\ttotal: 2.48s\tremaining: 1.03s\n",
      "707:\tlearn: 265996.0721639\ttotal: 2.49s\tremaining: 1.02s\n",
      "708:\tlearn: 265995.9942929\ttotal: 2.49s\tremaining: 1.02s\n",
      "709:\tlearn: 265995.9561362\ttotal: 2.49s\tremaining: 1.02s\n",
      "710:\tlearn: 265995.8698365\ttotal: 2.49s\tremaining: 1.01s\n",
      "711:\tlearn: 265995.7928993\ttotal: 2.5s\tremaining: 1.01s\n",
      "712:\tlearn: 265995.6901148\ttotal: 2.5s\tremaining: 1.01s\n",
      "713:\tlearn: 265995.6414457\ttotal: 2.51s\tremaining: 1s\n",
      "714:\tlearn: 265995.6035567\ttotal: 2.51s\tremaining: 1s\n",
      "715:\tlearn: 265995.5069292\ttotal: 2.52s\tremaining: 999ms\n",
      "716:\tlearn: 265995.4862666\ttotal: 2.52s\tremaining: 995ms\n",
      "717:\tlearn: 265995.4723817\ttotal: 2.52s\tremaining: 991ms\n",
      "718:\tlearn: 265995.3875241\ttotal: 2.52s\tremaining: 987ms\n",
      "719:\tlearn: 265995.3157818\ttotal: 2.53s\tremaining: 983ms\n",
      "720:\tlearn: 265995.2442056\ttotal: 2.53s\tremaining: 980ms\n",
      "721:\tlearn: 265995.2342710\ttotal: 2.53s\tremaining: 976ms\n",
      "722:\tlearn: 265995.2054506\ttotal: 2.54s\tremaining: 972ms\n",
      "723:\tlearn: 265995.1484752\ttotal: 2.54s\tremaining: 968ms\n",
      "724:\tlearn: 265995.0990080\ttotal: 2.54s\tremaining: 964ms\n",
      "725:\tlearn: 265995.0338199\ttotal: 2.54s\tremaining: 960ms\n",
      "726:\tlearn: 265994.9391137\ttotal: 2.54s\tremaining: 956ms\n",
      "727:\tlearn: 265994.8897542\ttotal: 2.55s\tremaining: 952ms\n",
      "728:\tlearn: 265994.8613803\ttotal: 2.55s\tremaining: 948ms\n",
      "729:\tlearn: 265994.8462207\ttotal: 2.55s\tremaining: 945ms\n",
      "730:\tlearn: 265994.7719498\ttotal: 2.56s\tremaining: 941ms\n",
      "731:\tlearn: 265994.6865638\ttotal: 2.56s\tremaining: 937ms\n",
      "732:\tlearn: 265994.6152044\ttotal: 2.56s\tremaining: 933ms\n",
      "733:\tlearn: 265994.5449141\ttotal: 2.56s\tremaining: 929ms\n",
      "734:\tlearn: 265994.5188199\ttotal: 2.57s\tremaining: 926ms\n",
      "735:\tlearn: 265994.4961146\ttotal: 2.57s\tremaining: 922ms\n",
      "736:\tlearn: 265994.4386260\ttotal: 2.57s\tremaining: 918ms\n",
      "737:\tlearn: 265994.3994669\ttotal: 2.58s\tremaining: 914ms\n",
      "738:\tlearn: 265994.3343635\ttotal: 2.58s\tremaining: 911ms\n",
      "739:\tlearn: 265994.2838413\ttotal: 2.58s\tremaining: 908ms\n",
      "740:\tlearn: 265994.2230049\ttotal: 2.58s\tremaining: 904ms\n",
      "741:\tlearn: 265994.1668942\ttotal: 2.59s\tremaining: 900ms\n",
      "742:\tlearn: 265994.1157504\ttotal: 2.59s\tremaining: 896ms\n",
      "743:\tlearn: 265994.0513855\ttotal: 2.6s\tremaining: 893ms\n",
      "744:\tlearn: 265994.0049150\ttotal: 2.6s\tremaining: 889ms\n",
      "745:\tlearn: 265993.9454032\ttotal: 2.6s\tremaining: 886ms\n",
      "746:\tlearn: 265993.9123945\ttotal: 2.6s\tremaining: 882ms\n",
      "747:\tlearn: 265993.8836724\ttotal: 2.6s\tremaining: 878ms\n",
      "748:\tlearn: 265993.8320910\ttotal: 2.61s\tremaining: 875ms\n",
      "749:\tlearn: 265993.7771188\ttotal: 2.61s\tremaining: 871ms\n",
      "750:\tlearn: 265993.7247147\ttotal: 2.62s\tremaining: 867ms\n",
      "751:\tlearn: 265993.6969497\ttotal: 2.62s\tremaining: 864ms\n",
      "752:\tlearn: 265993.6117272\ttotal: 2.62s\tremaining: 860ms\n",
      "753:\tlearn: 265993.5592632\ttotal: 2.63s\tremaining: 857ms\n",
      "754:\tlearn: 265993.5034951\ttotal: 2.63s\tremaining: 853ms\n",
      "755:\tlearn: 265993.4700027\ttotal: 2.63s\tremaining: 849ms\n",
      "756:\tlearn: 265993.4032338\ttotal: 2.63s\tremaining: 846ms\n",
      "757:\tlearn: 265993.3627319\ttotal: 2.64s\tremaining: 842ms\n",
      "758:\tlearn: 265993.3037363\ttotal: 2.64s\tremaining: 838ms\n",
      "759:\tlearn: 265993.2672263\ttotal: 2.64s\tremaining: 835ms\n",
      "760:\tlearn: 265993.2571556\ttotal: 2.65s\tremaining: 831ms\n",
      "761:\tlearn: 265993.2164129\ttotal: 2.65s\tremaining: 827ms\n",
      "762:\tlearn: 265993.1570770\ttotal: 2.65s\tremaining: 823ms\n",
      "763:\tlearn: 265993.1287781\ttotal: 2.65s\tremaining: 820ms\n",
      "764:\tlearn: 265993.0848222\ttotal: 2.66s\tremaining: 816ms\n",
      "765:\tlearn: 265992.9922760\ttotal: 2.66s\tremaining: 812ms\n",
      "766:\tlearn: 265992.9455382\ttotal: 2.66s\tremaining: 809ms\n",
      "767:\tlearn: 265992.9107525\ttotal: 2.66s\tremaining: 805ms\n",
      "768:\tlearn: 265992.8484338\ttotal: 2.67s\tremaining: 801ms\n",
      "769:\tlearn: 265992.8161820\ttotal: 2.67s\tremaining: 798ms\n",
      "770:\tlearn: 265992.7986136\ttotal: 2.67s\tremaining: 794ms\n",
      "771:\tlearn: 265992.7505104\ttotal: 2.68s\tremaining: 791ms\n",
      "772:\tlearn: 265992.6712804\ttotal: 2.68s\tremaining: 787ms\n",
      "773:\tlearn: 265992.6378008\ttotal: 2.68s\tremaining: 783ms\n",
      "774:\tlearn: 265992.5831220\ttotal: 2.68s\tremaining: 779ms\n",
      "775:\tlearn: 265992.5677389\ttotal: 2.69s\tremaining: 775ms\n",
      "776:\tlearn: 265992.5585466\ttotal: 2.69s\tremaining: 772ms\n",
      "777:\tlearn: 265992.5323427\ttotal: 2.69s\tremaining: 768ms\n",
      "778:\tlearn: 265992.4866823\ttotal: 2.69s\tremaining: 764ms\n",
      "779:\tlearn: 265992.4450708\ttotal: 2.7s\tremaining: 761ms\n",
      "780:\tlearn: 265992.4128365\ttotal: 2.7s\tremaining: 757ms\n",
      "781:\tlearn: 265992.3337623\ttotal: 2.7s\tremaining: 754ms\n",
      "782:\tlearn: 265992.2620076\ttotal: 2.71s\tremaining: 750ms\n",
      "783:\tlearn: 265992.2184685\ttotal: 2.71s\tremaining: 746ms\n",
      "784:\tlearn: 265992.1773432\ttotal: 2.71s\tremaining: 742ms\n",
      "785:\tlearn: 265992.1470604\ttotal: 2.71s\tremaining: 739ms\n",
      "786:\tlearn: 265992.0862543\ttotal: 2.72s\tremaining: 735ms\n",
      "787:\tlearn: 265992.0437997\ttotal: 2.72s\tremaining: 732ms\n",
      "788:\tlearn: 265991.9880116\ttotal: 2.72s\tremaining: 728ms\n",
      "789:\tlearn: 265991.9714005\ttotal: 2.72s\tremaining: 724ms\n",
      "790:\tlearn: 265991.8969011\ttotal: 2.73s\tremaining: 721ms\n",
      "791:\tlearn: 265991.8489846\ttotal: 2.73s\tremaining: 717ms\n",
      "792:\tlearn: 265991.7828904\ttotal: 2.73s\tremaining: 713ms\n",
      "793:\tlearn: 265991.7248572\ttotal: 2.73s\tremaining: 710ms\n",
      "794:\tlearn: 265991.6970331\ttotal: 2.74s\tremaining: 706ms\n",
      "795:\tlearn: 265991.6359589\ttotal: 2.74s\tremaining: 702ms\n",
      "796:\tlearn: 265991.5890416\ttotal: 2.74s\tremaining: 699ms\n",
      "797:\tlearn: 265991.5556191\ttotal: 2.75s\tremaining: 695ms\n",
      "798:\tlearn: 265991.5227196\ttotal: 2.75s\tremaining: 692ms\n",
      "799:\tlearn: 265991.4719656\ttotal: 2.75s\tremaining: 688ms\n",
      "800:\tlearn: 265991.4304108\ttotal: 2.75s\tremaining: 684ms\n",
      "801:\tlearn: 265991.3750451\ttotal: 2.76s\tremaining: 681ms\n",
      "802:\tlearn: 265991.3335839\ttotal: 2.76s\tremaining: 677ms\n",
      "803:\tlearn: 265991.2694291\ttotal: 2.76s\tremaining: 674ms\n",
      "804:\tlearn: 265991.2499843\ttotal: 2.77s\tremaining: 670ms\n",
      "805:\tlearn: 265991.1933536\ttotal: 2.77s\tremaining: 667ms\n",
      "806:\tlearn: 265991.1579012\ttotal: 2.77s\tremaining: 663ms\n",
      "807:\tlearn: 265991.1113638\ttotal: 2.78s\tremaining: 660ms\n",
      "808:\tlearn: 265991.0626510\ttotal: 2.78s\tremaining: 657ms\n",
      "809:\tlearn: 265991.0551344\ttotal: 2.78s\tremaining: 653ms\n",
      "810:\tlearn: 265991.0268599\ttotal: 2.79s\tremaining: 649ms\n",
      "811:\tlearn: 265990.9905350\ttotal: 2.79s\tremaining: 646ms\n",
      "812:\tlearn: 265990.9804385\ttotal: 2.79s\tremaining: 643ms\n",
      "813:\tlearn: 265990.9562162\ttotal: 2.8s\tremaining: 639ms\n",
      "814:\tlearn: 265990.9325684\ttotal: 2.8s\tremaining: 635ms\n",
      "815:\tlearn: 265990.9007700\ttotal: 2.8s\tremaining: 632ms\n",
      "816:\tlearn: 265990.8838032\ttotal: 2.8s\tremaining: 628ms\n",
      "817:\tlearn: 265990.8615563\ttotal: 2.81s\tremaining: 625ms\n",
      "818:\tlearn: 265990.8260509\ttotal: 2.81s\tremaining: 621ms\n",
      "819:\tlearn: 265990.7723611\ttotal: 2.81s\tremaining: 618ms\n",
      "820:\tlearn: 265990.7292544\ttotal: 2.82s\tremaining: 614ms\n",
      "821:\tlearn: 265990.6900365\ttotal: 2.82s\tremaining: 610ms\n",
      "822:\tlearn: 265990.6525096\ttotal: 2.82s\tremaining: 607ms\n",
      "823:\tlearn: 265990.5942590\ttotal: 2.83s\tremaining: 603ms\n",
      "824:\tlearn: 265990.5443754\ttotal: 2.83s\tremaining: 600ms\n",
      "825:\tlearn: 265990.4889775\ttotal: 2.83s\tremaining: 596ms\n",
      "826:\tlearn: 265990.4634899\ttotal: 2.83s\tremaining: 592ms\n",
      "827:\tlearn: 265990.4283069\ttotal: 2.83s\tremaining: 589ms\n",
      "828:\tlearn: 265990.3909986\ttotal: 2.84s\tremaining: 585ms\n",
      "829:\tlearn: 265990.3428317\ttotal: 2.84s\tremaining: 582ms\n",
      "830:\tlearn: 265990.3194220\ttotal: 2.84s\tremaining: 578ms\n",
      "831:\tlearn: 265990.2962280\ttotal: 2.85s\tremaining: 575ms\n",
      "832:\tlearn: 265990.2675782\ttotal: 2.85s\tremaining: 571ms\n",
      "833:\tlearn: 265990.2246993\ttotal: 2.85s\tremaining: 567ms\n",
      "834:\tlearn: 265990.1937561\ttotal: 2.85s\tremaining: 564ms\n",
      "835:\tlearn: 265990.1414497\ttotal: 2.86s\tremaining: 560ms\n",
      "836:\tlearn: 265990.1135308\ttotal: 2.86s\tremaining: 557ms\n",
      "837:\tlearn: 265990.0782944\ttotal: 2.86s\tremaining: 553ms\n",
      "838:\tlearn: 265990.0120625\ttotal: 2.86s\tremaining: 549ms\n",
      "839:\tlearn: 265989.9639460\ttotal: 2.87s\tremaining: 546ms\n",
      "840:\tlearn: 265989.9596733\ttotal: 2.87s\tremaining: 542ms\n",
      "841:\tlearn: 265989.9266086\ttotal: 2.87s\tremaining: 539ms\n",
      "842:\tlearn: 265989.9001006\ttotal: 2.87s\tremaining: 535ms\n",
      "843:\tlearn: 265989.8597840\ttotal: 2.88s\tremaining: 532ms\n",
      "844:\tlearn: 265989.8150577\ttotal: 2.88s\tremaining: 528ms\n",
      "845:\tlearn: 265989.7836331\ttotal: 2.88s\tremaining: 525ms\n",
      "846:\tlearn: 265989.7396016\ttotal: 2.88s\tremaining: 521ms\n",
      "847:\tlearn: 265989.7232645\ttotal: 2.89s\tremaining: 518ms\n",
      "848:\tlearn: 265989.7186084\ttotal: 2.89s\tremaining: 514ms\n",
      "849:\tlearn: 265989.6896482\ttotal: 2.89s\tremaining: 510ms\n",
      "850:\tlearn: 265989.6830435\ttotal: 2.89s\tremaining: 507ms\n",
      "851:\tlearn: 265989.6484509\ttotal: 2.9s\tremaining: 503ms\n",
      "852:\tlearn: 265989.6207491\ttotal: 2.9s\tremaining: 500ms\n",
      "853:\tlearn: 265989.5899853\ttotal: 2.9s\tremaining: 496ms\n",
      "854:\tlearn: 265989.5576927\ttotal: 2.9s\tremaining: 493ms\n",
      "855:\tlearn: 265989.5198201\ttotal: 2.91s\tremaining: 489ms\n",
      "856:\tlearn: 265989.4770998\ttotal: 2.91s\tremaining: 485ms\n",
      "857:\tlearn: 265989.4325656\ttotal: 2.91s\tremaining: 482ms\n",
      "858:\tlearn: 265989.3936638\ttotal: 2.91s\tremaining: 478ms\n",
      "859:\tlearn: 265989.3553500\ttotal: 2.92s\tremaining: 475ms\n",
      "860:\tlearn: 265989.3235890\ttotal: 2.92s\tremaining: 471ms\n",
      "861:\tlearn: 265989.2885112\ttotal: 2.92s\tremaining: 468ms\n",
      "862:\tlearn: 265989.2567497\ttotal: 2.92s\tremaining: 464ms\n",
      "863:\tlearn: 265989.2324963\ttotal: 2.93s\tremaining: 461ms\n",
      "864:\tlearn: 265989.2050470\ttotal: 2.93s\tremaining: 458ms\n",
      "865:\tlearn: 265989.1748899\ttotal: 2.93s\tremaining: 454ms\n",
      "866:\tlearn: 265989.1409202\ttotal: 2.94s\tremaining: 451ms\n",
      "867:\tlearn: 265989.1350185\ttotal: 2.94s\tremaining: 447ms\n",
      "868:\tlearn: 265989.1061580\ttotal: 2.94s\tremaining: 443ms\n",
      "869:\tlearn: 265989.0816469\ttotal: 2.94s\tremaining: 440ms\n",
      "870:\tlearn: 265989.0775909\ttotal: 2.95s\tremaining: 437ms\n",
      "871:\tlearn: 265989.0435162\ttotal: 2.95s\tremaining: 433ms\n",
      "872:\tlearn: 265989.0045966\ttotal: 2.95s\tremaining: 430ms\n",
      "873:\tlearn: 265988.9709294\ttotal: 2.96s\tremaining: 426ms\n",
      "874:\tlearn: 265988.9640306\ttotal: 2.96s\tremaining: 423ms\n",
      "875:\tlearn: 265988.9177614\ttotal: 2.96s\tremaining: 420ms\n",
      "876:\tlearn: 265988.8696446\ttotal: 2.97s\tremaining: 416ms\n",
      "877:\tlearn: 265988.8393234\ttotal: 2.97s\tremaining: 413ms\n",
      "878:\tlearn: 265988.8090858\ttotal: 2.97s\tremaining: 409ms\n",
      "879:\tlearn: 265988.8039083\ttotal: 2.98s\tremaining: 406ms\n",
      "880:\tlearn: 265988.7869131\ttotal: 2.98s\tremaining: 403ms\n",
      "881:\tlearn: 265988.7572030\ttotal: 3.04s\tremaining: 407ms\n",
      "882:\tlearn: 265988.7264403\ttotal: 3.05s\tremaining: 404ms\n",
      "883:\tlearn: 265988.6908434\ttotal: 3.05s\tremaining: 400ms\n",
      "884:\tlearn: 265988.6615037\ttotal: 3.05s\tremaining: 397ms\n",
      "885:\tlearn: 265988.6370493\ttotal: 3.06s\tremaining: 393ms\n",
      "886:\tlearn: 265988.6099318\ttotal: 3.06s\tremaining: 390ms\n",
      "887:\tlearn: 265988.5781378\ttotal: 3.07s\tremaining: 387ms\n",
      "888:\tlearn: 265988.5693477\ttotal: 3.07s\tremaining: 384ms\n",
      "889:\tlearn: 265988.5453171\ttotal: 3.08s\tremaining: 380ms\n",
      "890:\tlearn: 265988.5223284\ttotal: 3.08s\tremaining: 377ms\n",
      "891:\tlearn: 265988.5000316\ttotal: 3.08s\tremaining: 373ms\n",
      "892:\tlearn: 265988.4875078\ttotal: 3.09s\tremaining: 370ms\n",
      "893:\tlearn: 265988.4829515\ttotal: 3.09s\tremaining: 366ms\n",
      "894:\tlearn: 265988.4466636\ttotal: 3.09s\tremaining: 363ms\n",
      "895:\tlearn: 265988.4323399\ttotal: 3.09s\tremaining: 359ms\n",
      "896:\tlearn: 265988.4047325\ttotal: 3.1s\tremaining: 356ms\n",
      "897:\tlearn: 265988.3917180\ttotal: 3.1s\tremaining: 352ms\n",
      "898:\tlearn: 265988.3754931\ttotal: 3.1s\tremaining: 348ms\n",
      "899:\tlearn: 265988.3600287\ttotal: 3.1s\tremaining: 345ms\n",
      "900:\tlearn: 265988.3447229\ttotal: 3.11s\tremaining: 341ms\n",
      "901:\tlearn: 265988.3161267\ttotal: 3.11s\tremaining: 338ms\n",
      "902:\tlearn: 265988.2928623\ttotal: 3.11s\tremaining: 334ms\n",
      "903:\tlearn: 265988.2691412\ttotal: 3.11s\tremaining: 331ms\n",
      "904:\tlearn: 265988.2418482\ttotal: 3.12s\tremaining: 327ms\n",
      "905:\tlearn: 265988.2032698\ttotal: 3.12s\tremaining: 324ms\n",
      "906:\tlearn: 265988.1805214\ttotal: 3.12s\tremaining: 320ms\n",
      "907:\tlearn: 265988.1501628\ttotal: 3.12s\tremaining: 317ms\n",
      "908:\tlearn: 265988.1344205\ttotal: 3.13s\tremaining: 313ms\n",
      "909:\tlearn: 265988.1154041\ttotal: 3.13s\tremaining: 310ms\n",
      "910:\tlearn: 265988.0935802\ttotal: 3.13s\tremaining: 306ms\n",
      "911:\tlearn: 265988.0556330\ttotal: 3.13s\tremaining: 302ms\n",
      "912:\tlearn: 265988.0262968\ttotal: 3.14s\tremaining: 299ms\n",
      "913:\tlearn: 265988.0124363\ttotal: 3.14s\tremaining: 296ms\n",
      "914:\tlearn: 265987.9933845\ttotal: 3.14s\tremaining: 292ms\n",
      "915:\tlearn: 265987.9765388\ttotal: 3.14s\tremaining: 288ms\n",
      "916:\tlearn: 265987.9544832\ttotal: 3.15s\tremaining: 285ms\n",
      "917:\tlearn: 265987.9162375\ttotal: 3.15s\tremaining: 281ms\n",
      "918:\tlearn: 265987.8996303\ttotal: 3.15s\tremaining: 278ms\n",
      "919:\tlearn: 265987.8792630\ttotal: 3.16s\tremaining: 275ms\n",
      "920:\tlearn: 265987.8632973\ttotal: 3.16s\tremaining: 271ms\n",
      "921:\tlearn: 265987.8492080\ttotal: 3.16s\tremaining: 268ms\n",
      "922:\tlearn: 265987.8341943\ttotal: 3.17s\tremaining: 264ms\n",
      "923:\tlearn: 265987.8319633\ttotal: 3.17s\tremaining: 261ms\n",
      "924:\tlearn: 265987.8120462\ttotal: 3.17s\tremaining: 257ms\n",
      "925:\tlearn: 265987.8099238\ttotal: 3.18s\tremaining: 254ms\n",
      "926:\tlearn: 265987.7950826\ttotal: 3.18s\tremaining: 250ms\n",
      "927:\tlearn: 265987.7911768\ttotal: 3.18s\tremaining: 247ms\n",
      "928:\tlearn: 265987.7628691\ttotal: 3.19s\tremaining: 244ms\n",
      "929:\tlearn: 265987.7478440\ttotal: 3.19s\tremaining: 240ms\n",
      "930:\tlearn: 265987.7333609\ttotal: 3.19s\tremaining: 237ms\n",
      "931:\tlearn: 265987.7225223\ttotal: 3.2s\tremaining: 233ms\n",
      "932:\tlearn: 265987.6940422\ttotal: 3.2s\tremaining: 230ms\n",
      "933:\tlearn: 265987.6681626\ttotal: 3.21s\tremaining: 227ms\n",
      "934:\tlearn: 265987.6376609\ttotal: 3.21s\tremaining: 223ms\n",
      "935:\tlearn: 265987.6175446\ttotal: 3.21s\tremaining: 220ms\n",
      "936:\tlearn: 265987.6008773\ttotal: 3.22s\tremaining: 216ms\n",
      "937:\tlearn: 265987.5871335\ttotal: 3.22s\tremaining: 213ms\n",
      "938:\tlearn: 265987.5648241\ttotal: 3.22s\tremaining: 209ms\n",
      "939:\tlearn: 265987.5513723\ttotal: 3.22s\tremaining: 206ms\n",
      "940:\tlearn: 265987.5257521\ttotal: 3.23s\tremaining: 202ms\n",
      "941:\tlearn: 265987.5079119\ttotal: 3.23s\tremaining: 199ms\n",
      "942:\tlearn: 265987.4861075\ttotal: 3.23s\tremaining: 195ms\n",
      "943:\tlearn: 265987.4685317\ttotal: 3.23s\tremaining: 192ms\n",
      "944:\tlearn: 265987.4527526\ttotal: 3.24s\tremaining: 188ms\n",
      "945:\tlearn: 265987.4465552\ttotal: 3.24s\tremaining: 185ms\n",
      "946:\tlearn: 265987.4365730\ttotal: 3.24s\tremaining: 181ms\n",
      "947:\tlearn: 265987.4247989\ttotal: 3.24s\tremaining: 178ms\n",
      "948:\tlearn: 265987.4018517\ttotal: 3.25s\tremaining: 175ms\n",
      "949:\tlearn: 265987.3934878\ttotal: 3.25s\tremaining: 171ms\n",
      "950:\tlearn: 265987.3717988\ttotal: 3.25s\tremaining: 168ms\n",
      "951:\tlearn: 265987.3335246\ttotal: 3.25s\tremaining: 164ms\n",
      "952:\tlearn: 265987.3127685\ttotal: 3.26s\tremaining: 161ms\n",
      "953:\tlearn: 265987.2907154\ttotal: 3.26s\tremaining: 157ms\n",
      "954:\tlearn: 265987.2759936\ttotal: 3.26s\tremaining: 154ms\n",
      "955:\tlearn: 265987.2658556\ttotal: 3.27s\tremaining: 150ms\n",
      "956:\tlearn: 265987.2530300\ttotal: 3.27s\tremaining: 147ms\n",
      "957:\tlearn: 265987.2514617\ttotal: 3.27s\tremaining: 143ms\n",
      "958:\tlearn: 265987.2286766\ttotal: 3.27s\tremaining: 140ms\n",
      "959:\tlearn: 265987.2160039\ttotal: 3.27s\tremaining: 136ms\n",
      "960:\tlearn: 265987.2079854\ttotal: 3.28s\tremaining: 133ms\n",
      "961:\tlearn: 265987.2051081\ttotal: 3.28s\tremaining: 130ms\n",
      "962:\tlearn: 265987.1987758\ttotal: 3.28s\tremaining: 126ms\n",
      "963:\tlearn: 265987.1938000\ttotal: 3.29s\tremaining: 123ms\n",
      "964:\tlearn: 265987.1783303\ttotal: 3.29s\tremaining: 119ms\n",
      "965:\tlearn: 265987.1518996\ttotal: 3.29s\tremaining: 116ms\n",
      "966:\tlearn: 265987.1494238\ttotal: 3.29s\tremaining: 112ms\n",
      "967:\tlearn: 265987.1339193\ttotal: 3.3s\tremaining: 109ms\n",
      "968:\tlearn: 265987.1106862\ttotal: 3.3s\tremaining: 106ms\n",
      "969:\tlearn: 265987.0997138\ttotal: 3.3s\tremaining: 102ms\n",
      "970:\tlearn: 265987.0879271\ttotal: 3.3s\tremaining: 98.7ms\n",
      "971:\tlearn: 265987.0730500\ttotal: 3.31s\tremaining: 95.2ms\n",
      "972:\tlearn: 265987.0548187\ttotal: 3.31s\tremaining: 91.8ms\n",
      "973:\tlearn: 265987.0417469\ttotal: 3.31s\tremaining: 88.4ms\n",
      "974:\tlearn: 265987.0156019\ttotal: 3.31s\tremaining: 85ms\n",
      "975:\tlearn: 265986.9985594\ttotal: 3.32s\tremaining: 81.6ms\n",
      "976:\tlearn: 265986.9684192\ttotal: 3.32s\tremaining: 78.1ms\n",
      "977:\tlearn: 265986.9548964\ttotal: 3.32s\tremaining: 74.7ms\n",
      "978:\tlearn: 265986.9341604\ttotal: 3.32s\tremaining: 71.3ms\n",
      "979:\tlearn: 265986.9214923\ttotal: 3.33s\tremaining: 67.9ms\n",
      "980:\tlearn: 265986.9039326\ttotal: 3.33s\tremaining: 64.5ms\n",
      "981:\tlearn: 265986.9008977\ttotal: 3.33s\tremaining: 61.1ms\n",
      "982:\tlearn: 265986.8975334\ttotal: 3.33s\tremaining: 57.7ms\n",
      "983:\tlearn: 265986.8948612\ttotal: 3.34s\tremaining: 54.3ms\n",
      "984:\tlearn: 265986.8853428\ttotal: 3.34s\tremaining: 50.9ms\n",
      "985:\tlearn: 265986.8775568\ttotal: 3.34s\tremaining: 47.5ms\n",
      "986:\tlearn: 265986.8606963\ttotal: 3.35s\tremaining: 44.1ms\n",
      "987:\tlearn: 265986.8453991\ttotal: 3.35s\tremaining: 40.7ms\n",
      "988:\tlearn: 265986.8221114\ttotal: 3.35s\tremaining: 37.3ms\n",
      "989:\tlearn: 265986.8094074\ttotal: 3.36s\tremaining: 33.9ms\n",
      "990:\tlearn: 265986.7869369\ttotal: 3.36s\tremaining: 30.5ms\n",
      "991:\tlearn: 265986.7854634\ttotal: 3.36s\tremaining: 27.1ms\n",
      "992:\tlearn: 265986.7654814\ttotal: 3.37s\tremaining: 23.7ms\n",
      "993:\tlearn: 265986.7511848\ttotal: 3.37s\tremaining: 20.3ms\n",
      "994:\tlearn: 265986.7396194\ttotal: 3.37s\tremaining: 16.9ms\n",
      "995:\tlearn: 265986.7386023\ttotal: 3.37s\tremaining: 13.6ms\n",
      "996:\tlearn: 265986.7148719\ttotal: 3.38s\tremaining: 10.2ms\n",
      "997:\tlearn: 265986.6991448\ttotal: 3.38s\tremaining: 6.77ms\n",
      "998:\tlearn: 265986.6838936\ttotal: 3.38s\tremaining: 3.39ms\n",
      "999:\tlearn: 265986.6614098\ttotal: 3.39s\tremaining: 0us\n",
      "Prediction for 2028 using CatBoost completed and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor  # Import CatBoostRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026','2027']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a CatBoost Regression model\n",
    "model = CatBoostRegressor(iterations=1000, learning_rate=0.1)  # You can adjust hyperparameters as needed\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2028\n",
    "prediction_2028 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2028[prediction_2028 < 0] = 0\n",
    "\n",
    "# Add the predicted '2028' column to the DataFrame\n",
    "df['2028'] = prediction_2028\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\CatBoo_chumma.csv', index=False)\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(\"Prediction for 2028 using CatBoost completed and saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2802\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 159133.934216\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2018']  # Target variable for 2023\n",
    "\n",
    "# Create a LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Add the predicted values for 2024 as a new column\n",
    "existing_df['2026'] = prediction_2024\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "existing_df.to_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2024 is less than 0\n",
    "if prediction_2024[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2549\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 187616.654064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\LightGBM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2025\n",
    "prediction_2025 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2025[prediction_2025 < 0] = 0\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Add the predicted values for 2025 as a new column\n",
    "existing_df['2025'] = prediction_2025\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "existing_df.to_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2025 is less than 0\n",
    "if prediction_2025[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2802\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 187616.654064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\LightGBM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2026\n",
    "prediction_2026 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2026[prediction_2026 < 0] = 0\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Add the predicted values for 2026 as a new column\n",
    "existing_df['2026'] = prediction_2026\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "existing_df.to_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2026 is less than 0\n",
    "if prediction_2026[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3056\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 187616.654064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\LightGBM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2027\n",
    "prediction_2027 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2027[prediction_2027 < 0] = 0\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Add the predicted values for 2027 as a new column\n",
    "existing_df['2027'] = prediction_2027\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "existing_df.to_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2027 is less than 0\n",
    "if prediction_2027[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3309\n",
      "[LightGBM] [Info] Number of data points in the train set: 2645, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 187616.654064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\LightGBM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023','2024','2025','2026','2027']\n",
    "X_train = df[feature_cols]\n",
    "y_train = df['2023']  # Target variable for 2023\n",
    "\n",
    "# Create a LightGBM model\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for 2028\n",
    "prediction_2028 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2028[prediction_2028 < 0] = 0\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_df = pd.read_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv')\n",
    "\n",
    "# Add the predicted values for 2028 as a new column\n",
    "existing_df['2028'] = prediction_2028\n",
    "\n",
    "# Save the updated DataFrame to the same CSV file\n",
    "existing_df.to_csv(r'C:\\\\Users\\\\augus\\\\OneDrive\\\\Desktop\\\\js\\\\Cargo predict\\\\Export\\\\Dataset\\\\LightGBM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2028 is less than 0\n",
    "if prediction_2028[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'covars' must be symmetric, positive-definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\stats.py:81\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     cv_chol \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# The model is most probably stuck in a component with too\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# few observations, we need to reinitialize this components\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:88\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mCompute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:36\u001b[0m, in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 3-th leading minor of the array is not positive definite",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\stats.py:86\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     cv_chol \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_covar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:88\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03mCompute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\scipy\\linalg\\_decomp_cholesky.py:36\u001b[0m, in \u001b[0;36m_cholesky\u001b[1;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 3-th leading minor of the array is not positive definite",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m hmm\u001b[38;5;241m.\u001b[39mGaussianHMM(n_components\u001b[38;5;241m=\u001b[39mnum_components, covariance_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Make predictions for 2024\u001b[39;00m\n\u001b[0;32m     20\u001b[0m prediction_2024 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)  \u001b[38;5;66;03m# Predict based on existing data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\base.py:473\u001b[0m, in \u001b[0;36m_AbstractHMM.fit\u001b[1;34m(self, X, lengths)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmonitor_\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter):\n\u001b[1;32m--> 473\u001b[0m     stats, curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Compute lower bound before updating model parameters\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(curr_logprob)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\base.py:750\u001b[0m, in \u001b[0;36m_AbstractHMM._do_estep\u001b[1;34m(self, X, lengths)\u001b[0m\n\u001b[0;32m    748\u001b[0m curr_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_X \u001b[38;5;129;01min\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39msplit_X_lengths(X, lengths):\n\u001b[1;32m--> 750\u001b[0m     lattice, logprob, posteriors, fwdlattice, bwdlattice \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# Derived HMM classes will implement the following method to\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;66;03m# update their probability distributions, so keep\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;66;03m# a single call to this method for simplicity.\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accumulate_sufficient_statistics(\n\u001b[0;32m    755\u001b[0m         stats, sub_X, lattice, posteriors, fwdlattice,\n\u001b[0;32m    756\u001b[0m         bwdlattice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\base.py:863\u001b[0m, in \u001b[0;36mBaseHMM._fit_log\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 863\u001b[0m     log_frameprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     log_prob, fwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mforward_log(\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n\u001b[0;32m    866\u001b[0m     bwdlattice \u001b[38;5;241m=\u001b[39m _hmmc\u001b[38;5;241m.\u001b[39mbackward_log(\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_, log_frameprob)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\_emissions.py:130\u001b[0m, in \u001b[0;36mBaseGaussianHMM._compute_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compute_log_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_covars_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\stats.py:42\u001b[0m, in \u001b[0;36mlog_multivariate_normal_density\u001b[1;34m(X, means, covars, covariance_type)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mCompute the log probability under a multivariate Gaussian distribution.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    X under each of the n_components multivariate Gaussian distributions.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m log_multivariate_normal_density_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspherical\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_spherical,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtied\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_tied,\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiag\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_diag,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m: _log_multivariate_normal_density_full}\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_multivariate_normal_density_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovariance_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcovars\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\hmmlearn\\stats.py:89\u001b[0m, in \u001b[0;36m_log_multivariate_normal_density_full\u001b[1;34m(X, means, covars, min_covar)\u001b[0m\n\u001b[0;32m     86\u001b[0m         cv_chol \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39mcholesky(cv \u001b[38;5;241m+\u001b[39m min_covar \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(nf),\n\u001b[0;32m     87\u001b[0m                                   lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m---> 89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcovars\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be symmetric, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive-definite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m cv_log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mdiagonal(cv_chol)))\n\u001b[0;32m     93\u001b[0m cv_sol \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39msolve_triangular(cv_chol, (X \u001b[38;5;241m-\u001b[39m mu)\u001b[38;5;241m.\u001b[39mT, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mValueError\u001b[0m: 'covars' must be symmetric, positive-definite"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\HiddenM_chumma.csv')\n",
    "\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols].values\n",
    "\n",
    "# Create a Hidden Markov Model\n",
    "num_components = 5  # Set the number of hidden states\n",
    "model = hmm.GaussianHMM(n_components=num_components, covariance_type='full' )\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "# Replace negative predictions with 0\n",
    "prediction_2024[prediction_2024 < 0] = 0\n",
    "\n",
    "# Create a DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'2024': prediction_2024})\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\HiddenM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2024 is less than 0\n",
    "if prediction_2024[0] < 0:\n",
    "    print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# Load your dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\filtered_clustered_clster2.csv')\n",
    "# Extract the relevant columns for training\n",
    "feature_cols = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
    "X_train = df[feature_cols].values\n",
    "\n",
    "# Create a Hidden Markov Model\n",
    "num_components = 5 # Set the number of hidden states\n",
    "# Use 'tied' covariance type and add regularization\n",
    "model = hmm.GaussianHMM(n_components=num_components, covariance_type='tied', min_covar=1e-3)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train)\n",
    "\n",
    "# Make predictions for 2024\n",
    "prediction_2024 = model.predict(X_train)  # Predict based on existing data\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with the predicted value for 2024\n",
    "predicted_df = pd.DataFrame({'2024': prediction_2024})\n",
    "\n",
    "# Save the predicted DataFrame to a new CSV file\n",
    "predicted_df.to_csv(r'C:\\Users\\augus\\OneDrive\\Desktop\\js\\Cargo predict\\Export\\Dataset\\HiddenM_chumma.csv', index=False)\n",
    "\n",
    "# Print 0 if predicted value for 2024 is less than 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
